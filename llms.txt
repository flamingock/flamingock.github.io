// File: audit-stores/introduction

# Audit stores

The audit store is Flamingock's dedicated system for tracking execution history, preventing duplicate executions, and ensuring safe system evolution.

## What is the audit store?

The audit store tracks:
- **Execution history**: Which ChangeUnits ran, when, and with what outcome
- **Distributed locking**: Prevents concurrent executions across multiple instances  
- **Issue tracking**: Failed or uncertain executions requiring resolution

Unlike target systems (which your code modifies), the audit store is managed automatically by Flamingock and never modified by your ChangeUnits.

> **Conceptual overview**: For architectural understanding, see [Target systems vs audit store](../overview/audit-store-vs-target-system.md)

## Audit store options

### Cloud Edition
The audit store is **automatically provided and managed** by Flamingock Cloud. No configuration needed - just focus on your changes while Flamingock handles the audit infrastructure.

### Community setup
Alternatively, you can configure your own audit store using one of the supported databases:

- [MongoDB audit store](./community/mongodb-audit-store.md)
- [MongoDB Spring Data audit store](./community/mongodb-springdata-audit-store.md)
- [DynamoDB audit store](./community/dynamodb-audit-store.md)
- [Couchbase audit store](./community/couchbase-audit-store.md)


### Community configuration pattern

Register the audit store with the Flamingock builder:

```java
// Generic example - audit store configuration
public class App {
  public static void main(String[] args) {
    // Create your audit store connection
    AuditStore auditStore = new MongoSyncAuditStore(mongoClient, mongoDatabase);
    
    // Register with Flamingock
    FlamingockStandalone
      .setAuditStore(auditStore)  // Set the audit store
      .addTargetSystems(myTargetSystem)
      .build()
      .run();
  }
}
```

### Spring Boot configuration
```java
@Bean
public AuditStore auditStore(MongoClient mongoClient) {
    return new MongoSyncAuditStore(mongoClient, "flamingock-audit");
}

// Flamingock Spring Boot auto-configuration will pick this up automatically
```



The audit store is critical for Flamingock's safety guarantees and must be configured before running migrations.

---

// File: audit-stores/community/mongodb-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Audit Store

This page explains how to configure **MongoDB** as Flamingock's audit store.
The audit store is where Flamingock records execution history and ensures safe coordination across distributed deployments.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../overview/audit-store-vs-target-system.md).


## Minimum setup

To use MongoDB as your audit store you need to provide:  
- A **MongoClient**  
- A **MongoDatabase**

That's all. Flamingock will take care of collections, indexes, and consistency defaults.  

Example:

```java
public class App {
  public static void main(String[] args) {
    MongoClient client = MongoClients.create("mongodb://localhost:27017");
    MongoDatabase db = client.getDatabase("flamingock_audit");

    Flamingock.builder()
      .setAuditStore(new MongoSyncAuditStore()
          .withMongoClient(client)
          .withDatabase(db))
      .build()
      .run();
  }
}
```

## Dependencies

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `MongoClient` | `.withMongoClient(client)` | MongoDB connection client - **required** |
| `MongoDatabase` | `.withDatabase(database)` | Target database instance - **required** |

### Optional configurations

| Configuration | Method | Default | Description |
|---------------|--------|---------|-------------|
| `WriteConcern` | `.withWriteConcern(concern)` | `MAJORITY` with journal | Write acknowledgment level |
| `ReadConcern` | `.withReadConcern(concern)` | `MAJORITY` | Read isolation level |
| `ReadPreference` | `.withReadPreference(pref)` | `PRIMARY` | Server selection for reads |

## Reusing target system dependencies

If you're already using a MongoDB target system, you can reuse its dependencies to avoid duplicating connection configuration:

```java
// Reuse dependencies from existing target system
MongoSyncTargetSystem mongoTargetSystem = new MongoSyncTargetSystem("user-database")
    .withMongoClient(client)
    .withDatabase(userDatabase);

// Create audit store reusing the same dependencies
MongoSyncAuditStore auditStore = MongoSyncAuditStore
    .reusingDependenciesFrom(mongoTargetSystem);

Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(mongoTargetSystem)
    .build()
    .run();
```

You can still override specific settings if needed:

```java
MongoSyncAuditStore auditStore = MongoSyncAuditStore
    .reusingDependenciesFrom(mongoTargetSystem)
    .withReadConcern(ReadConcern.LOCAL);
```


## Supported versions

| MongoDB Driver                 | MongoDB Server | Support level   |
|--------------------------------|----------------|-----------------|
| `mongodb-driver-sync` 4.0–5.x | 3.6 – 7.0      | Full support    |
| `mongodb-driver-sync` 3.12.x  | 3.4 – 4.4      | Legacy support  |


## Dependencies

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

// MongoDB driver (if not already present)
implementation("org.mongodb:mongodb-driver-sync:5.2.0")
```

</TabItem>

<TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingock.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- MongoDB driver (if not already present) -->
<dependency>
  <groupId>org.mongodb</groupId>
  <artifactId>mongodb-driver-sync</artifactId>
  <version>5.2.0</version>
</dependency>
```

</TabItem>

</Tabs>


## Configuration options

MongoDB audit store works out of the box with production-ready defaults.  
Optional properties let you tune behavior if needed:

| Property                        | Default        | Description                                                                 |
|---------------------------------|----------------|-----------------------------------------------------------------------------|
| `mongodb.autoCreate`            | `true`         | Auto-create collections and indexes.                                        |
| `mongodb.readConcern`           | `MAJORITY`     | Read isolation level.                                                       |
| `mongodb.writeConcern.w`        | `MAJORITY`     | Write acknowledgment level.                                                 |
| `mongodb.writeConcern.journal`  | `true`         | Requires journal commit for durability.                                     |
| `mongodb.writeConcern.wTimeout` | `1s`           | Max wait time for write concern fulfillment.                                |
| `mongodb.readPreference`        | `PRIMARY`      | Node selection for reads.                                                   |
| `mongodb.auditRepositoryName`   | `flamingockAuditLogs` | Collection name for audit entries.                                   |
| `mongodb.lockRepositoryName`    | `flamingockLocks`     | Collection name for distributed locks.                               |

Example overriding defaults:

```java
Flamingock.builder()
  .setAuditStore(new MongoSyncAuditStore()
      .withClient(client)
      .withDatabase(db)
      .withProperty("mongodb.readConcern", "LOCAL")
      .withProperty("mongodb.writeConcern.w", 1))
  .build()
  .run();
```

⚠️ **Warning**: lowering concerns (e.g. `LOCAL`, `w=1`) increases performance but reduces safety.  
Recommended only for dev/test environments.


## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)  
- 👉 See a [full example project](https://github.com/flamingock/flamingock-examples/tree/master/mongodb)

---

// File: audit-stores/community/mongodb-springdata-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Spring Data Audit Store

This page explains how to configure **MongoDB with Spring Data** as Flamingock's audit store.
The audit store is where Flamingock records execution history and ensures safe coordination across distributed deployments.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../overview/audit-store-vs-target-system.md).


## Minimum setup

To use MongoDB Spring Data as your audit store you need to provide:  
- A **MongoTemplate**

That's all. Flamingock will take care of collections, indexes, and consistency defaults.

Example:

```java
public class App {
  public static void main(String[] args) {
    // Assuming MongoTemplate is configured via Spring
    MongoTemplate mongoTemplate = // ... from Spring context
    
    Flamingock.builder()
      .setAuditStore(new MongoSpringDataAuditStore()
          .withMongoTemplate(mongoTemplate))
      .build()
      .run();
  }
}
```

## Dependencies

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `MongoTemplate` | `.withMongoTemplate(template)` | Spring Data MongoDB template - **required** |

### Optional configurations

| Configuration | Method | Default | Description |
|---------------|--------|---------|-------------|
| `WriteConcern` | `.withWriteConcern(concern)` | `MAJORITY` with journal | Write acknowledgment level |
| `ReadConcern` | `.withReadConcern(concern)` | `MAJORITY` | Read isolation level |
| `ReadPreference` | `.withReadPreference(pref)` | `PRIMARY` | Server selection for reads |

## Reusing target system dependencies

If you're already using a MongoDB Spring Data target system, you can reuse its dependencies to avoid duplicating connection configuration:

```java
// Reuse dependencies from existing target system
MongoSpringDataTargetSystem mongoTargetSystem = new MongoSpringDataTargetSystem("user-database")
    .withMongoTemplate(mongoTemplate);

// Create audit store reusing the same dependencies
MongoSpringDataAuditStore auditStore = MongoSpringDataAuditStore
    .reusingDependenciesFrom(mongoTargetSystem);

Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(mongoTargetSystem)
    .build()
    .run();
```

You can still override specific settings if needed:

```java
MongoSpringDataAuditStore auditStore = MongoSpringDataAuditStore
    .reusingDependenciesFrom(mongoTargetSystem)
    .withReadConcern(ReadConcern.LOCAL);
```


## Supported versions

Flamingock provides two editions for different Spring Data MongoDB versions:

| Edition                                       | Spring Data MongoDB | JDK Required | Support level  |
|-----------------------------------------------|---------------------|--------------|----------------|
| `flamingock-community` (standard)            | 4.0.0 - 5.x         | 17+          | Full support   |
| `flamingock-community` (with legacy flag)    | 3.1.4 - 3.x         | 8-11         | Legacy support |

Choose the edition that matches your Spring Data MongoDB and JDK version.


## Dependencies

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

// Spring Data MongoDB (if not already present)
implementation("org.springframework.boot:spring-boot-starter-data-mongodb")
```

</TabItem>

<TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingock.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- Spring Data MongoDB (if not already present) -->
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-data-mongodb</artifactId>
</dependency>
```

</TabItem>

</Tabs>


## Configuration options

MongoDB Spring Data audit store works out of the box with production-ready defaults.  
Optional properties let you tune behavior if needed:

| Property                        | Default                | Description                                               |
|---------------------------------|------------------------|-----------------------------------------------------------|
| `mongodb.autoCreate`            | `true`                 | Auto-create collections and indexes.                      |
| `mongodb.readConcern`           | `MAJORITY`             | Read isolation level.                                     |
| `mongodb.writeConcern.w`        | `MAJORITY`             | Write acknowledgment level.                               |
| `mongodb.writeConcern.journal`  | `true`                 | Requires journal commit for durability.                   |
| `mongodb.writeConcern.wTimeout` | `1s`                   | Max wait time for write concern fulfillment.              |
| `mongodb.readPreference`        | `PRIMARY`              | Node selection for reads.                                 |
| `mongodb.auditRepositoryName`   | `flamingockAuditLogs`  | Collection name for audit entries.                        |
| `mongodb.lockRepositoryName`    | `flamingockLocks`      | Collection name for distributed locks.                    |

Example with Spring Boot configuration:

```yaml
# application.yml
flamingock:
  mongodb:
    autoCreate: true
    readConcern: MAJORITY
    writeConcern:
      w: MAJORITY
      journal: true
      wTimeout: 1s
```

Or programmatically:

```java
Flamingock.builder()
  .setAuditStore(new MongoSpringDataAuditStore()
      .withMongoTemplate(mongoTemplate)
      .withProperty("mongodb.readConcern", "LOCAL")
      .withProperty("mongodb.writeConcern.w", 1))
  .build()
  .run();
```

⚠️ **Warning**: lowering concerns (e.g. `LOCAL`, `w=1`) increases performance but reduces safety.  
Recommended only for dev/test environments.


## Spring Boot integration

For Spring Boot applications, use `@EnableFlamingock` for automatic configuration:

```java
@EnableFlamingock
@SpringBootApplication
public class MyApp {
  public static void main(String[] args) {
    SpringApplication.run(MyApp.class, args);
  }
}
```

Spring Boot will automatically:
- Detect and use your configured `MongoTemplate`
- Apply configuration from `application.yml`
- Set up the audit store


## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)  
- 👉 See a [full example project](https://github.com/flamingock/flamingock-examples/tree/master/mongodb-springdata)

---

// File: audit-stores/community/dynamodb-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# DynamoDB Audit Store

This page explains how to configure **Amazon DynamoDB** as Flamingock's audit store.
The audit store is where Flamingock records execution history and ensures safe coordination across distributed deployments.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../overview/audit-store-vs-target-system.md).


## Minimum setup

To use DynamoDB as your audit store you need to provide:  
- A **DynamoDbClient**

That's all. Flamingock will take care of tables, indexes, and capacity defaults.

Example:

```java
public class App {
  public static void main(String[] args) {
    DynamoDbClient client = DynamoDbClient.builder()
        .region(Region.US_EAST_1)
        .build();

    Flamingock.builder()
      .setAuditStore(new DynamoSyncAuditStore()
          .withClient(client))
      .build()
      .run();
  }
}
```

## Dependencies

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `DynamoDbClient` | `.withClient(client)` | AWS DynamoDB client - **required** |

## Reusing target system dependencies

If you're already using a DynamoDB target system, you can reuse its dependencies to avoid duplicating connection configuration:

```java
// Reuse dependencies from existing target system
DynamoDBTargetSystem dynamoTargetSystem = new DynamoDBTargetSystem("inventory-database")
    .withDynamoDBClient(dynamoDbClient);

// Create audit store reusing the same dependencies
DynamoSyncAuditStore auditStore = DynamoSyncAuditStore
    .reusingDependenciesFrom(dynamoTargetSystem);

Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(dynamoTargetSystem)
    .build()
    .run();
```


## Supported versions

| AWS SDK                        | DynamoDB       | Support level   |
|--------------------------------|----------------|-----------------|
| `dynamodb` 2.25.29+            | All versions   | Full support    |


## Dependencies

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

// AWS SDK (if not already present)
implementation("software.amazon.awssdk:dynamodb:2.28.0")
implementation("software.amazon.awssdk:dynamodb-enhanced:2.28.0")
```

</TabItem>

<TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingock.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- AWS SDK (if not already present) -->
<dependency>
  <groupId>software.amazon.awssdk</groupId>
  <artifactId>dynamodb</artifactId>
  <version>2.28.0</version>
</dependency>
<dependency>
  <groupId>software.amazon.awssdk</groupId>
  <artifactId>dynamodb-enhanced</artifactId>
  <version>2.28.0</version>
</dependency>
```

</TabItem>

</Tabs>


## Configuration options

DynamoDB audit store works out of the box with production-ready defaults.  
Optional properties let you tune behavior if needed:

| Property                        | Default                | Description                                                     |
|---------------------------------|------------------------|------------------------------------------------------------------|
| `dynamodb.autoCreate`           | `true`                 | Auto-create tables if they don't exist.                         |
| `dynamodb.readCapacityUnits`   | `5`                    | Read capacity units (PROVISIONED mode only).                    |
| `dynamodb.writeCapacityUnits`  | `5`                    | Write capacity units (PROVISIONED mode only).                   |
| `dynamodb.auditRepositoryName` | `flamingockAuditLogs`  | Table name for audit entries.                                   |
| `dynamodb.lockRepositoryName`  | `flamingockLocks`      | Table name for distributed locks.                               |

Example overriding defaults:

```java
Flamingock.builder()
  .setAuditStore(new DynamoSyncAuditStore()
      .withClient(client)
      .withProperty("dynamodb.readCapacityUnits", 10)
      .withProperty("dynamodb.writeCapacityUnits", 10))
  .build()
  .run();
```

⚠️ **Warning**: Adjust capacity units based on your workload. Under-provisioning may cause throttling.  
Consider using **ON_DEMAND** billing mode for unpredictable workloads.


## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)  
- 👉 See a [full example project](https://github.com/flamingock/flamingock-examples/tree/master/dynamodb)

---

// File: audit-stores/community/couchbase-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Couchbase Audit Store

This page explains how to configure **Couchbase** as Flamingock's audit store.  
The audit store is where Flamingock records execution history and ensures safe coordination across distributed deployments.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../overview/audit-store-vs-target-system.md).


## Minimum setup

To use Couchbase as your audit store you need to provide:  
- A **Cluster**
- A **Bucket**

That's all. Flamingock will take care of collections, indexes, and scope defaults.

Example:

```java
public class App {
  public static void main(String[] args) {
    Cluster cluster = Cluster.connect("localhost", "username", "password");
    Bucket bucket = cluster.bucket("audit-bucket");
    
    Flamingock.builder()
      .setAuditStore(new CouchbaseSyncAuditStore()
          .withCluster(cluster)
          .withBucket(bucket))
      .build()
      .run();
  }
}
```

## Dependencies

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `Cluster` | `.withCluster(cluster)` | Couchbase cluster connection - **required** |
| `Bucket` | `.withBucket(bucket)` | Target bucket instance - **required** |

## Reusing target system dependencies

If you're already using a Couchbase target system, you can reuse its dependencies to avoid duplicating connection configuration:

```java
// Reuse dependencies from existing target system
CouchbaseTargetSystem couchbaseTargetSystem = new CouchbaseTargetSystem("user-database")
    .withCluster(cluster)
    .withBucket(bucket);

// Create audit store reusing the same dependencies
CouchbaseSyncAuditStore auditStore = CouchbaseSyncAuditStore
    .reusingDependenciesFrom(couchbaseTargetSystem);

Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(couchbaseTargetSystem)
    .build()
    .run();
```


## Supported versions

| Couchbase SDK                  | Couchbase Server | Support level   |
|--------------------------------|------------------|-----------------|
| `java-client` 3.6.0+           | 7.0+             | Full support    |


## Dependencies

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

// Couchbase SDK (if not already present)
implementation("com.couchbase.client:java-client:3.7.0")
```

</TabItem>

<TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingock.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- Couchbase SDK (if not already present) -->
<dependency>
  <groupId>com.couchbase.client</groupId>
  <artifactId>java-client</artifactId>
  <version>3.7.0</version>
</dependency>
```

</TabItem>

</Tabs>


## Configuration options

Couchbase audit store works out of the box with production-ready defaults.  
Optional properties let you tune behavior if needed:

| Property                        | Default                | Description                                           |
|---------------------------------|------------------------|-------------------------------------------------------|
| `couchbase.autoCreate`          | `true`                 | Auto-create collections and indexes.                  |
| `couchbase.scopeName`           | `_default`             | Scope where audit collections will be created.        |
| `couchbase.auditRepositoryName` | `flamingockAuditLogs`  | Collection name for audit entries.                    |
| `couchbase.lockRepositoryName`  | `flamingockLocks`      | Collection name for distributed locks.                |

Example overriding defaults:

```java
Flamingock.builder()
  .setAuditStore(new CouchbaseSyncAuditStore()
      .withCluster(cluster)
      .withBucket(bucket)
      .withProperty("couchbase.scopeName", "custom-scope")
      .withProperty("couchbase.autoCreate", true))
  .build()
  .run();
```

⚠️ **Warning**: Ensure your Couchbase user has permissions to create collections if `autoCreate` is enabled.


## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)  
- 👉 See a [full example project](https://github.com/flamingock/flamingock-examples/tree/master/couchbase)

---

// File: change-units/introduction

# ChangeUnits

A **ChangeUnit** is the atomic, versioned, self-contained unit of change in Flamingock. It encapsulates logic to evolve [**target systems**](../overview/audit-store-vs-target-system.md) safely, deterministically, and with complete auditability.

## Key characteristics

- **Atomic execution**: Each ChangeUnit runs exactly once
- **Ordered sequence**: Executed based on their `order` property  
- **Auditable**: Recorded in the audit store to prevent duplicate execution
- **Safe by default**: If Flamingock is uncertain about a change's outcome, it stops and requires manual intervention
- **Rollback capable**: Can be undone through rollback methods

## What ChangeUnits can do

ChangeUnits enable you to version and track changes across your entire technology stack:

- **Message queue operations**: Topic creation, schema registry updates
- **Object storage**: Bucket setup, file migrations, policy updates  
- **Database migrations**: Schema changes, data transformations, index creation
- **External API integrations**: Service configurations, webhook setups
- **Infrastructure changes**: Feature flag updates, configuration changes

## Types of ChangeUnits

### Code-based ChangeUnits
Written in Java, Kotlin, or Groovy with annotations. Best for complex logic or when you need full programmatic control.

```java
@TargetSystem("user-database")
@ChangeUnit(id = "add-user-status", order = "0001", author = "dev-team")
public class _0001_AddUserStatus {
    
    @Execution
    public void execute(MongoDatabase database) {
        // Your change logic here
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        // Your rollback logic here
    }
}
```

### Template-based ChangeUnits
Use YAML or JSON definitions with reusable templates. Perfect for repetitive operations and standardized patterns.

```yaml
# File: _0002_add_status_column.yml
id: add_status_column
order: "0002"
author: "db-team"
templateName: sql-template
execution: "ALTER TABLE orders ADD COLUMN status VARCHAR(20);"
rollback: "ALTER TABLE orders DROP COLUMN status;"
```

## Safety and recovery

While ChangeUnit executions typically complete successfully, Flamingock provides configurable recovery strategies to handle any exceptional circumstances that may arise. If results are uncertain, Flamingock stops and requires manual intervention rather than risking data corruption, ensuring you always know the exact state of your systems.

You can configure different recovery strategies based on your requirements. For complete details on failure handling and recovery workflows, see [Safety and Recovery](../safety-and-recovery/introduction.md).

## Next steps

Dive deeper into specific aspects of ChangeUnits:

- **[Anatomy & Structure](./anatomy-and-structure.md)** - Learn the technical structure, required properties, and annotations
- **[Types & Implementation](./types-and-implementation.md)** - Understand code-based vs template-based approaches  
- **[Best Practices](./best-practices.md)** - Follow proven patterns for reliable ChangeUnits

Or continue to other key concepts:
- **[Target Systems](../target-systems/introduction.md)** - Configure where your changes will be applied
- **[Templates](../templates/templates-introduction.md)** - Explore reusable change patterns

---

// File: change-units/anatomy-and-structure

# ChangeUnit Anatomy & Structure

Every ChangeUnit follows a consistent structure with required properties, optional configurations, and specific annotations. Understanding this anatomy is essential for creating reliable changes.

## Required properties

Every ChangeUnit must define these three properties:

### `id` - Unique identifier
The `id` must be unique across all ChangeUnits in your application.

```java
@ChangeUnit(id = "add-user-status", order = "0001", author = "dev-team")
```

**Rules:**
- Must be unique application-wide
- Use descriptive names (e.g., `add-user-status`, not `change1`)
- Cannot be modified once deployed

### `order` - Execution sequence
The `order` determines when the ChangeUnit executes relative to others.

```java
@ChangeUnit(id = "create-indexes", order = "0001", author = "dev-team")
@ChangeUnit(id = "migrate-data", order = "0002", author = "dev-team") 
@ChangeUnit(id = "cleanup-temp-data", order = "0003", author = "dev-team")
```

**Requirements:**
- Must use zero-padded format: `0001`, `0002`, `0100`, etc.
- Minimum 4 digits recommended for future expansion
- Determines execution order across all target systems
- Cannot be changed once deployed

### `author` - Responsibility tracking
Identifies who is responsible for this change.

```java
@ChangeUnit(id = "update-schema", order = "0001", author = "database-team")
@ChangeUnit(id = "migrate-users", order = "0002", author = "john.doe@company.com")
```

**Best practices:**
- Use team names for shared responsibility: `database-team`, `api-team`
- Use individual emails for personal changes: `john.doe@company.com`
- Keep consistent within your organization

## Optional properties

### `description` - Change explanation
Briefly describes what the change does, especially useful for complex operations.

```java
@ChangeUnit(
    id = "optimize-user-queries", 
    order = "0001", 
    author = "performance-team",
    description = "Add composite index on user table to improve search performance"
)
```

### `transactional` - Transaction behavior
Controls whether the change runs within a transaction (default: `true`).

```java
@ChangeUnit(
    id = "create-large-index", 
    order = "0001", 
    author = "db-team",
    transactional = false  // DDL operations may require this
)
```

**When to set `transactional = false`:**
- DDL operations (CREATE INDEX, ALTER TABLE)
- Large bulk operations that exceed transaction limits  
- Cross-system changes spanning multiple databases
- Operations that don't support transactions

**Important:** For non-transactional target systems (S3, Kafka, etc.), this flag has no effect.

### `recovery` - Failure handling strategy
Controls how Flamingock handles execution failures (default: `MANUAL_INTERVENTION`).

```java
// Default behavior (manual intervention)
@ChangeUnit(id = "critical-change", order = "0001", author = "team")
public class CriticalChange {
    // Execution stops on failure, requires manual resolution
}

// Automatic retry
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
@ChangeUnit(id = "idempotent-change", order = "0002", author = "team")
public class IdempotentChange {
    // Automatically retries on failure until successful
}
```

**Recovery strategies:**
- `MANUAL_INTERVENTION` (default): Stops execution on failure, requires CLI resolution
- `ALWAYS_RETRY`: Automatically retries on subsequent executions until successful

For detailed information on recovery strategies, see [Safety and Recovery](../safety-and-recovery/introduction.md).

## Required annotations

### `@TargetSystem` - System specification
Declares which target system this ChangeUnit affects.

```java
@TargetSystem("user-database")
@ChangeUnit(id = "add-user-fields", order = "0001", author = "api-team")
public class _0001_AddUserFields {
    // Implementation
}
```


### `@ChangeUnit` - Class marker
Marks the class as a ChangeUnit and contains all metadata.

```java
@ChangeUnit(
    id = "migrate-user-data",
    order = "0001", 
    author = "migration-team",
    description = "Migrate legacy user format to new schema",
    transactional = true
)
```

## Required methods

### `@Execution` - Change logic
Contains the actual change implementation.

```java
@Execution
public void execute(MongoDatabase database, ClientSession session) {
    // Your change logic here
    database.getCollection("users")
            .insertOne(session, new Document("status", "active"));
}
```

**Method characteristics:**
- Must be public
- Can have any name (`execute`, `run`, `apply`, etc.)
- Parameters are dependency-injected by Flamingock
- Should contain idempotent operations when possible

### `@RollbackExecution` - Undo logic
Provides logic to reverse the change, essential for safety and CLI undo operations.

```java
@RollbackExecution
public void rollback(MongoDatabase database, ClientSession session) {
    // Undo the change
    database.getCollection("users")
            .deleteMany(new Document("status", "active"));
}
```

**Why rollback is required:**
- **Non-transactional systems**: Used automatically if execution fails
- **All systems**: Required for CLI/UI undo operations
- **Safety**: Ensures every change can be reversed
- **Governance**: Demonstrates you've thought through the change impact

## Method parameters and dependency injection

ChangeUnits receive dependencies through method parameters, automatically injected by Flamingock from the target system's context, global context, or underlying framework context.

```java
// MongoDB target system
@Execution
public void execute(MongoDatabase database, ClientSession session) {
    // database and session injected from target system or global context
}

// SQL target system  
@Execution
public void execute(DataSource dataSource) {
    // dataSource and connection injected from target system or  global context
}
```

For more details on how dependency resolution works, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## File naming conventions

All ChangeUnit files must follow the `_XXXX_DescriptiveName` pattern:

```
_0001_CreateUserIndexes.java
_0002_MigrateUserData.java  
_0003_AddUserStatusColumn.yml
_0100_OptimizeQueries.java
```

**Rules:**
- Start with underscore and zero-padded order
- Use PascalCase for descriptive names
- Match the `order` property in the annotation
- Applies to both code (.java/.kt/.groovy) and template (.yml/.json) files

## Complete example

Here's a complete ChangeUnit showing all elements:

```java
@TargetSystem("user-database")
@ChangeUnit(
    id = "add-user-preferences", 
    order = "0001", 
    author = "user-experience-team",
    description = "Add preferences object to user documents with default values",
    transactional = true
)
public class _0001_AddUserPreferences {
    
    @Execution
    public void execute(MongoDatabase database, ClientSession session) {
        // Add preferences field with default values
        Document defaultPreferences = new Document()
            .append("notifications", true)
            .append("theme", "light")
            .append("language", "en");
            
        database.getCollection("users")
                .updateMany(
                    session,
                    new Document("preferences", new Document("$exists", false)),
                    new Document("$set", new Document("preferences", defaultPreferences))
                );
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database, ClientSession session) {
        // Remove the preferences field
        database.getCollection("users")
                .updateMany(
                    session,
                    new Document(),
                    new Document("$unset", new Document("preferences", ""))
                );
    }
}
```

## Next steps

- **[ChangeUnit types & Implementation](./types-and-implementation)** - Deep dive into code-based vs template-based approaches
- **[ChangeUnit best Practices](./best-practices)** - Learn proven patterns for reliable ChangeUnits
- **[Target Systems](../target-systems/introduction)** - Configure where your changes will be applied

---

// File: change-units/types-and-implementation

# ChangeUnit Types & Implementation

Flamingock supports two approaches for implementing ChangeUnits: code-based and template-based. Each serves different use cases and provides the same safety guarantees.

## Code-based ChangeUnits

Code-based ChangeUnits are written in Java, Kotlin, or Groovy with annotations. They provide full programmatic control for custom logic or specific operations that don't fit existing templates.

### Basic structure

```java
@TargetSystem("user-database")
@ChangeUnit(id = "migrate-user-emails", order = "0001", author = "data-team")
public class _0001_MigrateUserEmails {
    
    @Execution
    public void execute(MongoDatabase database, ClientSession session) {
        // Custom implementation logic with full programmatic control
        MongoCollection<Document> users = database.getCollection("users");
        users.updateMany(session,
            new Document("email", new Document("$exists", true)),
            new Document("$set", new Document("emailVerified", false)));
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database, ClientSession session) {
        // Rollback logic
        database.getCollection("users")
                .updateMany(session, new Document(),
                    new Document("$unset", new Document("emailVerified", "")));
    }
}
```

## Template-based ChangeUnits

Template-based ChangeUnits use YAML or JSON files with reusable templates. Templates provide a low-code, declarative approach for common patterns and repetitive operations. Templates can be as powerful and complex as code-based ChangeUnits - the difference is that templates are developed for reusable patterns and integrations.

### Basic YAML structure

```yaml
# File: _0001_add_user_index.yml
id: add_user_index
order: "0001"
author: "database-team"
description: "Add index on user email field for faster lookups"
targetSystem: "user-database"
templateName: mongodb-index
execution:
  type: createIndex
  collection: users
  indexSpec:
    email: 1
  options:
    unique: true
    name: "idx_user_email"
rollback:
  type: removeIndex
  collection: users
  indexName: "idx_user_email"
```

For more details about available templates and creating custom templates, see [Templates](../templates/introduction).


## File organization

### Recommended project structure:
```
src/main/java/com/yourapp/changes/
├── _0001_CreateUserIndexes.java
├── _0002_add_user_status.yml
├── _0003_MigrateUserData.java
├── _0004_setup_notifications.yml
└── _0005_OptimizeQueries.java
```

### Best practices:
- **Keep together**: Store both code and template files in the same directory
- **Consistent naming**: Follow `_XXXX_DescriptiveName` pattern for both types

## Template development

Flamingock and the community provide useful templates for common operations. Organizations can also develop their own templates to standardize patterns and integrations specific to their needs.

For more information about available templates and how to create custom templates, see [Templates](../templates/introduction).

## Next steps

- **[Best Practices](./best-practices)** - Learn proven patterns for reliable ChangeUnits
- **[Templates](../templates/introduction)** - Explore available templates and create custom ones
- **[Target Systems](../target-systems/introduction)** - Configure where your changes will be applied

---

// File: change-units/best-practices

# ChangeUnit Best Practices

Following these proven patterns will help you create reliable, maintainable ChangeUnits that work safely in production environments.

## Core principles

### Treat ChangeUnits as immutable

Once a ChangeUnit is deployed, never modify it. Create new ChangeUnits for corrections.

**❌ Don't do this:**
```java
// Modifying an existing ChangeUnit after deployment
@ChangeUnit(id = "add-user-field", order = "0001", author = "team")
public class _0001_AddUserField {
    @Execution  
    public void execute(MongoDatabase db) {
        // Original: db.getCollection("users").updateMany(/* add field */)
        // Modified: db.getCollection("users").updateMany(/* different logic */)
    }
}
```

**✅ Do this instead:**
```java
// Keep the original unchanged
@ChangeUnit(id = "add-user-field", order = "0001", author = "team")
public class _0001_AddUserField {
    @Execution
    public void execute(MongoDatabase db) {
        // Original logic remains unchanged
    }
}

// Create a new ChangeUnit for corrections
@ChangeUnit(id = "fix-user-field-values", order = "0002", author = "team")
public class _0002_FixUserFieldValues {
    @Execution
    public void execute(MongoDatabase db) {
        // Correction logic
    }
}
```

### Always provide rollback logic

Every ChangeUnit must have a `@RollbackExecution` method, regardless of target system type.

**Why rollback matters:**
- **Non-transactional systems**: Automatic cleanup on failure
- **All systems**: CLI/UI undo operations
- **Safety**: Proves you understand the change impact
- **Governance**: Required for audit compliance

**Example with comprehensive rollback:**
```java
@ChangeUnit(id = "setup-user-indexes", order = "0001", author = "db-team")
public class _0001_SetupUserIndexes {
    
    @Execution
    public void execute(MongoDatabase database) {
        MongoCollection<Document> users = database.getCollection("users");
        
        // Create compound index for user queries
        users.createIndex(
            new Document("email", 1).append("status", 1),
            new IndexOptions().name("idx_user_email_status").unique(false)
        );
        
        // Create text index for search
        users.createIndex(
            new Document("firstName", "text").append("lastName", "text"),
            new IndexOptions().name("idx_user_search")
        );
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        MongoCollection<Document> users = database.getCollection("users");
        
        // Drop indexes in reverse order
        try {
            users.dropIndex("idx_user_search");
        } catch (Exception e) {
            // Index might not exist - log but continue
        }
        
        try {
            users.dropIndex("idx_user_email_status");  
        } catch (Exception e) {
            // Index might not exist - log but continue
        }
    }
}
```

### Keep scope focused

Each ChangeUnit should address one logical change. Avoid combining unrelated operations.

**❌ Avoid mixing concerns:**
```java
@ChangeUnit(id = "big-refactor", order = "0001", author = "team")
public class _0001_BigRefactor {
    @Execution
    public void execute(MongoDatabase db, KafkaProducer producer) {
        // Adding user field
        db.getCollection("users").updateMany(/* ... */);
        
        // Creating Kafka topic  
        producer.send(/* create topic message */);
        
        // Updating configuration
        db.getCollection("config").updateOne(/* ... */);
    }
}
```

**✅ Separate concerns:**
```java
@TargetSystem("user-database")
@ChangeUnit(id = "add-user-status", order = "0001", author = "team")
public class _0001_AddUserStatus {
    // Focus: User schema change only
}

@TargetSystem("kafka-events")
@ChangeUnit(id = "create-user-topic", order = "0001", author = "team") 
public class _0001_CreateUserTopic {
    // Focus: Kafka topic creation only
}
```

## Technical guidelines

### Design for idempotency

Make operations safe to re-run whenever possible.

**Example: Idempotent field addition:**
```java
@ChangeUnit(id = "add-user-preferences", order = "0001", author = "team")
public class _0001_AddUserPreferences {
    
    @Execution
    public void execute(MongoDatabase database) {
        // Only update users that don't already have preferences
        database.getCollection("users").updateMany(
            new Document("preferences", new Document("$exists", false)),
            new Document("$set", new Document("preferences", getDefaultPreferences()))
        );
    }
    
    private Document getDefaultPreferences() {
        return new Document()
            .append("theme", "light")
            .append("notifications", true);
    }
}
```

### Handle errors gracefully

Don't catch exceptions unless you have specific recovery logic. Let Flamingock handle error management.

**❌ Don't suppress errors:**
```java
@Execution
public void execute(MongoDatabase database) {
    try {
        // Some operation
        database.getCollection("users").updateMany(/* ... */);
    } catch (Exception e) {
        // Silently ignoring errors prevents proper error handling
        System.out.println("Error occurred: " + e.getMessage());
    }
}
```

**✅ Let exceptions bubble up:**
```java
@Execution  
public void execute(MongoDatabase database) {
    // Let Flamingock handle exceptions and recovery
    database.getCollection("users").updateMany(/* ... */);
}
```

### Use meaningful method names

Method names should clearly indicate their purpose.

**Good examples:**
```java
@Execution
public void migrateUserProfilesToNewSchema(MongoDatabase db) { }

@Execution  
public void addEmailIndexForFasterLookups(MongoDatabase db) { }

@RollbackExecution
public void removeEmailIndexAndRevertSchema(MongoDatabase db) { }
```

### Avoid domain objects

Don't use domain objects in ChangeUnits. Since ChangeUnits are immutable and your domain evolves, using domain classes can cause compilation errors when fields are removed or modified in newer versions. Instead, work with primitive types, collections, or framework-native objects like `Document` for MongoDB.


## Naming and organization

### Follow consistent naming patterns

**File names:**
- Use `_XXXX_DescriptiveName` format
- Match the order in `@ChangeUnit` annotation
- Use PascalCase for class names

**Good examples:**
```
_0001_CreateUserIndexes.java
_0002_MigrateUserData.java
_0003_AddUserPreferences.java
_0100_OptimizeUserQueries.java
```

### Use descriptive IDs and descriptions

Make your ChangeUnits self-documenting:

```java
@ChangeUnit(
    id = "migrate-legacy-user-format-to-v2",
    order = "0001",
    author = "data-migration-team", 
    description = "Migrate user documents from legacy format to v2 schema with new preference structure"
)
```

### Organize by chronological order

ChangeUnits should be organized chronologically by their order within stages. If you need logical grouping, use stages - but remember that execution order is only guaranteed within a stage, not between stages.

```
src/main/java/com/company/changes/
├── _0001_CreateUserCollection.java
├── _0002_AddUserIndexes.java  
├── _0003_MigrateUserData.java
├── _0004_CreateOrdersTable.java
└── _0005_AddOrderStatusColumn.java
```

## Testing and validation

### Test both execution and rollback

Create comprehensive tests for your ChangeUnits:

```java
@Test
public void testUserMigrationChangeUnit() {
    // Arrange
    MongoDatabase testDb = getTestDatabase();
    insertTestUsers(testDb);
    
    _0001_MigrateUsers changeUnit = new _0001_MigrateUsers();
    
    // Act - Test execution
    changeUnit.execute(testDb);
    
    // Assert - Verify execution results
    MongoCollection<Document> users = testDb.getCollection("users");
    assertEquals(5, users.countDocuments(new Document("status", "active")));
    
    // Act - Test rollback  
    changeUnit.rollback(testDb);
    
    // Assert - Verify rollback results
    assertEquals(0, users.countDocuments(new Document("status", new Document("$exists", true))));
}
```

### Validate with real-like data

Test with data that resembles production:

```java
@Test
public void testWithRealisticData() {
    // Use realistic data volumes and edge cases
    insertUsers(1000);  // Test batch processing
    insertUsersWithMissingFields(); // Test data inconsistencies
    insertUsersWithEdgeCaseValues(); // Test boundary conditions
    
    // Run your ChangeUnit
    changeUnit.execute(database);
    
    // Verify all scenarios handled correctly
}
```


## Next steps

- **[Templates](../templates/introduction)** - Explore reusable change patterns
- **[Target Systems](../target-systems/introduction)** - Configure where changes are applied
- **[Testing](../testing/introduction)** - Comprehensive testing strategies for ChangeUnits

---

// File: cli/cli

# Flamingock CLI

Command-line tool for audit management and maintenance operations.

> **Beta Release**  
> This is the beta version of Flamingock CLI, providing essential management operations for audit control and issue resolution. A more comprehensive CLI with full migration execution capabilities is in development.

## Overview

The Flamingock CLI provides operational commands for audit management and maintenance. Use these commands to view audit history, identify issues, and perform resolution operations.

## Installation

### Download

```bash
# Download the latest CLI distribution
curl -L https://github.com/flamingock/flamingock-java/releases/latest/download/flamingock-cli.tar.gz -o flamingock-cli.tar.gz

# Extract the archive
tar -xzf flamingock-cli.tar.gz

# Make it executable
chmod +x flamingock

# Run the CLI
./flamingock --help
```

### Configuration

Create a `flamingock.yml` configuration file in your working directory:

#### MongoDB Configuration
```yaml
serviceIdentifier: my-service  # Optional, defaults to "flamingock-cli"
audit:
  mongodb:
    connectionString: mongodb://localhost:27017
    database: myapp
    # Or use individual properties:
    # host: localhost
    # port: 27017
    # username: admin
    # password: secret
```

#### DynamoDB Configuration
```yaml
serviceIdentifier: my-service
audit:
  dynamodb:
    region: us-east-1
    # Optional endpoint for local development:
    # endpoint: http://localhost:8000
    # accessKey: local
    # secretKey: local
```

You can specify a custom configuration file using the `-c` or `--config` option:
```bash
flamingock -c custom-config.yml audit list
```

## Core Commands

### View Audit Entries

List the current state of all changes (snapshot view):
```bash
flamingock audit list
```

View the complete chronological history:
```bash
flamingock audit list --history
```

View changes since a specific date:
```bash
flamingock audit list --since 2025-01-01T00:00:00
```

Show extended information including execution details:
```bash
flamingock audit list --extended
```

### Find Issues

List all change units with inconsistent audit states:
```bash
flamingock issue list
```

Output in JSON format for automation:
```bash
flamingock issue list --json
```

### Investigate Issues

Get detailed information about a specific issue:
```bash
flamingock issue get -c user-migration-v2
```

Include resolution guidance:
```bash
flamingock issue get -c user-migration-v2 --guidance
```

Get the next priority issue (when no change ID specified):
```bash
flamingock issue get --guidance
```

### Resolve Issues

After manually verifying or fixing the state, mark the change as resolved:

If the change was successfully applied:
```bash
flamingock audit fix -c user-migration-v2 -r APPLIED
```

If the change was not applied or rolled back:
```bash
flamingock audit fix -c user-migration-v2 -r ROLLED_BACK
```

For detailed workflows on issue resolution, see [Issue resolution](../safety-and-recovery/issue-resolution.md).

## Command Reference

### Global Options

```bash
flamingock [global-options] <command> [command-options]
```

- `-c, --config <file>` - Configuration file path (default: `flamingock.yml`)
- `--verbose` - Enable verbose logging
- `--debug` - Enable debug logging
- `--quiet` - Suppress non-essential output
- `--help` - Show help information
- `--version` - Show version information

### `audit list`

Display audit entries from the audit store.

**Options:**
- `--history` - Show full chronological history (all entries)
- `--since <datetime>` - Show entries since date (ISO-8601 format: `2025-01-01T00:00:00`)
- `-e, --extended` - Show extended information (execution ID, duration, class, method, hostname)

**Examples:**
```bash
# View current state (latest per change unit)
flamingock audit list

# View all historical entries
flamingock audit list --history

# View changes from last 24 hours
flamingock audit list --since 2025-01-07T00:00:00

# View with extended details
flamingock audit list --extended
```

### `audit fix`

Resolve an inconsistent audit state after manual intervention.

**Options:**
- `-c, --change-id <id>` - Change unit ID to fix (required)
- `-r, --resolution <type>` - Resolution type: `APPLIED` or `ROLLED_BACK` (required)

**Examples:**
```bash
# Mark as successfully applied
flamingock audit fix -c create-user-index -r APPLIED

# Mark as rolled back (will be retried on next execution)
flamingock audit fix -c create-user-index -r ROLLED_BACK
```

### `issue list`

List all change units with inconsistent audit states.

**Options:**
- `-j, --json` - Output in JSON format

**Examples:**
```bash
# List issues in table format
flamingock issue list

# Output as JSON for automation
flamingock issue list --json
```

### `issue get`

Show detailed information about an issue.

**Options:**
- `-c, --change-id <id>` - Specific change unit ID (optional, shows next issue if omitted)
- `-g, --guidance` - Include resolution guidance
- `-j, --json` - Output in JSON format

**Examples:**
```bash
# Get next priority issue
flamingock issue get --guidance

# Get specific issue details
flamingock issue get -c user-migration-v3

# Get with resolution guidance
flamingock issue get -c user-migration-v3 --guidance

# Output as JSON
flamingock issue get -c user-migration-v3 --json
```

## Example Output

### Audit List Output
```
Audit Entries Snapshot (Latest per Change Unit):
==================================================

┌──────────────────────────────┬────────┬──────────────────┬─────────────────────┐
│ Change ID                    │ State  │ Author           │ Time                │
├──────────────────────────────┼────────┼──────────────────┼─────────────────────┤
│ create-users-collection      │ ✓      │ platform-team    │ 2025-01-07 10:15:23 │
│ add-user-indexes             │ ✓      │ platform-team    │ 2025-01-07 10:15:24 │
│ seed-initial-data            │ ✗      │ data-team        │ 2025-01-07 10:15:25 │
└──────────────────────────────┴────────┴──────────────────┴─────────────────────┘

Legend: ✓ = EXECUTED | ✗ = FAILED | ▶ = STARTED | ↩ = ROLLED_BACK

Total entries: 3
```

### Issue Details Output
```
Issue Details: seed-initial-data
==================================================

📋 OVERVIEW
  Change ID: seed-initial-data
  State: STARTED (❌)
  Target System: user-database
  Author: data-team
  Time: 2025-01-07 10:15:25
  Execution ID: exec-123456
  Duration: 1523ms

⚠️  ERROR DETAILS
  Execution interrupted unexpectedly

  Technical Details:
  - Class: i.f.changes.SeedData
  - Method: execute
  - Hostname: prod-server-01

🔧 Resolution Process:

     1. Review the error details above to understand the root cause

     2. Verify the actual state in your target system (user-database):
        • Check if the change was successfully applied despite the audit failure
        • Determine if the change was partially applied or not applied at all

     3. Fix the audit state based on your findings:

        ✅ If change was successfully applied:
           flamingock audit fix -c seed-initial-data -r APPLIED

        ↩️  If change was not applied or you've manually rolled it back:
           flamingock audit fix -c seed-initial-data -r ROLLED_BACK
           (Flamingock will retry this change in the next execution)

     ⚠️  Important: For partially applied changes, you must either:
         • Manually complete the change, then fix it with resolution(-r) APPLIED
         • Manually revert the change, then fix it with resolution(-r) ROLLED_BACK
```

## Logging Levels

Control the verbosity of output using logging options:

```bash
# Normal output (default)
flamingock audit list

# Verbose output with info logs
flamingock --verbose audit list

# Debug output with detailed logs
flamingock --debug audit list

# Minimal output
flamingock --quiet audit list
```

## Environment Variables

You can set default values using environment variables:

```bash
export FLAMINGOCK_CONFIG=/path/to/config.yml
export FLAMINGOCK_LOG_LEVEL=DEBUG
```

## Troubleshooting

### Connection Issues

If you see "Cannot connect to audit store":
1. Verify your configuration file exists and is valid YAML
2. Check database connection parameters
3. Ensure the database is accessible from your location
4. Test with verbose logging: `flamingock --verbose audit list`

### No Issues Found

If `issue list` shows no issues but you expect some:
1. Verify you're connecting to the correct audit store
2. Check if issues were already resolved
3. Use `audit list --history` to see all historical entries

### Permission Errors

If you get permission errors when running `audit fix`:
1. Ensure your database credentials have write access
2. Verify the audit collection/table permissions
3. Check if the database user can modify audit entries

---

// File: cloud-edition/cloud-edition

# Cloud Edition
:::warning[**Cloud Edition Coming Soon**]
The Cloud Edition is currently under development and not yet publicly available.

**If you'd like to participate in early testing or be notified when Cloud Edition is available, email us at [support@flamingock.io](mailto:support@flamingock.io)**

🔔 Stay tuned — it’s launching very soon!


:::
Flamingock Cloud Edition is a **fully managed SaaS platform** that brings advanced features, collaboration, and visibility to your change management workflow.

While the Community Audit Stores offers core functionality with local storage and self-managed execution, the Cloud Edition extends that with powerful enterprise-grade capabilities.

## What the Cloud Edition will offer

Once released, the Cloud Edition will enable:

- **Centralized dashboards** to track and visualize changes across services and environments
- **Built-in user and team management** with Role-Based Access Control (RBAC)
- **Cross-environment visibility** for staging, production, and everything in between
- **Advanced template and extension support** for faster integration and reuse
- **Governance, auditability, and compliance** built into every change lifecycle
- **Multi-tenant and multi-service support**, ready for real-world deployment complexity

:::note
The Cloud Edition still relies on the Flamingock client library to run within your application.  
:::

## What's coming in this section

This section will guide you through:

- How to set up your **Cloud Edition environment**
- How to configure the Flamingock **client for Cloud Edition**
- How to use the **dashboard**, explore audits, and manage services
- Best practices for working with **multi-environment** and **multi-team** setups

---

// File: flamingock-library-config/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Flamingock library configuration

Flamingock provides flexible configuration options to support a variety of environments and workflows — from local setups to cloud-native distributed systems.

Configuration is divided into two distinct scopes:

- **Setup configuration** defines how Flamingock discovers and organizes change units. This is configured using the `@Flamingock` annotation.

- **Runtime configuration** includes optional parameters such as locking, metadata, author, etc., and can be provided via builder or (depending on the environment) a file.


## What you can configure

| Area                             | Description                                         | Link |
|----------------------------------|-----------------------------------------------------|------|
| ⭐ Setup & stages                | Organize changes into ordered stages - **Essential** | [Setup & stages](./setup-and-stages.md) |
| ⭐ Target systems               | Configure target systems for your changes - **Essential** | [Target systems](../target-systems/introduction.md) |
| ⭐ Audit store                  | Configure audit storage - **Essential** | [Audit stores](../audit-stores/introduction.md) |
| Global dependency injection      | Dependency injection to ChangeUnits and environment | [Context and dependencies](./context-and-dependencies.md) |
| Cloud Edition                    | Cloud-specific setup: token, env, service           | [Cloud Edition](../cloud-edition/cloud-edition.md) |
| Framework integration            | Integration with frameworks (currently Spring Boot) | [Spring Boot integration](../frameworks/springboot-integration/introduction.md) |
| Lock                             | Distributed locking and timing options              | [Lock configuration](./lock.md) |
| Extra                            | Metadata, default author, enable/disable            | [Additional configuration](./additional-configuration.md) |


Each of these topics is explained in its own section.




## Applying runtime configuration
Runtime configuration (everything except the pipeline) can be applied in the following ways:

| Runtime environment |  Builder  |         File          |
|---------------------|:---------:|:---------------------:|
| Standalone          |     ✅     |    ❌ (coming soon)    |
| Springboot          |     ✅     |  ✅(framework native)  |

:::info
You can combine both approaches. If a property is defined in both, the builder value takes precedence.
:::


## Next steps

Start with the essential configurations marked with ⭐, then explore additional options based on your needs:

### Essential configurations (start here)
- [⭐ Setup & stages](./setup-and-stages.md) - Define how changes are organized and discovered
- [⭐ Target systems](../target-systems/introduction.md) - Configure systems where changes will be applied
- [⭐ Audit stores](../audit-stores/introduction.md) - Set up audit storage (not needed for Cloud Edition)

### Additional configurations
- [Global dependency injection](./context-and-dependencies.md) - Configure dependency resolution
- [Framework integration](../frameworks/springboot-integration/introduction.md) - Spring Boot integration
- [Lock configuration](./lock.md) - Distributed locking options
- [Additional configuration](./additional-configuration.md) - Metadata, author, and other settings

### Choose your edition
- [☁️ Cloud Edition](../cloud-edition/cloud-edition.md) - Fully-featured managed solution
- [🧪 Community Edition](../audit-stores/introduction.md) - Community audit stores (feature-limited)

---

// File: flamingock-library-config/setup-and-stages

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Setup & Stages

The Flamingock **setup** organizes and executes your changes using **stages**. By default, you'll use a single stage that groups all your changes and executes them sequentially.

Changes within a stage are executed sequentially with order guaranteed. However, execution order between stages is not guaranteed - Flamingock handles system and legacy stages appropriately to ensure correctness.


## Setup configuration

Flamingock is configured using the `@EnableFlamingock` annotation on any class in your application. This annotation is required for all environments — whether you're using the standalone runner or Spring Boot integration.

The annotation is **only** used for defining the setup (stages and their sources). No runtime configuration should be placed here.


## Defining the setup

Here's the default single-stage configuration:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")
    }
)
public class FlamingockConfig {
    // Configuration class
}
```

Alternatively, using a YAML file:

```java
@EnableFlamingock(pipelineFile = "config/setup.yaml")
public class FlamingockConfig {}
```

Where `config/setup.yaml` contains:
```yaml
pipeline:
  stages:
    - name: main
      location: com.yourcompany.changes
```

:::info Advanced options:
- **Multiple stages**: For complex scenarios requiring independent change sets go to the [stage section below](#multiple-stages-advanced)
- **File-based configuration**: Use `pipelineFile` parameter for YAML configuration
- **Explicit naming**: Use `@Stage(name = "custom", location = "com.yourcompany.changes")`
:::


## Stage Types

Flamingock supports two families of stages:

### Standard Stages (default)
The default stage type where users place their changes. This is where you'll put all your application changes (Kafka, MongoDB, SQL, S3, etc.). Standard stages execute changeUnits in order and provide predictable, sequential execution.

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")  // Standard stage (default type)
    }
)
```

### Special Stages
For specific scenarios, Flamingock provides special stage types that require explicitly specifying a `type` parameter. Examples include `SYSTEM` and `LEGACY` stage types, which are used in particular contexts such as the Mongock upgrade process.

```java
@EnableFlamingock(
        stages = {
                @Stage(type = SYSTEM, location = "com.yourapp.system"),
                @Stage(type = LEGACY, location = "com.yourapp.mongock"),
                @Stage(location = "com.yourcompany.changes")  // Standard stage (default type)
        }
)
```

To see these special stages in action, refer to the [Upgrade from Mongock guide](../resources/upgrade-from-mongock) which demonstrates their practical usage.


## Multiple Stages (Advanced)

Most applications will naturally fit into a single stage, which keeps things simple and ensures a clear, deterministic execution order. 
However, if you prefer to organize changes into multiple stages—for example, to separate concerns or enforce isolated execution 
flows—Flamingock fully supports that as well. We’ll explain how it works and what to consider when taking that approach.

:::tip Default approach:
Most applications use a single stage: `@Stage(location = "com.yourcompany.changes")`. The name is auto-derived ("changes") and this is the recommended default setup.
:::


### When to Use Multiple Stages

Multiple stages are beneficial in specific scenarios:

#### Multi-module Applications
In monolithic applications with well-defined module boundaries, you can give each module its own stage for full autonomy:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "user-module", location = "com.yourapp.users.changes"),
        @Stage(name = "billing-module", location = "com.yourapp.billing.changes"),
        @Stage(name = "notification-module", location = "com.yourapp.notifications.changes")
    }
)
```

This approach allows:
- Independent change management across modules
- Different release cycles for different modules
- Clear separation of concerns and responsibilities

#### Functional Separation
You might want to separate changes by function or lifecycle:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "core-setup", location = "com.yourapp.setup.changes"),
        @Stage(name = "business-logic", location = "com.yourapp.business.changes"),
        @Stage(name = "monitoring-setup", location = "com.yourapp.monitoring.changes")
    }
)
```

### Restrictions and Important Considerations

#### No Execution Order Guarantees
**Critical limitation**: Flamingock does not guarantee execution order between stages. This means:

- Stage A might execute before, after, or concurrently with Stage B
- You cannot rely on changes in one stage being applied before another stage starts
- Each stage should be completely independent from others

#### Why This Matters
Consider this problematic scenario:
```java
// ❌ PROBLEMATIC: Relies on execution order
@EnableFlamingock(
    stages = {
        @Stage(name = "create-tables", location = "com.yourapp.schema"),     // Creates tables
        @Stage(name = "seed-data", location = "com.yourapp.data")           // Inserts data - DEPENDS on tables existing!
    }
)
```

The `seed-data` stage might execute before `create-tables`, causing failures.

#### Correct Approach
Instead, group dependent changes in the same stage:
```java
// ✅ CORRECT: All related changes in one stage
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")  // Contains both table creation AND data seeding in order
    }
)
```


### When NOT to Use Multiple Stages

Avoid multiple stages when:
- **You need execution order across different change types** - Use a single stage instead
- **Changes are logically related** - Keep them together for easier maintenance
- **Simple applications** - The complexity isn't worth the overhead
- **Cross-cutting concerns** - Changes that affect multiple areas should be in one stage

:::info Future Enhancements
Conditional stage execution based on dependencies or conditions is planned for future releases, which would allow:
- Running stages based on success/failure of other stages
- Defining explicit dependencies between stages
- More sophisticated stage orchestration patterns
:::

## Required fields

Each stage must define:
- `name` (optional): A unique identifier - if not provided, it will be auto-derived from the location
- `location`: The package or directory where changes are located


## Stage fields

| Field            | Required            | Description                                                                 |
|------------------|---------------------|-----------------------------------------------------------------------------|
| `location`       | :white_check_mark:  | Package or directory scanned for both code-based and template-based changes |
| `name`           | :x:                 | Unique identifier for the stage (auto-derived from location if not provided) |
| `description`    | :x:                 | Optional text explaining the stage's purpose                                |


## Where Changes are located

- **`location`** refers to a source package (e.g., `com.company.changes`), a relative(e.g., `my/path/changes`) or absolute(e.g., `/my/path/changes`) resources directory.  
  - Template-based and code-based changes can co-exist if location is a source package.
  - If location references a resource directory, it only accepts template-based changeUnits.
  - Default source roots: `src/main/java`, `src/main/kotlin`, `src/main/scala`, `src/main/groovy`. 
  - Source root can be customized via the `sources` compiler option.
  - Resource root can be customized via the `resources` compiler option.
  
- Customizing Source and Resource Root Paths
<Tabs groupId="gradle_maven">
    <TabItem value="gradle" label="Gradle" default>
```kotlin
tasks.withType<JavaCompile> {
    options.compilerArgs.addAll(listOf(
        "-Asources=custom/src",
        "-Aresources=custom/resources"
    ))
}
```
    </TabItem>
    <TabItem value="maven" label="Maven">
```xml
<build>
  <plugins>
    <plugin>
      <artifactId>maven-compiler-plugin</artifactId>
      <configuration>
        <compilerArgs>
          <arg>-Asources=custom/src</arg>
          <arg>-Aresources=custom/resources</arg>
        </compilerArgs>
      </configuration>
    </plugin>
  </plugins>
</build>
```
    </TabItem>
</Tabs>



## Example Pipeline

```yaml
pipeline:
  stages:
    - name: user-setup
      description: User-related DB setup
      location: com.yourapp.flamingock.users
```

Folder view:

```
src/
  main/
    java/
      com/
        yourapp/
          flamingock/
            users/
              _0001_CREATE_USERS_TABLE.java
              _0002_ADD_INDEX.yaml
```


## Best Practices

### Single Stage Execution (default and recommended)

In most applications, **changes that require a specific, deterministic execution order** should be grouped into a **single stage**. This ensures they are applied sequentially and in the exact order they are defined.

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")
    }
)
```

Grouping related changes into a single stage:
- Ensures **predictable, sequential execution**
- Avoids ambiguity from cross-stage execution timing
- Eliminates the need to manage inter-stage dependencies
- Keeps setup simple and easier to maintain
- Supports mixing all types of changes (Kafka, MongoDB, SQL, S3, etc.) in a well-defined order

:::info Advanced scenarios
If your application benefits from separating changes—for example, by module or lifecycle—you can define [Multiple Stages (Advanced)](#multiple-stages-advanced). Just remember: deterministic execution is guaranteed only within a stage, not across them.
:::

### Placing your changes
We strongly recommend placing all your changes — code-based and template-based — in a **single location** defined by the `@Stage` annotation.
  - Ensures changes are always scanned, regardless of type
  - Avoids needing two locations if one template-based change requires fallback to code
  - Keeps everything in one logical location


### Naming Convention for Changes
To ensure clarity and enforce ordering, we recommend naming changes using the following format:

```
_0001_CREATE_CLIENTS_TABLE.java
_0002_ADD_INDEX_TO_EMAIL.yaml
```

- `XXXX`: The execution order of the change
- `CHANGE_NAME`: Descriptive name of what the change does

This convention:
- Works across both code-based and template-based formats
- Makes the execution order obvious at a glance
- Ensures consistent naming and project hygiene

:::tip
While Java typically avoids underscores and leading digits, change units are not traditional classes. Prioritizing **readability and order** is more valuable in this context.
:::



## 🛠 Troubleshooting

### My stage isn't picked up
- Make sure the stage has a `location` field defined
- Check the file path is correct and uses `/` as a separator, not `.` in YAML
- If using resource directory paths, make sure the file is placed under `src/main/resources/your-dir`

### No changes found in stage
- Verify that the class or YAML file is located in the expected package/directory
- For code-based changes, ensure the class is annotated with `@Change` or `@ChangeUnit`
- For template-based changes, check file names and YAML formatting

---

// File: flamingock-library-config/context-and-dependencies

# Context and dependencies

Flamingock provides a sophisticated dependency injection system that automatically resolves dependencies for ChangeUnits from multiple sources. Understanding this system is crucial for building maintainable and well-structured changes.

## What is the context?

The context is Flamingock's dependency container that holds all the dependencies your ChangeUnits might need. It's organized hierarchically, allowing for proper scoping and isolation of dependencies.

Contexts can contain:
- System connectors (databases, message queues, storage services, APIs)
- Configuration properties and objects
- Service instances and business logic components
- Framework-specific beans (like Spring components)
- Custom utilities and helpers

## Dependency resolution hierarchy

Flamingock uses a **hierarchical resolution strategy** that searches for dependencies in this order:

1. **Target system context** - Dependencies provided by the specific target system. For more information, see [Target systems](../target-systems/introduction.md).
2. **General application context** - Shared dependencies registered globally directly in the builder  
3. **Framework context** - When using Spring Boot, beans from the Spring container. For more information, see [Spring Boot integration](../frameworks/springboot-integration/introduction.md).

This approach ensures that system-specific dependencies are properly scoped while allowing shared utilities to be available everywhere.

### How it works in practice

When a ChangeUnit needs a dependency, Flamingock follows a specific search pattern. For example, imagine your ChangeUnit requires a `NotificationService`:

**Scenario 1**: If the Kafka target system provides its own notification service specifically for event streaming, and your ChangeUnit belongs to that Kafka target system, Flamingock will use the Kafka-specific notification service. The target system context always wins.

**Scenario 2**: If your MongoDB target system doesn't provide a notification service, but you've registered one globally in Flamingock's builder, the ChangeUnit will receive that global notification service. Flamingock searches the target system first, doesn't find it, then falls back to the global context.

**Scenario 3**: In a Spring Boot application, if neither the target system nor the global context provides the dependency, Flamingock will look for a Spring bean of that type. This allows seamless integration with your existing Spring components.

This hierarchy ensures that specialized implementations (like a Kafka-optimized notification service) are used when available, while still allowing shared services to be accessible across all ChangeUnits.

## Providing dependencies

### Target system dependencies

Every target system provides two ways to add dependencies:

**Specific methods** - Each concrete implementation offers `.withXXX()` methods for common dependencies:
```java
MongoSyncTargetSystem mongoTarget = new MongoSyncTargetSystem("user-db")
    .withDatabase(database)      // MongoDB-specific method
    .withMongoClient(client);    // MongoDB-specific method
```

**Generic methods** - All target systems (including DefaultTargetSystem) support generic dependency injection:
```java
DefaultTargetSystem kafkaTarget = new DefaultTargetSystem("events")
    .addDependency(kafkaProducer)
    .addDependency("notification-service", notificationService)
    .setProperty("batch.size", 1000);
```

This flexibility allows DefaultTargetSystem to inject any dependencies needed for non-transactional systems, while specialized target systems provide convenience methods for their common dependencies.

### Global dependencies

You can register dependencies globally to make them available to all ChangeUnits:

```java
Flamingock.builder()
    .addDependency(userService)
    .addDependency(emailService)
    .addDependency(configurationProperties)
    .addTargetSystems(mongoTarget)
    .build();
```

### Framework dependencies

When using frameworks like Spring Boot, Flamingock automatically accesses beans from the framework container:

```java
@Service
public class UserService {
    // This service is automatically available to ChangeUnits
}
```

:::warning
Remember that target system contexts are isolated. Dependencies in one target system aren't available to ChangeUnits in another target system.
:::

## Best practices

### Scope dependencies appropriately
- **Target system specific**: System connectors (DB, Kafka, S3, etc.), system-specific configurations
- **Global**: Shared services, utilities, application-wide configuration
- **Framework**: Let Spring manage beans, services, and repositories


**Key takeaway**: Flamingock's hierarchical dependency resolution provides flexibility while maintaining clear separation of concerns. Use target system contexts for system-specific dependencies and global context for shared resources.

---

// File: flamingock-library-config/lock

# Lock

Flamingock uses a distributed lock to ensure that changes are only applied **once and only once**, even when multiple instances of your application start simultaneously in a distributed system.

The lock mechanism is **mandatory** and is stored in your configured audit store (e.g., MongoDB, DynamoDB).


## Configurable properties

| Property                             | Default          | Description                                                                         |
|--------------------------------------|------------------|-------------------------------------------------------------------------------------|
| `lockAcquiredForMillis`              | `60000` (1 min)  | Time the lock remains valid once acquired. Automatically released if not refreshed. |
| `lockQuitTryingAfterMillis`          | `180000` (3 min) | How long to retry acquiring the lock if another instance holds it.                  |
| `lockTryFrequencyMillis`             | `1000` (1 sec)   | Interval between attempts while waiting for the lock.                               |
| `throwExceptionIfCannotObtainLock`   | `true`           | Whether Flamingock should fail if the lock can't be acquired.                       |
| `enableRefreshDaemon`                | `true`           | Whether to run a background thread that periodically extends the lock.              |


## Why locking matters

In distributed systems, multiple app instances may start simultaneously — but only **one** should apply pending changes. Flamingock uses locking to:

- Prevent race conditions
- Ensure consistent and safe state transitions
- Guarantee single execution of each change

:::info
If no pending changes exist, the lock is not acquired and startup proceeds normally.
:::

## Refresh Daemon (safety net)

The **refresh daemon** is a background thread that extends the lock before it expires.  
It’s critical for **long-running changes** that might exceed the lock duration.

Without the daemon:

- A long-running change (e.g., 90s) could outlive a default lock (e.g., 60s)
- Another instance might acquire the lock prematurely, causing conflict

:::note
By default, Flamingock uses proxy-based injection guards. Before executing any injected dependency, Flamingock verifies that the lock is still valid.
:::

If you're injecting **non-critical components** (e.g., a local list or stateless helper), you can annotate them with `@NonLockGuarded` to avoid the proxy overhead.


## Configuration Examples

### Builder
```java
FlamingockStandalone
  .setLockAcquiredForMillis(120000)
  .setLockQuitTryingAfterMillis(300000)
  .setLockTryFrequencyMillis(2000)
  .setThrowExceptionIfCannotObtainLock(true)
  .setEnableRefreshDaemon(true)
  ...
```


## When to tweak Lock settings

Most projects can use the default configuration. You may need to adjust values if:

- You expect **long-running changes** (increase `lockAcquiredForMillis`)
- You run **many app instances** and want to reduce startup wait (decrease `lockTryFrequencyMillis`)
- You want Flamingock to **fail fast** if it can't acquire a lock (keep `throwExceptionIfCannotObtainLock` as `true`)


## ✅ Best Practices

- Keep the refresh daemon **enabled**, especially for distributed or slow-processing environments
- Avoid setting `lockAcquiredForMillis` too short if any changes might run longer
- Use `@NonLockGuarded` sparingly — only when you're sure no side-effects will occur

[//]: # (TODO: Add "🛠 Troubleshooting" section)

---

// File: flamingock-library-config/transactions

# Transactions

Flamingock provides intelligent transaction management that adapts to your target systems' capabilities. Understanding when and how changes are executed transactionally is key to building reliable system evolution.

## How Flamingock handles transactions

Flamingock's transaction handling is determined by the **target system's capabilities**, not just the `transactional` flag. The behavior differs fundamentally between transactional and non-transactional target systems.

### 🔄 Transactional target systems
**Examples**: PostgreSQL, MySQL, MongoDB, SQL databases, DynamoDB, Couchbase

These systems support native transaction capabilities:

**When `transactional = true` (default)**:
- Execution runs within a native database transaction
- **On failure**: Automatic rollback using database's native transaction mechanism
- Session/connection managed automatically by Flamingock
- `@RollbackExecution` used only for manual operations (CLI undo)

**When `transactional = false`**:
- Execution runs without transaction
- **On failure**: Safety through compensation logic (@RollbackExecution)
- Useful for DDL operations or large bulk operations that exceed transaction limits

### ⚡ Non-transactional target systems
**Examples**: Kafka, S3, REST APIs, file systems, message queues

These systems have no native transaction support:

**The `transactional` flag is ignored** - behavior is always the same:
- Execution runs normally (no native transaction possible)
- **On failure**: Safety through compensation logic (@RollbackExecution)
- Safety relies entirely on idempotent operations and rollback methods

### Behavior summary table

| Target System Type | `transactional = true` (default) | `transactional = false` |
|---------------------|-----------------------------------|-------------------------|
| **Transactional** | Native transaction rollback on failure | `@RollbackExecution` on failure |
| **Non-transactional** | **Flag ignored** - `@RollbackExecution` on failure | **Flag ignored** - `@RollbackExecution` on failure |

## Best practices

### Always provide @RollbackExecution
- **Transactional systems with `transactional = true`**: Used for manual rollback operations (CLI undo)
- **Transactional systems with `transactional = false`**: Called automatically on failure
- **Non-transactional systems**: Always called automatically on failure (flag ignored)
- **All cases**: Essential for complete change management

### Use appropriate transactionality
- **Keep default `transactional = true`** for regular data changes on transactional systems
- **Use `transactional = false`** only when necessary on transactional systems (DDL, bulk operations)
- **For non-transactional systems**: The flag doesn't matter - design idempotent operations and robust rollback logic

**Key takeaway**: Flamingock's transaction behavior is determined by your target system's capabilities. For transactional systems, the `transactional` flag controls failure handling (native rollback vs @RollbackExecution). For non-transactional systems, the flag is ignored and @RollbackExecution is always used.

---

// File: flamingock-library-config/additional-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Additional configuration

This section includes additional settings for customizing defaults and adding contextual information to your Flamingock setup. 

| Setting         | Purpose                                      | Default            |
|-----------------|-----------------------------------------------|--------------------|
| `metadata`      | Attach tags and labels for audit tracking     | _empty map_        |
| `defaultAuthor` | Used when no author is specified in a change  | `"default_author"` |
| `enabled`       | Globally enable/disable Flamingock            | `true`             |

:::note
These options can currently be defined using the Flamingock builder. Support for config file (outside Spring Boot) will be added in a future release
:::

## Metadata

Flamingock provides a Metadata object - which is a flexible `Map<String, Object>` that allows you to attach custom information to your Flamingock process.

The metadata is stored as part of the **audit log**, and can be used for labeling, traceability, and future reporting.

### Use Cases
You can use metadata to:
- Tag executions by **team**, **service**, or **region**
- Include a **deployment ID**, **build number**, or **triggering user**
- Attach **comments** or **labels** for easier traceability

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
metadata:
  owner: platform-team
  triggeredBy: ci-cd-pipeline
  notes: initial deployment setup
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
Map<String, Object> metadata = new HashMap<>();
metadata.put("owner", "platform-team");
metadata.put("triggeredBy", "ci-cd-pipeline");

FlamingockStandalone
.setMetadata(metadata)
...
```
    </TabItem>
</Tabs>


### Default Author

If a change unit does not specify an `author`, Flamingock will use this value as the fallback.

- Applies to both **code-based** and **template-based** changes
- Default value: `"default_author"`
- Ignored if the change itself defines an explicit author

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
defaultAuthor: antonio
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
FlamingockStandalone
        .setDefaultAuthor("antonio")
```
    </TabItem>
</Tabs>


## Disable flamingock process

This global toggle allows you to enable or disable Flamingock.

- If set to `false`, Flamingock will **not run**
- A log message will appear in the **application logs**, indicating that Flamingock is disabled
- No changes will be applied and no audit entries will be created

:::note 
Useful in test environments, local runs, or cases where you want to conditionally skip changes.
:::

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
enabled: false
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
FlamingockStandalone
  .setEnabled(false)
```
    </TabItem>
</Tabs>

---

// File: flamingock-library-config/events

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Events

This guide provides a comprehensive explanation of how Flamingock events function.

## Introduction

Flamingock utilizes events to notify the main application about the current state of the Flamingock process, as well as the eventual outcome of its execution.

The event-handling approach differs significantly depending on the type of runner being used:

- For Spring-based applications, Flamingock leverages the ```ApplicationEventPublisher```, which is provided during the build process.
- For standalone applications, Flamingock requires an explicit event handler to be defined at build time.

Flamingock offers event handling capabilities for both Pipelines and Stages.

## Type of events

Flamingock emits three types of events:

- **Start Event**: Triggered just before the migration process begins, following successful validation.
- **Success Event**: Emitted upon successful completion of the migration. This indicates that no unhandled exceptions occurred, or that any errors were either properly handled or associated changeLogs were marked with 'Fail' as false.
- **Failure Event**: Emitted when a change log fails and the failure is not handled, as described above.

:::warning
The Success and Failure events are mutually exclusive, only one of them will be raised for a given migration execution.
:::

## Getting started with events

Each runner's documentation page provides the necessary information for using events in accordance with that runner's specific implementation.

## Standalone basic example

In the Flamingock builder, you must configure the events you intend to use and implement the corresponding listeners.

### Builder

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
      FlamingockStandalone.local()
          .setPipelineStartedListener(new PipelineStartedListener())
          .setPipelineCompletedListener(new PipelineCompletedListener())
          .setPipelineFailedListener(new PipelineFailedListener())
          .setStageStartedListener(new StageStartedListener())
          .setStageCompletedListener(new StageCompletedListener())
          .setStageFailedListener(new StageFailedListener())
          .build()
          .run();
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
      FlamingockStandalone.local()
          .setPipelineStartedListener(PipelineStartedListener())
          .setPipelineCompletedListener(PipelineCompletedListener())
          .setPipelineFailedListener(PipelineFailedListener())
          .setStageStartedListener(StageStartedListener())
          .setStageCompletedListener(StageCompletedListener())
          .setStageFailedListener(StageFailedListener())
          .build()
          .run()
  ```
  </TabItem>
</Tabs>
  
### Listener

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
    public class StageCompletedListener implements Consumer<IStageCompletedEvent> {

    public static int executed = 0;
    @Override
    public void accept(IStageCompletedEvent iStageCompletedEvent) {
        executed++;
    }
    }
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
class StageCompletedListener : (IStageCompletedEvent) -> Unit {

    companion object {
        var executed = 0
    }

    override fun invoke(iStageCompletedEvent: IStageCompletedEvent) {
        executed++
    }
}
  ```
  </TabItem>
</Tabs>

## Spring-based basic example

### Listeners

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
    ```java
      @Bean
      public PipelineStartedListener startFlamingockListener() {
          return new PipelineStartedListener();
      }

      @Bean
      public PipelineCompletedListener successFlamingockListener() {
          return new PipelineCompletedListener();
      }

      @Bean
      public PipelineFailedListener sailedFlamingockListener() {
          return new PipelineFailedListener();
      }

      @Bean
      public StageStartedListener stageStartedListener() {return new StageStartedListener();}

      @Bean
      public StageCompletedListener stageCompletedListener() {return new StageCompletedListener();}

      @Bean
      public StageFailedListener stageFailedListener() {return new StageFailedListener();}
    ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin" default>
    ```kotlin
        @Bean
        fun startFlamingockListener(): PipelineStartedListener {
            return PipelineStartedListener()
        }

        @Bean
        fun successFlamingockListener(): PipelineCompletedListener {
            return PipelineCompletedListener()
        }

        @Bean
        fun sailedFlamingockListener(): PipelineFailedListener {
            return PipelineFailedListener()
        }

        @Bean
        fun stageStartedListener(): StageStartedListener {
            return StageStartedListener()
        }

        @Bean
        fun stageCompletedListener(): StageCompletedListener {
            return StageCompletedListener()
        }

        @Bean
        fun stageFailedListener(): StageFailedListener {
            return StageFailedListener()
        }
    ```
  </TabItem>
</Tabs>

---

// File: frameworks/graalvm

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# GraalVM support

Flamingock provides **first-class support for GraalVM native images**, enabling your application to compile into fast, self-contained executables without sacrificing change tracking, rollback, or template support.

This page explains how to generate a GraalVM native image for a Flamingock-enabled application, using the **reflection metadata** produced by the **annotation processor** and Flamingock’s built-in GraalVM **registration feature**.


## How it works

When building your application, Flamingock's annotation processor:

- Scans for all annotated code-based changes (`@ChangeUnit`)
- Discovers template-based changes from `sourcesPackage` and `resourcesDir`
- Generates metadata files containing all required classes for reflection

At native image generation time, Flamingock’s **GraalVM feature** picks up these files and registers the required types with GraalVM, so they’re available at runtime.

:::tip
Learn more about the basics of GraalVM native image compilation in the [GraalVM Native Image basics guide](https://www.graalvm.org/latest/reference-manual/native-image/basics/).
:::


## Step-by-step setup

### 1. Add Flamingock GraalVM dependency

<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```kotlin
implementation("io.flamingock:flamingock-graalvm:$flamingockVersion")
```

</TabItem>
<TabItem value="maven" label="Maven">

```xml
<dependencies>
  <dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-graalvm</artifactId>
    <version>${flamingock.version}</version>
  </dependency>
</dependencies>
```

</TabItem>
</Tabs>


### 2. Add plugin management (only for Gradle)

If using Gradle, ensure your `settings.gradle.kts` includes:

```kotlin
pluginManagement {
    repositories {
        mavenLocal()
        gradlePluginPortal()
        mavenCentral()
    }
}
```


### 3. Add GraalVM resource config

Create a file named `resource-config.json` in your project root:

```json
{
  "resources": {
    "includes": [
      { "pattern": "META-INF/flamingock/metadata.json" }
    ]
  }
}
```

:::info
This file declares which resource files should be accessible to your native image. You can add other application-specific resources here as needed.

See the [GraalVM resource configuration documentation](https://www.graalvm.org/latest/reference-manual/native-image/metadata/#resources) for more details.
:::


### 4. Build the application

```bash
./gradlew clean build
```

#### Expected build output

During the build process, Flamingock will emit logs similar to the following — indicating successful annotation processing and metadata generation.

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>



### 5. Create the native image

```bash
native-image \
  --no-fallback \
  --features=io.flamingock.graalvm.RegistrationFeature \
  -H:ResourceConfigurationFiles=resource-config.json \
  -H:+ReportExceptionStackTraces \
  --initialize-at-build-time=org.slf4j.simple \
  -jar build/libs/your-app.jar
```

#### What these options do:

- `--features=io.flamingock.graalvm.RegistrationFeature`: Registers all Flamingock-related classes for reflection using metadata gathered during build time.
- `-H:ResourceConfigurationFiles=resource-config.json`: Informs GraalVM of required static resource files to include.
- `--initialize-at-build-time`: – **Optional**. Build‑time init for listed classes/packages (freeze static state; faster start; avoids early reflection/I/O). Flamingock does not require specific entries. Use only if a library benefits (e.g., logging). Example: --initialize-at-build-time=org.slf4j.impl,org.slf4j.simple. Omit if unsure.

#### Expected native image output

When creating the native image, you should see log output from Flamingock's GraalVM `RegistrationFeature`, confirming that Flamingock successfully scanned and registered internal classes, templates, system modules, and user-defined change units. 

The actual output may differ slightly depending on the modules you’ve included, but it should look similar to the following:
<details>
<summary>Click to see the expected logs</summary>
```
 - io.flamingock.graalvm.RegistrationFeature
[Flamingock] Starting GraalVM classes registration
[Flamingock] Starting registration of internal classes
    Registering class: io.flamingock.core.task.TaskDescriptor 
    Registering class: io.flamingock.core.task.AbstractTaskDescriptor 
    Registering class: io.flamingock.core.preview.PreviewPipeline 
    Registering class: io.flamingock.core.preview.PreviewStage 
    Registering class: io.flamingock.core.preview.CodePreviewChangeUnit 
    Registering class: io.flamingock.core.preview.CodePreviewLegacyChangeUnit 
    Registering class: io.flamingock.core.preview.PreviewMethod 
    Registering class: io.flamingock.core.api.template.ChangeTemplateConfig 
    Registering class: io.flamingock.core.preview.TemplatePreviewChangeUnit 
    Registering class: io.flamingock.core.pipeline.Pipeline 
    Registering class: io.flamingock.core.pipeline.LoadedStage 
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedTask 
    Registering class: io.flamingock.core.task.loaded.AbstractReflectionLoadedTask 
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedChangeUnit 
    Registering class: io.flamingock.core.task.loaded.CodeLoadedChangeUnit 
    Registering class: io.flamingock.core.task.loaded.TemplateLoadedChangeUnit 
    Registering class: java.nio.charset.CoderResult 
[Flamingock] Completed internal classes
[Flamingock] Starting registration of templates
    Registering class: io.flamingock.core.api.template.TemplateFactory 
    Registering class: io.flamingock.core.api.template.ChangeTemplate 
    Registering class: io.flamingock.core.api.template.AbstractChangeTemplate 
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplate 
    Registering class: io.flamingock.template.mongodb.model.MongoOperation 
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplateConfig 
[Flamingock] Completed templates
[Flamingock] Starting registration of system modules
    Registering class: io.flamingock.core.engine.audit.importer.changeunit.MongockImporterChangeUnit 
    Registering class: io.flamingock.core.engine.audit.importer.ImporterModule 
[Flamingock] Completed system modules
[Flamingock] Starting registration of user classes
    Registering class: io.flamingock.changes._1_create_clients_collection_change 
    Registering class: io.flamingock.changes._2_insertClientFederico_change 
    Registering class: io.flamingock.changes._3_insert_client_jorge 
[Flamingock] Completed user classes
[Flamingock] Completed GraalVM classes registration
```
</details>

:::tip
For more information on image creation and options, refer to the [GraalVM build overview documentation](https://www.graalvm.org/latest/reference-manual/native-image/overview/Build-Overview/).
:::


### 6. Run the native image

```bash
./your-app
```


## Example project

We have built a [complete example project for GraalVM](https://github.com/flamingock/flamingock-examples/tree/master/graalvm) that demonstrates:
- A working Flamingock configuration with GraalVM
- Sample change units
- Proper resource configuration
- Native image generation process

You can use this example as a reference implementation while following the steps in this guide.

---

// File: frameworks/springboot-integration/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Spring Boot integration

Flamingock integrates seamlessly with Spring Boot, offering a powerful and flexible setup for managing your change units in Spring-based applications.

This integration leverages Spring Boot’s features—such as dependency injection, profiles, event publishing, and property configuration—to provide a streamlined and production-ready experience.


## Why integrate Flamingock with Spring Boot?

Using Flamingock with Spring Boot allows you to:

- Inject Spring-managed beans directly into change units
- Configure Flamingock via Spring Boot's native configuration files
- Use Spring profiles to control when specific change units run
- Receive execution lifecycle events using `ApplicationEventPublisher`
- Choose between Spring Boot lifecycle hooks (`ApplicationRunner` or `InitializingBean`) to run Flamingock.


## Two setup approaches

Flamingock offers **two ways to integrate with Spring Boot**, depending on how much control you want over the configuration and lifecycle.

### Builder-based setup (manual)

This approach gives you full control and uses the standard Flamingock builder with `@EnableFlamingock(setup = SetupType.BUILDER)`.  
You manually inject the required Spring Boot components(ApplicationContext and ApplicationEventPublisher) as well as any Flamingock core configuration.

In addition, you can register other dependencies manually — these will take precedence over beans from the Spring context when resolving what to inject into change units.

This is recommended for advanced users or highly customized environments.

> See: [Builder-based setup](./builder-based-setup.md)


### Automatic setup

This is the simplest way to enable Flamingock in Spring Boot.  
Just annotate any class with `@EnableFlamingock` (commonly your main application class), and Flamingock will:

- Auto-detect the application context and event publisher
- Read configuration from Spring Boot config files
- Automatically wire the `FlamingockRunner` bean
- Process the setup configuration from the annotation

Ideal for most users who prefer convention over configuration.

> See: [Automatic setup](./enable-flamingock-setup.md)


## Runner strategy: ApplicationRunner vs InitializingBean

Flamingock supports two strategies for executing its process during Spring Boot startup. You can control this via the `runnerType` property in your Spring configuration (`flamingock.runnerType`), or programmatically if using the manual builder.

### Comparison

|                                            | `ApplicationRunner`                                                        | `InitializingBean`                                                |
|--------------------------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------------|
| **Phase**                                  | After all beans are initialized — just before the app is marked as started | During bean initialization — before the app is considered started |
| **Context availability**                   | ✅ Full — all Spring beans and profiles available                           | ⚠️ Limited — not all beans may be available                       |
| **Typical use case**                       | Most common — recommended for production environments                      | For lightweight internal logic or strict startup ordering         |
| **Events fully supported?**                | ✅ Yes                                                                      | ⚠️ Risky — context may not be fully ready                         |
| **Spring beans available in change units** | ✅ Yes                                                                      | ⚠️ May fail or be incomplete                                      |

### Startup failure behavior

If Flamingock encounters an error during execution — whether using `ApplicationRunner` or `InitializingBean` — the Spring Boot application **will fail to start**.

This is intentional: Flamingock runs before the application is marked as ready. In deployment platforms such as **Kubernetes**, a failure at this stage will:

- Prevent the container from reaching a *Ready* state
- Trigger restart policies, health checks, or rollbacks as configured
- Ensure that the system is never exposed in a partially initialized or inconsistent state

This behavior ensures your application only starts when all change units have been applied successfully.


## Dependency

To use the Spring Boot integration, add the appropriate module for your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Flamingock provides two editions for Spring Boot integration.

### Why are there two Spring Boot integration artifacts?

The only difference is the Java version they target:

- `flamingock-springboot-integration` — requires JDK 17 or newer.
- `flamingock-springboot-integration-v2-legacy` — kept for teams still on Spring Boot 2 who must stay on JDK 8 – 11.

Choose the artifact that matches the JDK level of your application today; switching later is as simple as changing the dependency.

| Package Name                                   | Spring Boot Version  |
|------------------------------------------------|----------------------|
| `flamingock-springboot-integration`            | [3.0.0, 4.0.0)       |
| `flamingock-springboot-integration-v2-legacy`  | [2.0.0, 3.0.0)       |


## :white_check_mark: Best practices

Consider the following recommendations to get the most out of Flamingock’s Spring Boot integration:

- **Prefer `ApplicationRunner` as your runner strategy**  
  It ensures Flamingock runs after the application context is fully initialized, giving it access to all beans, profiles, and configuration. It also integrates more safely with event publishing and external monitoring tools like Actuator or Prometheus.

- **Use automatic setup (`@EnableFlamingock`) for simpler setups**  
  Unless you have advanced needs (such as injecting non-Spring-managed dependencies), the automatic setup provides a clean and reliable integration path.

- **Use Spring profiles to scope change units**  
  Profiles let you control when specific change units execute, avoiding the need for environment-specific pipelines.

- **Avoid manual execution unless absolutely necessary**  
  Letting Spring handle the execution via `ApplicationRunner` or `InitializingBean` ensures Flamingock runs at the appropriate time in your application lifecycle.

- **Register custom platform components using `.addDependency(...)` only when required**  
  Most applications using automatic setup will not need to register components manually.

---

// File: frameworks/springboot-integration/enable-flamingock-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Automatic Setup

Flamingock provides a convenient automatic integration with Spring Boot using the `@Flamingock` annotation. This setup is ideal when you want Flamingock to automatically detect and wire required components without writing explicit builder logic.


## Import the springboot integration library

Add the appropriate Flamingock Spring Boot integration dependency, depending on your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x (Spring 6.x)
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (Spring 5.x, legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x (Spring 6.x) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (Spring 5.x, legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Check [Version Compatibility](introduction.md#version-compatibility)

## Configure setup and activate integration

To activate the integration, add `@EnableFlamingock` to any class in your application (commonly on your main class or a configuration class):

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@SpringBootApplication
public class MyApplication {
  public static void main(String[] args) {
    SpringApplication.run(MyApplication.class, args);
  }
}
```

The `@EnableFlamingock` annotation enables automatic Spring Boot integration, which:

- Detect and use Spring’s `ApplicationContext` and `ApplicationEventPublisher`
- Loads Flamingock configuration directly from your Spring Boot config file
- Automatically configures the runner (e.g., ApplicationRunner or InitializingBean)
- Processes the setup configuration from the annotation


## Providing configuration

Runtime configuration is defined using standard Spring Boot configuration files. Use the `flamingock` section for all core and edition-specific options.

```yaml
flamingock:
  lockAcquiredForMillis: 1200
  runnerType: InitializingBean
  # other configuration...
```

:::info
If the `runnerType` property is not provided, Flamingock defaults to using `ApplicationRunner`.
:::


## Next steps

- Want full control over the builder? See [Builder-based setup](builder-based-setup.md)
- Explore [Spring Boot profile support](profiles.md)
- Learn about [Flamingock lifecycle events](../../flamingock-library-config/events.md)

---

// File: frameworks/springboot-integration/builder-based-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Flamingock supports manual integration with Spring Boot using the same builder API shared with standalone setups. 

This unified approach makes it easy to switch between environments without changing your integration logic, while giving you full control over how Flamingock is initialized and executed within your application.

It’s especially useful when integrating Flamingock alongside other frameworks, when you need fine-grained control over the setup process, or when you want to override or prioritize specific dependencies manually.


## Import the springboot integration library

Add the appropriate Flamingock Spring Boot integration dependency, depending on your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Check [Version Compatibility](introduction.md#version-compatibility)

## Configure setup and build Flamingock manually

With the manual setup, you first need to configure Flamingock using `@EnableFlamingock` annotation with `setup = SetupType.BUILDER`, then manually configure and run Flamingock using the builder API.

### 1. Configure the annotation

```java
@EnableFlamingock(
    setup = SetupType.BUILDER,
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@Configuration
public class FlamingockConfig {
    // Configuration class
}
```

### 2. Manual builder configuration

With the manual setup, you are responsible for configuring and running Flamingock using the builder API. This includes:

- Providing your configuration (e.g., lock settings, metadata) directly via the builder
- Registering the required **platform components** using `.addDependency(...)`
- `ApplicationContext`
- `ApplicationEventPublisher`

```java
FlamingockBuilder builder = Flamingock
    .setLockAcquiredForMillis(120000) // example config
    .addDependency(applicationContext)
    .addDependency(applicationEventPublisher);
```

:::info
Platform components are registered using the same `.addDependency(...)` method used for change unit dependencies.  
For details, see the [Context and dependencies](../../flamingock-library-config/context-and-dependencies.md) page.
:::
## Overriding Spring-provided dependencies
When using the builder-based setup, Flamingock will attempt to resolve dependencies using the Spring context.

However, if you manually register a dependency via `.addDependency(...)`, that dependency will take precedence over anything resolved from the Spring context. This gives you fine-grained control when you want to:

- Override a Spring-managed bean with a custom instance
- Inject mock or test-specific versions of services
- Provide external or non-Spring-managed components directly

```java
builder
  .addDependency(customClientService) // Overrides Spring's bean of same type
  .addDependency(applicationContext); // Registers Spring context for base dependency injection
```
In a nutshell, Flamingock resolves dependencies using the following order:
- Manually added dependencies via .addDependency(...)
- Beans from the Spring context (if ApplicationContext was registered)


## Running Flamingock

Once you've configured the builder, you can choose how to execute Flamingock:

### Option 1: Run manually

You can run Flamingock manually:

```java
builder.build().run();
```

### Option 2: Expose as a Spring Bean

Alternatively, you can integrate Flamingock into the Spring Boot lifecycle by exposing it as an `ApplicationRunner` or `InitializingBean`:

```java
@Bean
public ApplicationRunner flamingockRunner() {
  return SpringbootUtil.toApplicationRunner(builder.build());
}
```

Or:

```java
@Bean
public InitializingBean flamingockRunner() {
  return SpringbootUtil.toInitializingBean(builder.build());
}
```

This ensures Flamingock executes automatically as part of the Spring Boot startup sequence.


## Next steps

**Want to avoid manual setup?** Explore the [Automatic Setup](./enable-flamingock-setup.md) for automatic integration with minimal code.

---

// File: frameworks/springboot-integration/profiles

# Spring Boot profiles

Flamingock supports **Spring Boot profiles** out of the box. This allows you to conditionally run specific change units depending on which profile(s) are active in your application.

This is useful for managing environment-specific changes, such as different initialization data for `dev`, `staging`, or `prod` environments.


## What is a Spring profile?

Spring profiles provide a way to segregate parts of your application configuration and behavior based on the active environment.

You can define profiles like `dev`, `test`, `staging`, or `prod`, and activate **one or more** of them using any of the following methods:

- Inside `application.yml` or `application.properties`:
  ```yaml
  spring:
    profiles:
      active: dev,staging
  ```

- Using profile-specific configuration files like `application-dev.yml` or `application-prod.yml`

- As command-line arguments:
  ```bash
  --spring.profiles.active=dev,staging
  ```

- Through environment variables:
  ```bash
  SPRING_PROFILES_ACTIVE=dev,staging
  ```

When multiple profiles are active, Flamingock evaluates each change unit against **all active profiles**, and includes it if any match.


## How Flamingock uses profiles

Flamingock automatically retrieves the active profiles from Spring’s `ApplicationContext`. You don’t need to manually provide them.

You can then annotate any change unit with Spring’s native `@Profile` annotation to control whether it runs:

```java
@ChangeUnit(id = "add-test-data", order = "001")
@Profile("dev")
public class AddTestDataChangeUnit {
  // will only run if "dev" profile is active
}
```

Flamingock applies the same logic as Spring Boot when evaluating whether a change unit should run.


## Multiple profiles

You can declare multiple profiles in a single `@Profile` expression:

```java
@Profile({"dev", "staging"})
```

This change unit will run if **any** of the listed profiles is active.


## Excluding profiles

To exclude a change unit from a specific profile, you can use Spring Expression Language (SpEL):

```java
@Profile("!prod")
```

This will run the change unit in **all environments except `prod`**.


## ✅ Best practices

- Use profiles to isolate test data, preview features, or tenant-specific migrations
- Avoid mixing profile-specific logic inside a single change unit — split them into separate classes
- Keep profile names consistent across your team and environments (e.g., use `dev` everywhere, not `development`, `dev-env`, etc.)
- Consider grouping related change units under a shared profile for easier activation

---

// File: overview/Introduction

# Introduction

Flamingock is a change management framework that ensures your distributed systems evolve safely and consistently. It applies versioned, auditable changes to any target system (message brokers, APIs, cloud services, databases, and any other external service) with guaranteed safety and recovery mechanisms.

## Core principles

### Safety by default
When Flamingock cannot guarantee a safe outcome, it stops and requires manual intervention. This prevents silent data corruption and ensures predictable deployments.

### Complete auditability
Every change execution is tracked in an audit store, providing a complete history of what was applied, when, by whom, and with what result.

### Recovery strategies
Configurable recovery mechanisms determine how Flamingock handles failures:
- **Manual intervention** (default): Stops on failure and requires human review
- **Always retry**: Automatically retries idempotent operations  


## Target systems

Flamingock can apply changes to any external service your application interacts with. Examples include:
- **Message brokers**: Kafka, RabbitMQ, AWS SQS
- **Cloud services**: S3, Lambda, API Gateway
- **APIs**: REST endpoints, GraphQL schemas
- **Configuration systems**: Feature flags, vault secrets
- **Databases**: SQL (PostgreSQL, MySQL) and NoSQL (MongoDB, DynamoDB)
- **And any other external system** your application needs to evolve

## Architecture overview

### ChangeUnits
The fundamental unit of change. Each ChangeUnit:
- Has a unique identifier and execution order
- Targets a specific system
- Contains execution and rollback logic
- Is executed exactly once

### Audit store vs target system
- **Audit store**: Where Flamingock tracks execution history (managed by Flamingock)
- **Target system**: Where your business changes are applied (any external service your application interacts with)

### Execution flow
1. Application startup triggers Flamingock
2. Flamingock discovers all ChangeUnits
3. Checks audit store for pending changes
4. Acquires distributed lock
5. Executes changes in order
6. Records results in audit store
7. Handles failures according to recovery strategy  


## Next steps
- [Quick start](quick-start.md) - Minimum setup to run Flamingock
- [Core concepts](core-concepts.md) - Detailed explanation of key concepts
- [Audit store vs target system](audit-store-vs-target-system.md) - Understanding the dual-system architecture

---

// File: overview/quick-start

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Quick start

This guide shows you the minimum setup required to get Flamingock running. In just a few steps you will have it integrated in your application.

Let's walk through a simple scenario: evolving your inventory service with a few typical changes:

- Add a new column to a MySQL database  
- Provision a new S3 bucket for product images  
- Create a Kafka topic for stock updates  

Even in this basic example, Flamingock ensures all these changes are applied **safely, consistently, and audibly** at your application startup.  
This guide walks you through the process in 5 simple steps.


## 1. Set up Flamingock in your project

Add Flamingock to your build:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

annotationProcessor("io.flamingock:flamingock-processor:$flamingockVersion")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingockVersion}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- Annotation processor -->
<build>
  <plugins>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <version>3.11.0</version>
      <configuration>
        <annotationProcessorPaths>
          <path>
            <groupId>io.flamingock</groupId>
            <artifactId>flamingock-processor</artifactId>
            <version>${flamingockVersion}</version>
          </path>
        </annotationProcessorPaths>
      </configuration>
    </plugin>
  </plugins>
</build>
```

  </TabItem>
</Tabs>



## 2. Define your first ChangeUnits

Each ChangeUnit represents a single change.  
For our example, we'll define three:

- **MySQL**: Add a column `category` to products
- **S3**: Create a `product-images` bucket  
- **Kafka**: Create a `stock-updates` topic

ChangeUnits can be:
- **Code-based**: Java classes with annotations
- **Template-based**: YAML files using reusable templates

<Tabs groupId="change">
  <TabItem value="template_based" label="Template based" default>

```yaml
id: add-product-category
author: team
order: "001"
targetSystem: mysql-inventory
template: sql-template
execution: |
  ALTER TABLE products ADD COLUMN category VARCHAR(255)
rollback: |
  ALTER TABLE products DROP COLUMN category
```

  </TabItem>
  <TabItem value="code_based" label="Code based">

```java
@TargetSystem("aws-s3")
@ChangeUnit(id = "create-s3-bucket", order = "002", author = "team")
public class _002_CreateS3Bucket {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("product-images")
        .createBucketConfiguration(
            CreateBucketConfiguration.builder()
                .locationConstraint(BucketLocationConstraint.EU_WEST_1)
                .build())
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("product-images")
        .build());
  }
}
```

  </TabItem>
</Tabs>

For more details, see [Core concepts](core-concepts.md).


## 3. Create target systems

Target systems represent the external systems Flamingock will apply your changes to.  
They are configured in the builder and shared across ChangeUnits.

For our example:
- A MySQL database (`mysql-inventory`)
- An S3 bucket service (`aws-s3`)  
- A Kafka cluster (`kafka`)

```java
SqlTargetSystem sql = new SqlTargetSystem("mysql-inventory").withDatasource(ds);
DefaultTargetSystem s3 = new DefaultTargetSystem("aws-s3");
DefaultTargetSystem kafka = new DefaultTargetSystem("kafka");
```

See [Target systems](../target-systems/introduction.md) for more details.


## 4. Configure stages

Flamingock organizes your changes in stages.  
Most applications only need one stage:

```java
@EnableFlamingock(
  stages = {
    @Stage(location = "com.company.inventory.changes")
  }
)
public class App {}
```

- **location**: Where Flamingock should look for changes (package or resources)
- **name**: Optional — defaults to the location name

See [Stages](../flamingock-library-config/setup-and-stages.md) for more details and advanced setups.


## 5. Configure Flamingock runtime

Finally, configure Flamingock before running your application.

- **Community Audit Stores**: Set your audit store (MongoDB, DynamoDB, Couchbase, etc.) in the builder

- **Cloud Edition** (coming soon): Provide your API token, service name, and environment

<Tabs groupId="edition">
  <TabItem value="community" label="Community" default>

```java
FlamingockStandalone
  .setAuditStore(new MongoSyncAuditStore(mongoClient, mongoDatabase))
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
  <TabItem value="cloud" label="Cloud (coming soon)">

```java
FlamingockStandalone
  .setApiToken("your-flamingock-api-token") 
  .setEnvironment("dev")
  .setService("inventory-service")
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
</Tabs>


## 6. Run your application

When your service starts, Flamingock automatically:

1. Discovers your ChangeUnits
2. Checks pending changes  
3. Executes them safely in order
4. Records everything in the audit store

**If Flamingock cannot guarantee a safe outcome, it stops and alerts you. Safety first.**

### Example output

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>


## Next steps

- [Spring Boot integration](../frameworks/springboot-integration/introduction.md)
- [Configuration options](../flamingock-library-config/setup-and-stages.md)
- [Recovery and safety](../safety-and-recovery/recovery-strategies.md)

---

// File: overview/core-concepts

# Core concepts

## ChangeUnits
**ChangeUnits** are the fundamental building blocks of Flamingock's Change-as-Code architecture. They represent atomic, versioned changes applied to target systems with complete safety guarantees and audit capabilities.

Each ChangeUnit includes:
- **Unique identity**: ID, order, and metadata for tracking
- **Target system**: Where the changes is applied to
- **Execution logic**: The actual change implementation
- **Rollback capability**: Compensation logic for governance and undo operations
- **Recovery strategy**: Configurable behavior for handling failures

ChangeUnits can be implemented in two forms:
- **Code-based**: Java classes with annotations that contain the change logic
- **Template-based**: Declarative low-code approach using YAML configurations

For a deeper dive around ChangeUnits, see the [ChangeUnits](../change-units/anatomy-and-structure.md) section.


## Templates
Templates provide a reusable layer on top of ChangeUnits for common change patterns. When you have multiple changes that share similar logic (for example, executing SQL statements), templates allow you to abstract that common logic and reuse it.

With templates, you create multiple ChangeUnits using a declarative, low-code approach. Each ChangeUnit uses a template and passes its specific configuration. For example, an SQL template receives the SQL statement as configuration, executes it, and handles errors consistently.

This approach is particularly useful for:
- Standardizing common operations across your codebase
- Reducing boilerplate code
- Enabling non-developers to define changes through configuration

For more information about templates, see the [Templates](../templates/templates-introduction.md) section.


## Recovery strategies

Recovery strategies define how Flamingock responds when a ChangeUnit fails during execution. They determine whether the system should stop and wait for manual intervention or automatically retry the operation.

Flamingock provides two main strategies:
- **Manual intervention** (default): Stops execution and requires human review when failures occur
- **Always retry**: Automatically retries the change on the next execution attempt

The choice of strategy depends on whether your changes are idempotent and how critical they are to your system's integrity.

For detailed configuration and implementation, see the [Recovery strategies](../safety-and-recovery/recovery-strategies.md) section.


## Audit store
The **audit store** is where Flamingock records metadata about change executions. Its purpose is to track which ChangeUnits have been executed, when they ran, and their outcomes. This ensures idempotency, enables rollbacks, and provides audit capabilities. The audit store is managed entirely by Flamingock - your code never directly interacts with it.
  :::info
  In Cloud Edition, the audit store is automatically provided - no configuration needed in your builder. Community Edition users must configure their own audit store.
  :::

## Target system  
The **target system** is where your actual business changes are applied. These are the systems your ChangeUnits modify - databases, message queues, APIs, configuration services, etc. Each ChangeUnit declares which target system it operates on.

For more details about how these systems work together, see the [Audit store vs target system](audit-store-vs-target-system.md) section.


## Transaction handling
Flamingock adapts its behavior based on the transactional capabilities of your target systems:

### Transactional target systems
Systems that support ACID transactions, such as MongoDB 4.0+, PostgreSQL, MySQL, or other transactional stores. When working with these systems, Flamingock can leverage native transaction support to ensure atomicity of changes. If a failure occurs mid-execution, the native rollback mechanism ensures no partial changes are left in the system.

### Non-transactional target systems
Systems like Kafka, S3, REST APIs, or file systems that don't support transactions. For these systems, Flamingock relies on explicit rollback methods and careful change design to maintain consistency. Recovery strategies become particularly important for handling failures in non-transactional contexts.

For implementation details, see the [Transactions](../flamingock-library-config/transactions.md) section.


## Stages
Stages organize your changes into logical groups within Flamingock's execution pipeline. By default, you work with a single stage that contains all your changes, ensuring they execute sequentially in a deterministic order.

Key characteristics:
- Changes within a stage execute sequentially with guaranteed order
- Most applications only need a single stage
- Multiple stages can be used for modular architectures, but execution order between stages is not guaranteed
- Each stage defines where to find its changes (package or directory location)

For detailed information about stages and advanced configurations, see the [Setup and stages](../flamingock-library-config/setup-and-stages.md) section.

---

// File: overview/audit-store-vs-target-system

# Target systems vs audit store
*Understanding Flamingock's dual-system design for enterprise safety*

Flamingock's architecture separates business changes from execution tracking through two distinct system types. This separation is fundamental to Flamingock's safety guarantees and competitive advantages.


## The dual-system architecture

### Target systems: where changes are applied
**Target systems** are your business systems where actual changes happen:

- **Examples**: User database, Product catalog, Order management system, Kafka topics, S3 buckets, REST APIs
- **Purpose**: Store and process your business data and configurations
- **Modified by**: Your business logic through ChangeUnits
- **Configuration**: See [Target Systems](../target-systems/introduction.md) for technical setup

### Audit store: where execution is tracked  
**Audit store** is Flamingock's dedicated system for tracking what happened:

- **Examples**: Flamingock Cloud backend or dedicated audit table/collection in the user's database. 
- **Purpose**: Record execution history, compliance data, issue tracking
- **Modified by**: Flamingock framework automatically (never your code)
- **Configuration**: See [Audit Stores](../audit-stores/introduction.md) for technical setup


## Why this separation matters

### Enterprise safety benefits
1. **Complete Audit Trail**: Every change attempt is recorded regardless of business system failures
2. **Governance Separation**: Business data and compliance data have different access patterns
3. **Recovery Capabilities**: Operations team can resolve issues by reading audit state, not business data
4. **Compliance Independence**: Audit integrity is maintained even during business system issues


## Target system types

### Transactional target systems
Systems with native ACID transaction support (PostgreSQL, MySQL, MongoDB 4.0+):

**Safety and coordination:**
- **Community Audit Stores**: Reliable execution tracking and recovery capabilities
- **Cloud Edition**: Advanced coordination protocols ensure complete recoverability

### Non-transactional target systems
Systems without native transaction support (Kafka, S3, REST APIs, File Systems):

**Safety and coordination:**
- **Community Audit Stores**: Reliable execution tracking and rollback-based recovery
- **Cloud Edition**: Enhanced recoverability with custom validation options


## Audit store types

### Cloud Edition audit store
Flamingock Cloud provides a fully managed audit store with superior synchronization and recovery through advanced coordination protocols, real-time dashboards, advanced analytics, and multi-environment governance.

### Community Audit Stores audit store  
User-provided audit store (MongoDB, DynamoDB, Couchbase) that ensures complete execution tracking, prevents duplicate executions, and provides basic recovery capabilities. See [Audit stores](../audit-stores/introduction.md) for setup.



## How it works

```
     Your ChangeUnits:
     ┌──────────────────────────────────────────────────────────────────────────┐
     │ 1. Change[UpdateKafkaSchema] → Target System[Kafka Schema Registry]      │
     │ 2. Change[SeedKafkaEvents]   → Target System[Kafka Topics]               │
     │ 3. Change[AddUserStatus]     → Target System[User Database]              │
     └──────────────────────────────────────────────────────────────────────────┘
                                │
                                ▼
                    ┌───────────────────────┐
                    │      Flamingock       │
                    │    (Orchestrator)     │
                    └───────────────────────┘
                                │
                                │ Executes sequentially
                                │
                 ChangeUnit #1  │───────────────────────────┐
            (UpdateKafkaSchema) │                           │
                                │                           │
                                │             ┌─────────────┴────────────┐
                                │             ▼                          ▼
                                │     ┌─────────────────────┐      ┌──────────────┐
                                │     │   Target System:    │      │ Audit Store  │
                                │     │ ┌─────────────────┐ │      │              │
                                │     │ │ Schema Registry │ │      │   Records:   │
                                │     │ └─────────────────┘ │      │ #1 applied   │
                                │     │  (applies change)   │      │              │
                                │     └─────────────────────┘      └──────────────┘
                                │
                                │
                  ChangeUnit #2 │───────────────────────────┐
              (SeedKafkaEvents) │                           │
                                │                           │
                                │             ┌─────────────┴────────────┐
                                │             ▼                          ▼
                                │     ┌─────────────────────┐      ┌──────────────┐
                                │     │   Target System:    │      │ Audit Store  │
                                │     │ ┌─────────────────┐ │      │              │
                                │     │ │  Kafka Topics   │ │      │   Records:   │
                                │     │ └─────────────────┘ │      │ #2 applied   │
                                │     │  (applies change)   │      │              │
                                │     └─────────────────────┘      └──────────────┘
                                │
                                │
                  ChangeUnit #3 └───────────────────────────┐
                (AddUserStatus)                             │
                                                            │
                                              ┌─────────────┴────────────┐
                                              ▼                          ▼
                                      ┌─────────────────────┐      ┌──────────────┐
                                      │   Target System:    │      │ Audit Store  │
                                      │ ┌─────────────────┐ │      │              │
                                      │ │  User Database  │ │      │   Records:   │
                                      │ └─────────────────┘ │      │ #3 applied   │
                                      │  (applies change)   │      │              │
                                      └─────────────────────┘      └──────────────┘
                                
```

**The Flow:**
1. **You create ChangeUnits** - Define what changes need to happen
2. **Flamingock orchestrates** - Safely applies changes across all your systems  
3. **Target systems evolve** - Your business systems get updated
4. **Audit store tracks everything** - Complete history for compliance and recovery


## Key takeaways

### For developers
- **Target systems**: Where your business logic runs and makes changes
- **Audit store**: Automatically managed by Flamingock for tracking and compliance
- **Implementation**: See [Target Systems](../target-systems/introduction.md) and [Audit Stores](../audit-stores/introduction.md)

### For architects  
- **Clean separation**: Business logic separated from execution tracking
- **Enterprise scalability**: Architecture supports compliance, governance, multi-environment
- **Flexibility**: Works with any target system type (transactional, non-transactional, hybrid)

### For operations
- **Issue resolution**: Tools operate on audit store, you fix target systems
- **Compliance**: Complete audit trail independent of business system availability  
- **Recovery**: Always know the state, even during complex failure scenarios

**Bottom Line**: This dual-system architecture is what enables Flamingock to provide enterprise-grade safety and governance capabilities that traditional tools cannot match.

---

// File: overview/Change-as-Code

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

**Automate changes. Version changes. Control changes.**  
Change-as-Code (CaC) means every system change—whether it’s an S3 bucket toggle, a new database schema, or a Kafka topic configuration—is authored, versioned, and audited just like application code.

At Flamingock, we champion CaC as the foundation for truly reliable, auditable, and repeatable deployments. No more one-off shell scripts or manual "clicks" in a console—every change is written in code, tracked in your VCS, and executed in a controlled pipeline.

## Why CaC matters today

Modern applications increasingly span dozens of external systems—ranging from relational and NoSQL databases to SaaS feature flags, message buses, and infrastructure APIs. Managing these changes manually or with ad-hoc scripts leads to:

- **Drift and “snowflake” environments**  
  When teams manually tweak production configurations, environments diverge, making rollbacks or audits nearly impossible.

- **Lack of auditability**  
  Regulatory and security teams require a full record of “what changed, when, and who made it.” Spreadsheets and one-off commands don’t cut it.

- **Inefficient collaboration**  
  Developers, operations, and security need a single source of truth: change definitions in code, reviewed and versioned via pull requests.

- **Increased risk of human error**  
  Pasting commands into a console or clicking UI checkboxes invites typos, misconfigurations, and stress during deployment windows.

Flamingock's CaC approach solves these problems by treating every external-system change as first-class code—complete with version control, automated execution, and a centralized audit trail.

## Four Pillars of Change-as-Code

1. **One-Hundred-Percent Versioned**  
   All ChangeUnits live in your Git repository (or other VCS). This means you can review, diff, and roll back changes just like application code.

2. **Automated Execution**  
   Flamingock scans and applies ChangeUnits at application startup or on-demand via the CLI. No manual intervention—just code running code.

3. **Auditable & Traceable**  
   Every ChangeUnit outcome is recorded in an audit store (your database or Flamingock Cloud). Teams can query “who ran what change, and when,” ensuring full compliance.

4. **Cross-Component Support**  
   Whether it's SQL/NoSQL DDL, S3 buckets, Kafka topics, feature-flag toggles, or REST API calls—Flamingock treats them all as code. Your entire system evolves in lockstep.

## "Hello, CaC" Code Snippet

Imagine you need to toggle a feature flag in a downstream service (not a database). In Flamingock, you’d write:

```java
@Change(id = "enable-autosave", order = "0005", author = "ops-team")
public class _0005_EnableAutoSaveFeature {

  @Execution
  public void enableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", true);
  }

  @RollbackExecution
  public void disableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", false);
  }
}
```

- **Versioned**: This code-based or template-based ChangeUnit lives in your VCS.
- **Automated**: Flamingock executes it in order (0005) at startup or via CLI.
- **Auditable**: Upon success, an audit entry is written to your audit store.
- **Cross-Component**: The same pattern works for a DynamoDB schema change, a Kafka topic creation, or any REST API call.

## Illustration: CaC vs. IaC

![](../../static/img/Change%20as%20code-2.png)

- **Infrastructure as Code (IaC)**: Use Terraform, CloudFormation, Pulumi, etc., to provision VMs, networks, and databases (the “foundation”).
- **Change as Code (CaC)**: Use Flamingock to version and apply everything that lives on that foundation—database schemas, feature flags, SaaS configurations, message topics, and more.

## Real-World Use Cases

### Multi-tenant SaaS Onboarding

**Problem**: Over the lifetime of your application, you might need to create and then later modify external resources—such as an S3 bucket, Kafka topics, IAM roles, and initial database state—as part of each new release. Doing this manually or with ad-hoc scripts risks drift, missing audits, and inconsistent environments..

**CaC Solution**: Define a sequence of ChangeUnits that run in order on mutiple deployments, inserting audit entries and ensuring reproducible, versioned updates::
<Tabs groupId="config">
<TabItem value="code-base" label="Code" default>
```java
@ChangeUnit(id = "provision-bucket", order = "0001", author = "team-a", transactional = false)
public class _0001_ProvisionBucketChange {

    @Execution
    public void execute(S3Client s3) {
        s3.createBucket(CreateBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }

    @RollbackExecution
    public void rollback(S3Client s3) {
        s3.deleteBucket(DeleteBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }
}

@ChangeUnit(id = "create-kafka-topics", order = "0002", author = "devops", transactional = false)
public class _0002_CreateKafkaTopicsChange {

    @Execution
    public void exec(KafkaAdminClient admin) {
        NewTopic topic1 = new NewTopic("app-events", 3, (short) 1);
        NewTopic topic2 = new NewTopic("user-notifications", 2, (short) 1);
        admin.createTopics(Arrays.asList(topic1, topic2));
    }

    @RollbackExecution
    public void rollback(KafkaAdminClient admin) {
        admin.deleteTopics(Arrays.asList("app-events", "user-notifications"));
    }
}

@ChangeUnit(id = "setup-iam-roles", order = "0003", author = "devops", transactional = false)
public class _0003_SetupIamRolesChange {

    @Execution
    public void exec(IamClient iam) {
        CreateRoleResponse response = iam.createRole(CreateRoleRequest.builder()
                .roleName("flamingock-app-role")
                .assumeRolePolicyDocument("{...}") // truncated for brevity
                .build());
    }

    @RollbackExecution
    public void rollback(IamClient iam) {
        iam.deleteRole(DeleteRoleRequest.builder()
                .roleName("flamingock-app-role")
                .build());
    }
}

@ChangeUnit(id = "seed-database", order = "0004", author = "devops", transactional = true)
public class _0004_SeedTenantDataChange {

    @Execution
    public void exec(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate(
                    "INSERT INTO tenants (id, name, created_at) " +
                            "VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW())"
            );
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }

    @RollbackExecution
    public void rollback(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate("DELETE FROM tenants WHERE id IN (1, 2)");
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }
}

@ChangeUnit(id = "update-bucket-settings", order = "0005", author = "team-a", transactional = false)
public class _0005_UpdateBucketSettingsChange {

    @Execution
    public void execute(S3Client s3) {
        // Example: enable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Enabled")
                        .build())
                .build());
    }

    @RollbackExecution
    public void rollback(S3Client s3) {
        // Example: disable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Suspended")
                        .build())
                .build());
    }
}

```
</TabItem>
<TabItem value="template-base" label="Template">

```yaml

# File: _0001_provision-bucket.yaml
id: "provision-bucket"
order: 0001
author: "team-a"
transactional: false
templateName: aws-s3-template
execution:
  bucketName: "flamingock-app-bucket"
  region: "us-east-1"
rollback:
  bucketName: "flamingock-app-bucket"

---

# File: _0002_create-kafka-topics.yaml
id: "create-kafka-topics"
order: 0002
author: "devops"
transactional: false
templateName: kafka-template
execution:
  topics:
    - "app-events"
    - "user-notifications"
  configs:
    app-events:
      partitions: 3
      replicationFactor: 1
    user-notifications:
      partitions: 2
      replicationFactor: 1
rollback:
  topics:
    - "app-events"
    - "user-notifications"
  rollbackTopics:
    - "app-events"
    - "user-notifications"

---

# File: _0003_setup-iam-roles.yaml
id: "setup-iam-roles"
order: 0003
author: "devops"
transactional: false
templateName: aws-iam-template
execution:
  roleName: "flamingock-app-role"
  assumeRolePolicy: |
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": { "Service": "ec2.amazonaws.com" },
          "Action": "sts:AssumeRole"
        }
      ]
    }
rollback:
  roleName: "flamingock-app-role"
  rollbackRoleName: "flamingock-app-role"

---

# File: _0004_seed-database.yaml
id: "seed-database"
order: 0004
author: "devops"
transactional: true
templateName: sql-template
execution: |
  INSERT INTO tenants (id, name, created_at)
  VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW());
rollback: |
  DELETE FROM tenants WHERE id IN (1, 2);

---

# File: _0005_update-bucket-settings.yaml
id: "update-bucket-settings"
order: 0005
author: "team-a"
transactional: false
templateName: aws-s3-template
execution:
  # Enable versioning on an existing bucket
  bucketName: "flamingock-app-bucket"
  versioningConfiguration:
    status: "Enabled"
rollback:
  # Rollback: suspend versioning
  bucketName: "flamingock-app-bucket"
  versioningConfiguration:
    status: "Suspended"
  rollbackVersioningConfiguration:
    bucketName: "flamingock-app-bucket"
    versioningConfiguration:
      status: "Suspended"

---

```

</TabItem>
</Tabs>

Flamingock ensures these four steps run in sequence—never twice—and logs them in your audit store for future reference.

## Change-as-Code Checklist

- ✅ **Change lives in VCS**: Every ChangeUnit class (or YAML template) is versioned.
- ✅ **Automated pipeline**: Flamingock applies changes automatically at startup or via CLI.
- ✅ **Audit trail**: Query your audit store for a complete history of applied changes.
- ✅ **Rollback logic**: Each ChangeUnit provides `@RollbackExecution` to undo or compensate if needed.
- ✅ **Consistent ordering**: All ChangeUnits follow a strict, declared ordering (via the `order` attribute).
- ✅ **Cross-component**: You can target databases, SaaS APIs, feature flags, message systems—anything with a client API.

## Next Steps

- [Quick start](quick-start.md) → Learn how to create your first ChangeUnit and run Flamingock. 
- [Core concepts](./core-concepts.md)   → Dive deeper into auditing, drivers, transactions, and distributed locking.
- [Real use case examples](../resources/examples.md) → Explore real-world code samples: MongoDB, DynamoDB, Couchbase, Kafka, and more.

---

// File: resources/examples

## Introduction

The **Flamingock Examples** repository showcases a growing collection of real-world use cases demonstrating how to use Flamingock in different environments, integrations, and technologies. Each top-level folder represents a target technology and contains one or more self-contained example projects. Each project is designed to be cloned, explored, and run as a reference or foundation for your own implementation.

👉 **GitHub Repository**: [github.com/flamingock/flamingock-examples](https://github.com/flamingock/flamingock-examples)


## What you’ll find

Within each technology folder, you’ll find one or more example ​projects that demonstrate how to configure Flamingock and apply change units in various scenarios. Each folder contains its own `README.md` with setup instructions, and each project inside has its own documentation.

| Technology Folder                                                                 | Description                                                                                                                                                               |
|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [mongodb](https://github.com/flamingock/flamingock-examples/tree/master/mongodb)     | Folder containing Flamingock CE projects using MongoDB as the audit‐log backend. Each project shows different integration scenarios (standalone Java, Spring Boot, etc.). |
| [dynamodb](https://github.com/flamingock/flamingock-examples/tree/master/dynamodb)   | Folder containing Flamingock CE projects using Amazon DynamoDB for audit logging. Includes both standalone and Spring Boot examples.                                      |
| [couchbase](https://github.com/flamingock/flamingock-examples/tree/master/couchbase) | Folder containing Flamingock CE projects using Couchbase as the audit‐log backend.                                                                                        |

More examples are planned — including PostgreSQL, Redis, LocalStack, Kafka, Spring Native, multi‐module projects, and custom runners.


## How to use the examples

Each example folder and project includes its own `README.md` with detailed setup and run instructions. In general:

1. **Clone the examples repository**
   ```bash
   git clone https://github.com/flamingock/flamingock-examples.git
   ```  
   This repository contains all the example folders for various technologies.

2. **Navigate to the technology folder of interest**
   ```bash
   cd flamingock-examples/s3
   ```  
   Replace `s3` with the folder name for the technology you are interested in (e.g., `kafka`, `mongodb`, `dynamodb`, etc.).

3. **Navigate to a specific example project**
   ```bash
   cd s3
   ```  
   Each folder contains one or more projects. Move into the project folder that matches your use case or environment.

4. **Run the example**
   - For standalone Java applications:
     ```bash
     ./gradlew run
     ```  
   - For Spring Boot projects:
     ```bash
     ./gradlew bootRun
     ```  
   - Follow any additional instructions in the project’s `README.md`. Some examples may use Testcontainers or LocalStack; if so, ensure Docker is running on your machine.


## Who this is for

- **New users**: Learn by example. Pick an example that matches your tech stack and explore how Flamingock integrates with your environment.
- **Advanced users**: Discover integration patterns with external systems like Kafka, AWS, or NoSQL databases.
- **Contributors**: Want to improve or submit a new example? Fork the repo, add your example folder, and create a pull request!


## Contributing

We welcome community contributions to expand this repository! Please consider:

- Adding new example projects or folders (e.g., Wiremock, Kafka, PostgreSQL, Redis)
- Fixing or modernizing existing examples
- Improving documentation and setup instructions

See the [CONTRIBUTING.md](https://github.com/flamingock/flamingock-examples/blob/master/CONTRIBUTING.md) for detailed guidelines.

---

// File: resources/faq

## Introduction

This FAQ addresses frequent questions about Flamingock, from basic usage to advanced recovery strategies and operational concerns.


### Getting started

**Should I use a template-based or code-based ChangeUnit?**  
Choose template-based ChangeUnits to eliminate boilerplate for common tools and integrations (SQL DDL, SaaS/API, etc) and for your custom ChangeUnits by defining changes declaratively in YAML or JSON.
Use code-based ChangeUnits when you need custom or conditional logic in Java.
See: [Template introduction](templates/templates-introduction.md)

**Can I integrate Flamingock into a Spring Boot application?**  
Yes, you can. You just need to import the Spring Boot integration module and annotate you main application with [`@EnableFlamingock`](../frameworks/springboot-integration/introduction#automatic-setup).
See: [Spring Boot integration](../frameworks/springboot-integration/introduction.md)

**Can I use Flamingock without Spring Boot?**  
Yes. You can use Flamingock in any Java application by configuring it manually using the [`FlamingockBuilder`](../overview/quick-start#5-configure-flamingock-runtime). This approach is ideal for applications that do not rely on Spring Boot or that require finer control.

**What Java version is required?**  
Flamingock’s core engine runs on Java 8 and above. However, some optional integration modules (such as the Spring Boot support) target more recent ecosystems and require Java 17+. For those cases we publish two artifacts:

- A modern module (e.g., flamingock-springboot-integration) built for Java 17+ and Spring Boot 3.x
- A legacy counterpart (e.g., flamingock-springboot-integration-v2-legacy) compatible with Java 8 and Spring Boot 2.x

Most users on Java 8 can stick with the core and legacy integrations; if you’re on Java 17 or newer, simply use the up-to-date modules.

**Is it possible to use Flamingock in GraalVM native images?**  
Yes, Flamingock provides a dedicated [GraalVM integration guide](../frameworks/graalvm.md). Ensure your dependencies and reflection requirements are correctly configured.


### Compatibility

**Can I switch between different audit stores?**
If you are working with different audit stores that use the **same underlying database** (such as MongoDB), and they share the same structure and collection for storing metadata, it is possible to switch between them with minimal adjustments. This enables flexible integration depending on your preferred access layer, such as switching from the MongoDB Java Driver to the Spring Data implementation.


### Behaviour and execution

**Does Flamingock guarantee idempotent execution?**  
Yes. Each `ChangeUnit` has a unique ID and Flamingock ensures it runs only once per system, even across multiple instances.

**What happens if a ChangeUnit execution fails midway?**  
Flamingock's behavior depends on your recovery strategy configuration:

**With MANUAL_INTERVENTION (default)**:
1. **Transactional changes**: Database automatically rolls back, issue logged for manual review
2. **Non-transactional changes**: `@RollbackExecution` method called, issue logged for manual review
3. **Resolution required**: Use CLI (`flamingock issue get`, then `flamingock audit fix`) to resolve after investigation

**With ALWAYS_RETRY**:
1. **Transactional changes**: Database automatically rolls back, automatic retry on next execution
2. **Non-transactional changes**: `@RollbackExecution` method called, automatic retry on next execution
3. **No manual intervention**: Continues until successful

This intelligent failure handling prevents silent data corruption and provides operational control.

**How can I ensure changes are transactional?**  
If your database supports transactions (e.g. MongoDB ≥ 4.0 in replica set), you can enable them using [Flamingock’s transaction config](../flamingock-library-config/transactions.md).

**Should I implement the @RollbackExecution method in transactional environments?**

Yes, we highly recommend to implement the `@RollbackExecution` method. The main reason for this is that some other operations like undo, rely on this method to work. However it's a very good practice as it provides a robust system that is less affected when moving to non-transactional environments.

**Can I react to the execution of Flamingock from my application?**  
Yes. Flamingock provides an event system that allows your application to listen to key lifecycle moments, such as when a `ChangeUnit` starts or finishes execution. These events can be used to trigger logging, monitoring, or other side effects external to the change execution logic itself.

This enables loose coupling between Flamingock’s core execution and your application-level behaviour, without modifying the `ChangeUnit` directly.

For more details, see the [Events](../flamingock-library-config/events.md) guide.

**Is Flamingock compatible with Spring Boot profiles?**  
Yes. You can conditionally run ChangeUnits using [`@Profile`](../frameworks/springboot-integration/profiles.md), allowing changes to vary by environment.


### Configuration

**Where do I set MongoDB connection options like write concern or read preference?**  
You can define these directly in the config using dedicated properties (e.g. `mongodb.writeConcern.w`, `readPreference`, etc.). Refer to the [additional configuration](../flamingock-library-config/additional-configuration.md) section for detailed examples.

**Can I inject Spring beans or other services into my ChangeUnits?**  
Yes. Flamingock supports full [dependency injection](../flamingock-library-config/context-and-dependencies.md) in both Spring and non-Spring environments.

**Can I define ChangeUnit dependencies and execution order?**  
Yes. ChangeUnits can declare dependencies via annotations or configuration metadata. See [ChangeUnit anatomy](../change-units/anatomy-and-structure.md) for more.


### Testing and development

**How do I test Flamingock ChangeUnits?**  
You can perform unit, integration, and Spring Boot integration tests using test runners and mocking utilities. See the [Testing](../testing/introduction.md) section for more details.

**Can I use templates to generate ChangeUnits?**  
Yes. Flamingock offers a templating mechanism for [creating new ChangeUnits](../templates/templates-introduction.md) and defining reusable components.


### Migrating from Mongock

**What’s the relationship between Flamingock and Mongock?**  
Flamingock is the direct evolution of Mongock. While it inherits the core idea of tracking and executing changes reliably, Flamingock is a complete architectural and conceptual redesign aimed at overcoming the limitations of Mongock.

Some of the key advancements introduced by Flamingock include:

- **Cloud-native capabilities**: Support for cloud-managed storage and execution, enabling Flamingock to run in distributed, serverless, or ephemeral environments without additional setup.
- **Execution stages and pipelines**: A structured way to group and orchestrate ChangeUnits by context, environment, or lifecycle stage.
- **Modular architecture**: Clean separation of core, editions, templates, and integrations, enabling better extensibility and maintainability.
- **Template-based ChangeUnits**: An additional declarative mechanism to define reusable changes without writing Java code, accelerating development and standardisation.

While Flamingock retains conceptual compatibility with Mongock, it represents a significant leap forward in flexibility, scalability, and developer experience.

If you are currently using Mongock, we encourage you to [review the migration guide](coming-from-mongock.md) and explore what Flamingock can offer in modern change management.


### Recovery Strategies & Safety

**What are recovery strategies and why do I need them?**  
Recovery strategies determine how Flamingock handles failures - the key differentiator from traditional tools that retry blindly or fail silently. You choose between:
- **MANUAL_INTERVENTION** (default): Stop and alert for human review when uncertain
- **ALWAYS_RETRY**: Continue automatically until successful for idempotent operations

This prevents silent data corruption and gives you operational control based on your risk tolerance.

**When should I use MANUAL_INTERVENTION vs ALWAYS_RETRY?**  
**Use MANUAL_INTERVENTION for**:
- Financial transactions
- User data modifications  
- Critical business logic
- Non-idempotent operations
- Compliance-sensitive changes

**Use ALWAYS_RETRY for**:
- Cache warming operations
- Idempotent API calls
- Event publishing (with consistent keys)
- Configuration updates
- Index creation
- File operations with overwrite

**How do I know if my operation is idempotent?**  
An operation is idempotent if running it multiple times produces the same result as running it once. Examples:
- ✅ `SET user.status = 'active'` (same result every time)
- ✅ `CREATE INDEX IF NOT EXISTS` (safe to repeat)  
- ✅ File overwrite with same content
- ❌ `INCREMENT user.score` (different result each time)
- ❌ Append operations
- ❌ Time-sensitive calculations

**What is the issue resolution workflow?**  
1. **Detection**: `flamingock issue list` shows all unresolved issues
2. **Triage**: `flamingock issue get` provides next priority issue with guidance
3. **Investigation**: Check target system state (not audit store)
4. **Resolution**: `flamingock audit fix -c change-id --resolution APPLIED|ROLLED_BACK`

This structured workflow eliminates guesswork and provides complete audit trails.

**Can I change recovery strategies after deployment?**  
Yes, you can update the `@Recovery` annotation in your code and redeploy. Existing audit entries maintain their state, but new executions use the updated strategy.

**How does Cloud Edition improve recovery without changing my code?**  
Cloud Edition uses the same recovery strategies but provides enhanced outcomes through:
- **Intelligent automation**: Advanced reconciliation and marker mechanisms
- **Enhanced retry logic**: Sophisticated backoff and circuit breaker patterns  
- **Automatic issue resolution**: Many failures requiring manual intervention in Community Audit Stores are resolved automatically

Your change definitions remain identical - Cloud Edition just delivers better results.


### Enterprise & Operational Concerns

**How does Flamingock ensure data integrity in distributed systems?**  
Flamingock uses a dual-architecture separating target systems (where changes are applied) from audit store (execution tracking):
- **Complete audit trail**: Every change attempt recorded regardless of business system failures
- **Recovery capabilities**: CLI operates on audit state, you fix business systems
- **Compliance independence**: Audit integrity maintained during business system issues
- **Governance separation**: Business and compliance data have different access patterns

**What compliance and audit capabilities does Flamingock provide?**  
- **Complete execution history** with timestamp, author, system, and outcome
- **Issue tracking and resolution** workflows for failed changes
- **CLI-based audit management** for governance and compliance
- **Integration ready** for external observability platforms (ELK, Prometheus, Datadog)
- **Regulatory reporting** capabilities in Cloud Edition

**How does Flamingock compare to traditional migration tools?**  
| Aspect | Flyway/Liquibase | Mongock | Flamingock |
|--------|-----------------|---------|------------|
| **Focus** | SQL databases | MongoDB only | All systems |
| **Distributed Systems** | ❌ Not designed for | ❌ Limited | ✅ First-class support |
| **Non-transactional** | ❌ No support | ❌ Assumes transactions | ✅ Full support |
| **Failure Handling** | Retry blindly | Retry blindly | Configurable strategies |
| **Issue Resolution** | Manual SQL | None | CLI + Cloud automation |
| **Safety Default** | None | None | MANUAL_INTERVENTION |

**Can Flamingock handle multi-system coordination?**  
Yes, Flamingock is designed for distributed systems. A single ChangeUnit can coordinate changes across multiple target systems (databases, APIs, message queues) while maintaining a unified audit trail and recovery strategy.

**How do I ensure my team adopts Flamingock safely?**  
1. **Start conservative**: Use MANUAL_INTERVENTION (default) initially
2. **Establish governance**: Define organization-wide recovery strategy guidelines
3. **Create runbooks**: Document investigation procedures for your changes
4. **Train on CLI**: Ensure team knows issue resolution workflow
5. **Monitor patterns**: Review failure patterns to optimize strategies over time

**What happens if the audit store goes down?**  
Flamingock's safety guarantee: **No business changes applied without proper audit tracking**. If the audit store is unavailable:
- Flamingock stops execution safely
- No changes are applied to target systems
- System remains in safe, known state
- Resume automatically once audit store connectivity is restored

**Can I use Flamingock in microservices architectures?**  
Absolutely. Flamingock is designed for distributed systems:
- Each microservice can have its own ChangeUnits for its domain
- Shared audit store provides cross-service visibility (especially in Cloud Edition)  
- CLI provides centralized operational control across all services
- Recovery strategies can be tailored per service's risk profile

**What are the organizational benefits of adopting Flamingock?**  
- **Risk reduction**: Prevent silent data corruption through safety-first defaults
- **Team velocity**: Eliminate deployment bottlenecks with autonomous change management
- **Operational excellence**: Centralized governance with distributed execution
- **Compliance automation**: Complete audit trails and governance workflows
- **Reduced dependencies**: Teams control their domain without infrastructure dependencies

**How does Flamingock support regulatory compliance requirements?**  
- **Complete audit trails** with immutable execution history
- **Governance workflows** for change approval and review
- **Issue resolution documentation** for regulatory reporting
- **CLI integration** for compliance automation
- **Separation of concerns** between business and compliance data
- **Cloud Edition features**: Advanced reporting, RBAC, multi-environment governance


### Other

**Is Flamingock open-source?**  
Yes. The Flamingock client library — used across all editions, including Community, Self-managed, and Cloud — is fully open-source.

For the Cloud and Self-managed editions, additional enterprise components such as the server runtime, dashboards, and governance tools are provided under a commercial licence. These components build on top of the open-source core to deliver advanced features like observability, orchestration, and centralised management.

**Is there a CLI available?**  
Yes! The [Flamingock CLI](../cli/cli.md) provides enterprise-grade operational control for issue resolution, audit management, and maintenance tasks.


If your question is not listed here, please check the corresponding edition’s guide or open an issue on our GitHub repository.

---

// File: resources/coming-from-mongock

# Coming from Mongock

:::info 🚀 Transition Support Coming Soon

We're actively working on a smooth transition path from Mongock to Flamingock.

Our team is developing the mechanisms and best practices to make your transition as easy as possible, following Flamingock's architectural principles. Both the transition features and the complete guide will be available soon.

Stay tuned for updates!

:::

---

// File: safety-and-recovery/introduction

# Safety and Recovery

While Flamingock executions typically complete successfully, the framework provides configurable recovery mechanisms to handle exceptional circumstances with complete control and visibility.

## Safety-first philosophy

In the rare cases where Flamingock cannot guarantee a safe outcome, it stops execution and requires explicit resolution rather than risking data corruption or system inconsistency. This approach ensures you always know the exact state of your systems.

## Recovery strategies

Flamingock provides two recovery strategies to handle execution failures:

### Manual intervention (default)
- **When it activates**: Any failure where the outcome is uncertain
- **What happens**: Execution stops and requires human review before continuing
- **Use case**: When safety is prioritized over automation

### Always retry
- **When it activates**: Any failure, automatically retrying on next execution
- **What happens**: Continues attempting the change until successful
- **Use case**: When changes are idempotent and safe to retry

## How it works

1. **Change execution** - Flamingock attempts to execute a ChangeUnit
2. **Failure detection** - If execution fails, the recovery strategy determines next steps
3. **Strategy application** - Either automatic retry or manual intervention workflow
4. **Issue resolution** - For manual intervention, use CLI tools to investigate and resolve

## In this section

- **[Recovery strategies](recovery-strategies.md)** - Technical details and configuration
- **[Issue resolution](issue-resolution.md)** - Operational workflows for handling issues

---

// File: safety-and-recovery/issue-resolution

# Issue Resolution

Issue resolution is an iterative process of identifying failures, investigating their cause in target systems, and marking the appropriate resolution. Flamingock provides CLI tools to systematically work through issues until all are resolved.


## Understanding Issues

### What Creates an Issue?
An "issue" is detected when:
1. **Change execution fails** during the `@Execution` method
2. **Change starts but never completes** (process crash, timeout)
3. **Rollback fails** during `@RollbackExecution` method
4. **Change needs to run again** but is in uncertain state


## CLI-Driven Resolution Workflow

### 1. Issue Discovery
```bash
flamingock issue list
```

**Example Output**:
```
ISSUES FOUND (3)
┌─────────────────────────┬─────────┬──────────────────┬──────────────┐
│ Change ID               │ State   │ Error            │ Target       │
├─────────────────────────┼─────────┼──────────────────┼──────────────┤
│ user-data-sync-v2       │ STARTED │ Connection lost  │ user-db      │
│ cache-warming-q4        │ FAILED  │ Redis timeout    │ redis-cache  │
│ payment-processing      │ FAILED  │ Validation error │ payment-api  │
└─────────────────────────┴─────────┴──────────────────┴──────────────┘

Use 'flamingock issue get' to process issues automatically, or
'flamingock issue get -c <change-id>' for specific issue details.
```

### 2. Automated Issue Triage
```bash
flamingock issue get
```

**What This Does**:
- Automatically selects the next issue
- Provides detailed context and diagnostic information
- Suggests resolution approaches based on failure type
- No need to copy/paste change IDs

**Example Output**:
```
ISSUE: user-data-sync-v2
Status: STARTED (execution began but never completed)
Target System: user-database
Author: platform-team
Started: 2024-01-15 14:32:15 UTC
Error: Connection lost during execution

DIAGNOSTIC INFORMATION:
- Change was modifying user profiles in MongoDB
- Execution started but connection dropped after 30 seconds
- No rollback was triggered (connection failure before completion)
- Potentially partial state in target system

RESOLUTION GUIDANCE:
1. Check target system state:
   - Query user-database for partially updated records
   - Look for users with incomplete profile updates
   - Check MongoDB logs for connection errors around 14:32:15 UTC

2. Determine actual state:
   - If no changes were applied → mark as APPLIED (safe to continue)
   - If changes were partially applied → complete manually, then mark APPLIED
   - If changes were fully applied → mark as APPLIED
   - If changes caused corruption → rollback manually, then mark ROLLED_BACK

3. Resolve the issue:
   flamingock audit fix -c user-data-sync-v2 --resolution APPLIED
   flamingock audit fix -c user-data-sync-v2 --resolution ROLLED_BACK

Next: flamingock issue get (to process next issue)
```

### 3. Verify Target System State

Based on the guidance, investigate the **target system** (not the audit store) to determine the actual state of the change. You will find one of three possible states:

- **Fully applied**: The change completed successfully and all expected modifications are present
- **Not applied at all**: The change failed before making any modifications to the target system
- **Partially applied**: Some but not all changes were made to the target system (**only possible with non-transactional target systems**)

For partially applied changes, you must decide whether to:
- Manually complete the remaining changes, then mark as **APPLIED**
- Manually revert the partial changes, then mark as **ROLLED_BACK**

### 4. Mark Audit Resolution

Based on your target system verification, mark the audit with the appropriate resolution.

- If the change was successfully applied to the target system (either fully or after manual completion of partial changes), mark it as **APPLIED**:

```bash
flamingock audit fix -c change-id -r APPLIED
```

- If the change was not applied or was manually reverted, mark it as **ROLLED_BACK**:

```bash
flamingock audit fix -c change-id -r ROLLED_BACK
```

## Resolution Commands

### APPLIED Resolution
Mark the change as successfully applied when the target system contains the expected changes:

```bash
flamingock audit fix -c change-id -r APPLIED
```

**Use when:**
- Changes were successfully applied to target system
- Partial changes were completed manually
- Target system is in the desired end state

### ROLLED_BACK Resolution
Mark the change as not applied when the target system was not modified or was reverted:

```bash
flamingock audit fix -c change-id -r ROLLED_BACK
```

**Use when:**
- Changes were not applied to target system
- Changes were reverted due to issues
- Target system should be left unchanged

**Note:** Changes marked as ROLLED_BACK will be attempted again on the next execution.

---

// File: safety-and-recovery/recovery-strategies

# Recovery strategies

Recovery strategies determine how Flamingock handles ChangeUnit execution failures. They provide configurable behavior to balance safety with automation based on your specific requirements.

## Strategy types

### Manual intervention (default)
- **Behavior**: Stops execution and requires human intervention when any failure occurs
- **Use case**: When safety is prioritized over automation
- **Technical challenge**: Prevents silent failures and ensures human oversight for uncertain outcomes

### Always retry
- **Behavior**: Automatically retries the change on subsequent executions until successful
- **Use case**: When changes are idempotent and safe to retry automatically
- **Technical challenge**: Reduces operational overhead for recoverable failures

## Configuration

### Code-based ChangeUnits

Use the `@Recovery` annotation to specify the strategy:

```java
// Default behavior (manual intervention)
@ChangeUnit(id = "example-change", order = "001", author = "team")
public class ExampleChange {
    @Execution
    public void execute() {
        // Change logic here
    }
}

// Explicit always retry
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
@ChangeUnit(id = "retry-change", order = "002", author = "team")
public class RetryChange {
    @Execution
    public void execute() {
        // Idempotent change logic here
    }
}
```

### Template-based ChangeUnits

Use the `recovery` field in your YAML configuration:

```yaml
# Default behavior (manual intervention)
id: example-change
order: "001"
author: team
template: example-template
execution: |
  # Change logic here

---

# Explicit always retry
id: retry-change
order: "002"
author: team
recovery: ALWAYS_RETRY
template: example-template
execution: |
  # Idempotent change logic here
```

## When failures occur

### Manual intervention workflow
1. Execution stops immediately on failure
2. Issue is logged in the audit store
3. Use CLI tools to investigate and resolve
4. Mark change as applied or rolled back manually

### Always retry workflow
1. Execution fails but continues on next run
2. Change attempts retry automatically
3. Process continues until successful or manually intervened

## Best practices

### Choose manual intervention when:
- Changes modify critical system state
- Failures require investigation before proceeding
- Rollback logic is complex or requires validation

### Choose always retry when:
- Operations are truly idempotent
- Failures are typically transient (network, temporary unavailability)
- Automatic recovery is acceptable

For detailed information on ChangeUnit annotations and configuration, see [ChangeUnit anatomy](../change-units/anatomy-and-structure.md).

For operational workflows when issues occur, see [Issue resolution](issue-resolution.md).

---

// File: target-systems/introduction

# Target systems

Target systems are the real-world systems where your business changes are applied.
These include any external service your application interacts with or evolves - message queues, APIs, cloud services, databases, configuration stores, and more. The examples throughout this documentation are illustrative; Flamingock can work with any system your application needs to change.

A ChangeUnit always declares which target system it belongs to. This ensures Flamingock can:
- Track and audit changes per system
- Guarantee safe execution across heterogeneous environments
- Provide clear visibility into which changes affect which systems

> **Conceptual Overview**: For architectural understanding of target systems vs audit store, see [Target Systems vs Audit Store](../overview/audit-store-vs-target-system.md).


## Why target systems matter

### Explicit ownership
Every change is tied to a named target system, avoiding ambiguity and enabling clear governance.

### Transactionality awareness
- **Transactional target systems** (like PostgreSQL, MySQL, or MongoDB with transactions) allow Flamingock to use native rollback and guarantees.
- **Non-transactional systems** (like S3, Kafka, or REST APIs) are still safe, but Flamingock relies on rollback methods you provide.

This distinction is built into the target system definition.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

### Dependency injection

Each target system can expose the dependencies required by its ChangeUnits. For example:
- A MongoDB target system provides a `MongoDatabase`
- A Kafka target system provides a `KafkaTemplate`  
- A SQL target system provides a `Connection` or `DataSource`

#### Dependency resolution hierarchy

Each target system needs specific dependencies to function (except `DefaultTargetSystem` which requires none). When Flamingock initializes a target system, it resolves dependencies using this hierarchy:

1. **Direct injection** via `.withXXX()` methods (highest priority)
2. **Global context** lookup if not directly injected
3. **Default values** for optional configurations, or **exception** for required ones

This approach provides maximum flexibility while ensuring all requirements are met:

```java
MongoSyncTargetSystem mongoTarget = new MongoSyncTargetSystem("user-db")
    .withDatabase(database);
```

In this example, Flamingock resolves dependencies as follows:
- **MongoDatabase**: Provided directly via `.withDatabase()`, so it's immediately available
- **MongoClient**: Not provided directly, so Flamingock searches the global context
- **WriteConcern**: Not found in either place, so uses the default value (MAJORITY with journal)
- If MongoClient is missing from the global context, Flamingock throws an exception since it's a required dependency

:::info
ChangeUnits are not limited to target system dependencies. They can also request shared or application-level dependencies. Flamingock resolves them automatically, starting from the target system context and falling back to the general context.
:::


## Registering target systems

Target systems are registered at runtime with the Flamingock builder. You can define and register as many as you need:

```java

SqlTargetSystem mysql = new SqlTargetSystem("mysql-inventory")
    .withDatasource(ds);

DefaultTargetSystem s3 = new DefaultTargetSystem("aws-s3");

DefaultTargetSystem kafka = new DefaultTargetSystem("kafka-stock");

Flamingock.builder()
    .setAuditStore(new MongoSyncAuditStore(mongoClient, mongoDatabase))
    .addTargetSystems(mysql, s3, kafka)
    .build()
    .run();
  
```

At startup, Flamingock automatically injects the right dependencies from the corresponding target system into each ChangeUnit.

### Spring Boot Integration
For Spring Boot applications, target systems are configured as beans:

```java
@Bean
public SqlTargetSystem sqlTargetSystem(DataSource dataSource) {
    return new SqlTargetSystem("mysql-inventory")
        .withDatasource(dataSource);
}

@Bean  
public DefaultTargetSystem kafkaTargetSystem() {
    return new DefaultTargetSystem("kafka-stock");
}
```

Spring Boot's auto-configuration will automatically register these target systems with Flamingock.

For more details, see [Spring Boot Integration](../frameworks/springboot-integration/introduction.md).



## Linking ChangeUnits to target systems

When defining ChangeUnits, you specify which target system they belong to using the `@TargetSystem` annotation:

```java
@TargetSystem("mysql-inventory")
@ChangeUnit(id = "add-category", order = "001", author = "team")
public class _001_AddCategory {
    //...
}
```



## Cloud Edition visibility

In the Cloud Edition, target systems become a first-class part of the dashboard:
- See all changes grouped by target system
- Filter execution history by system
- Track failures and recoveries per system

This makes it easier to govern and audit distributed environments at scale.


## Best practices

- Use descriptive names (`mysql-inventory`, `aws-s3`, `kafka-stock`)
- Be consistent across related ChangeUnits
- Avoid generic names like "database" or "api"
- Provide rollback logic for non-transactional systems
- Keep dependencies scoped to the system they belong to — don’t overload the general context when they are system-specific


## Available target system implementations

Flamingock provides several built-in target system implementations. The ecosystem includes specialized implementations for technologies that benefit from specific handling, and a universal fallback for everything else:

### Specialized target systems
These target systems provide optimized handling for specific technologies:

**Transactional systems** - Leverage native transaction capabilities for automatic rollback:
- [MongoDB target system](../target-systems/mongodb-target-system.md) - For MongoDB with the sync driver
- [MongoDB Spring Data target system](../target-systems/mongodb-springdata-target-system.md) - For MongoDB with Spring Data
- [SQL target system](../target-systems/sql-target-system.md) - For relational databases (PostgreSQL, MySQL, etc.)
- [DynamoDB target system](../target-systems/dynamodb-target-system.md) - For Amazon DynamoDB
- [Couchbase target system](../target-systems/couchbase-target-system.md) - For Couchbase

### Universal fallback
For any system that doesn't require specialized handling:

- [Default target system](../target-systems/default-target-system.md) - The fallback choice for any system without a dedicated implementation (Kafka Schema Registry, S3, REST APIs, file systems, etc.)

**Future extensibility**: The Flamingock ecosystem may expand with more specialized target systems as specific needs are identified. These can be implemented by the Flamingock team, community contributions, or custom implementations by users.


**Key Takeaway**: Target systems provide the foundation for safe, auditable changes across your entire technology stack. By explicitly declaring and configuring them, you enable Flamingock to orchestrate complex distributed system evolution with confidence.

---

// File: target-systems/mongodb-target-system

# MongoDB Sync Target System

The MongoDB Sync target system (`MongoSyncTargetSystem`) enables Flamingock to apply changes to MongoDB databases using the official MongoDB Java sync driver. As a transactional target system, it supports automatic rollback through MongoDB's native transaction capabilities.

## Minimum recommended setup

```java
MongoSyncTargetSystem mongoTarget = new MongoSyncTargetSystem("user-database")
    .withMongoClient(mongoClient)
    .withDatabase(database);
```

While dependencies can be provided through the global context, we highly recommend injecting them directly at the target system level. This provides clearer scoping, better isolation between systems, and makes dependencies explicit and easier to track.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `MongoClient` | `.withMongoClient(client)` | MongoDB connection client - **required** for both ChangeUnit execution and transaction management |
| `MongoDatabase` | `.withDatabase(database)` | Target database instance - **required** for both ChangeUnit execution and transaction management |

### Optional configurations

| Configuration | Method | Default | Description |
|---------------|--------|---------|-------------|
| `WriteConcern` | `.withWriteConcern(concern)` | `MAJORITY` with journal | Write acknowledgment level |
| `ReadConcern` | `.withReadConcern(concern)` | `MAJORITY` | Read isolation level |
| `ReadPreference` | `.withReadPreference(pref)` | `PRIMARY` | Server selection for reads |

**Important**: These default values are optimized for maximum consistency and should ideally be left unchanged. Override them only for testing purposes or exceptional cases where the defaults cannot be used (e.g., specific infrastructure limitations).

Remember: If not provided directly via `.withXXX()`, Flamingock searches the global context. If still not found:
- **Required dependencies** will throw an exception
- **Optional configurations** will use the defaults shown above

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with specific dependencies
MongoSyncTargetSystem mongoTarget = new MongoSyncTargetSystem("user-database")
    .withMongoClient(productionMongoClient)    // Target-specific client
    .withDatabase(userDatabase)                // Target-specific database
    .addDependency(auditService);              // Custom service for this target

// Global context with different dependencies
Flamingock.builder()
    .addDependency(defaultMongoClient)         // Different client in global
    .addDependency(defaultDatabase)            // Different database in global
    .addDependency(emailService)               // Available to all targets
    .addTargetSystems(mongoTarget)
    .build();
```

**What gets resolved for ChangeUnits in "user-database":**
- **MongoClient**: Uses `productionMongoClient` (from target system, not `defaultMongoClient` from global)
- **MongoDatabase**: Uses `userDatabase` (from target system, not `defaultDatabase` from global)
- **AuditService**: Available from target system context
- **EmailService**: Available from global context
- **WriteConcern/ReadConcern**: Use defaults (MAJORITY with journal)

The target system context always takes precedence, ensuring proper isolation between different systems.

## Transactional support

For a ChangeUnit to leverage MongoDB's transactional capabilities, it must use the `ClientSession` parameter. Flamingock uses the injected `MongoClient` and `MongoDatabase` dependencies to create and manage this session's lifecycle - starting the transaction before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

```java
@TargetSystem("user-database")
@ChangeUnit(id = "create-users", order = "001")
public class CreateUsers {
    
    @Execution
    public void execution(MongoDatabase db, ClientSession session) {
        // The ClientSession is required for transactional execution
        // Flamingock uses the target system's MongoClient to create this session
        // and handles transaction start, commit, and rollback automatically
        db.getCollection("users")
          .insertOne(session, new Document("name", "John"));
    }
}
```

**How transactions work:**
1. **Session creation**: Flamingock uses the target system's `MongoClient` to create a `ClientSession`
2. **Transaction management**: The same `MongoClient` and `MongoDatabase` handle transaction operations
3. **Lifecycle**: Flamingock automatically starts the transaction, commits on success, or rolls back on failure

Without the `ClientSession` parameter, operations will execute but won't participate in transactions.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject MongoDB-specific dependencies like `MongoClient`, `MongoDatabase`, and `ClientSession` (for transactions), but are not limited to these. Any dependency can be added to the target system context via `.addDependency()`, taking precedence over global dependencies.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)
- See [MongoDB examples](https://github.com/flamingock/flamingock-examples/tree/master/mongodb)

---

// File: target-systems/mongodb-springdata-target-system

# MongoDB Spring Data Target System

The MongoDB Spring Data target system (`MongoSpringDataTargetSystem`) enables Flamingock to apply changes to MongoDB databases using Spring Data MongoDB. As a transactional target system, it integrates seamlessly with Spring's transaction management and supports automatic rollback through MongoDB's native transaction capabilities.

## Minimum recommended setup

```java
MongoSpringDataTargetSystem mongoTarget = new MongoSpringDataTargetSystem("user-database")
    .withMongoTemplate(mongoTemplate);
```

While dependencies can be provided through the global context, we highly recommend injecting them directly at the target system level. This provides clearer scoping, better isolation between systems, and makes dependencies explicit and easier to track.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `MongoTemplate` | `.withMongoTemplate(template)` | Spring Data MongoDB template - **required** for both ChangeUnit execution and transaction management |

### Optional configurations

| Configuration | Method | Default | Description |
|---------------|--------|---------|-------------|
| `WriteConcern` | `.withWriteConcern(concern)` | `MAJORITY` with journal | Write acknowledgment level |
| `ReadConcern` | `.withReadConcern(concern)` | `MAJORITY` | Read isolation level |
| `ReadPreference` | `.withReadPreference(pref)` | `PRIMARY` | Server selection for reads |

**Important**: These default values are optimized for maximum consistency and should ideally be left unchanged. Override them only for testing purposes or exceptional cases where the defaults cannot be used (e.g., specific infrastructure limitations).

Remember: If not provided directly via `.withXXX()`, Flamingock searches the global context. If still not found:
- **Required dependencies** will throw an exception
- **Optional configurations** will use the defaults shown above

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with specific dependencies
MongoSpringDataTargetSystem mongoTarget = new MongoSpringDataTargetSystem("user-database")
    .withMongoTemplate(userMongoTemplate)      // Target-specific template
    .addDependency(userAuditService);          // Custom service for this target

// Global context with different dependencies
Flamingock.builder()
    .addDependency(defaultMongoTemplate)       // Different template in global
    .addDependency(emailService)               // Available to all targets
    .addTargetSystems(mongoTarget)
    .build();
```

**What gets resolved for ChangeUnits in "user-database":**
- **MongoTemplate**: Uses `userMongoTemplate` (from target system, not `defaultMongoTemplate` from global)
- **UserAuditService**: Available from target system context
- **EmailService**: Available from global context
- **WriteConcern/ReadConcern**: Use defaults (MAJORITY with journal)

The target system context always takes precedence, ensuring proper isolation between different systems.

## Transactional support

Spring Data MongoDB target system integrates with Spring's transaction management. When a ChangeUnit is marked as transactional (the default), Flamingock uses the injected `MongoTemplate` dependency to handle transaction operations through Spring's infrastructure.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

```java
@TargetSystem("user-database")
@ChangeUnit(id = "create-users", order = "001")
public class CreateUsers {
    
    @Execution
    public void execution(MongoTemplate mongoTemplate) {
        // MongoTemplate automatically participates in Spring transactions
        // Flamingock uses the target system's MongoTemplate for transaction management
        // through Spring's @Transactional infrastructure
        mongoTemplate.save(new User("john@example.com", "John Doe"));
    }
}
```

**How transactions work:**
1. **Spring integration**: Flamingock leverages the target system's `MongoTemplate` within Spring's transaction context
2. **Transaction management**: The same `MongoTemplate` handles both ChangeUnit operations and transaction coordination
3. **Lifecycle**: Spring's transaction infrastructure manages start, commit, and rollback automatically

The transaction lifecycle is managed through Spring's transaction infrastructure, ensuring consistency with your existing Spring Data operations.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject Spring Data dependencies like `MongoTemplate`, but are not limited to these. Any dependency can be added to the target system context via `.addDependency()`, taking precedence over global dependencies.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Spring integration

This target system is designed to work seamlessly with Spring Boot applications. When using Spring Boot auto-configuration, your existing `MongoTemplate` beans are automatically available for injection into target systems.

For more information on Spring Boot integration, see [Spring Boot integration](../frameworks/springboot-integration/introduction.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)
- See [MongoDB Spring Data examples](https://github.com/flamingock/flamingock-examples/tree/master/mongodb-springdata)

---

// File: target-systems/sql-target-system

# SQL Target System

The SQL target system (`SqlTargetSystem`) enables Flamingock to apply changes to relational databases including PostgreSQL, MySQL, Oracle, and SQL Server using standard JDBC connections. As a transactional target system, it supports automatic rollback through the database's native transaction capabilities.

## Minimum recommended setup

```java
SqlTargetSystem sqlTarget = new SqlTargetSystem("inventory-database")
    .withDatasource(dataSource);
```

While dependencies can be provided through the global context, we highly recommend injecting them directly at the target system level. This provides clearer scoping, better isolation between systems, and makes dependencies explicit and easier to track.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `DataSource` | `.withDatasource(dataSource)` | JDBC DataSource connection pool - **required** for both ChangeUnit execution and transaction management |

### Optional configurations

| Configuration | Method | Default | Description |
|---------------|--------|---------|-------------|
| `Connection` | `.withConnection(connection)` | None | Direct JDBC connection (alternative to DataSource) |

Remember: If not provided directly via `.withXXX()`, Flamingock searches the global context. If still not found:
- **Required dependencies** will throw an exception

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with specific dependencies
SqlTargetSystem sqlTarget = new SqlTargetSystem("inventory-database")
    .withDatasource(inventoryDataSource)       // Target-specific datasource
    .addDependency(inventoryService);          // Custom service for this target

// Global context with different dependencies
Flamingock.builder()
    .addDependency(defaultDataSource)          // Different datasource in global
    .addDependency(emailService)               // Available to all targets
    .addTargetSystems(sqlTarget)
    .build();
```

**What gets resolved for ChangeUnits in "inventory-database":**
- **DataSource**: Uses `inventoryDataSource` (from target system, not `defaultDataSource` from global)
- **InventoryService**: Available from target system context
- **EmailService**: Available from global context

The target system context always takes precedence, ensuring proper isolation between different systems.

## Transactional support

For a ChangeUnit to leverage SQL's transactional capabilities, it must use either the `DataSource` or `Connection` parameter. Flamingock uses the injected `DataSource` dependency to create connections and manage the transaction lifecycle - starting the transaction before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

```java
@TargetSystem("inventory-database")
@ChangeUnit(id = "update-products", order = "001")
public class UpdateProducts {
    
    @Execution
    public void execution(DataSource dataSource) throws SQLException {
        // DataSource automatically participates in transactions
        // Flamingock uses the target system's DataSource for transaction management
        // and handles transaction start, commit, and rollback automatically
        try (Connection conn = dataSource.getConnection()) {
            try (PreparedStatement stmt = conn.prepareStatement(
                "INSERT INTO products (id, name, price) VALUES (?, ?, ?)")) {
                stmt.setString(1, "P001");
                stmt.setString(2, "Updated Product");
                stmt.setBigDecimal(3, new BigDecimal("19.99"));
                stmt.executeUpdate();
            }
        }
    }
}
```

You can also inject a `Connection` directly if you prefer to work with connections instead of DataSource:

```java
@TargetSystem("inventory-database")
@ChangeUnit(id = "create-indexes", order = "002")
public class CreateIndexes {
    
    @Execution
    public void execution(Connection connection) throws SQLException {
        // Connection automatically participates in transactions
        // Flamingock uses the target system's connection for transaction operations
        // and handles transaction lifecycle automatically
        try (Statement stmt = connection.createStatement()) {
            stmt.execute("CREATE INDEX idx_product_name ON products(name)");
        }
    }
}
```

**How transactions work:**
1. **Connection management**: Flamingock uses the target system's `DataSource` to obtain database connections
2. **Transaction management**: The same `DataSource` or `Connection` handles transaction operations (begin, commit, rollback)
3. **Lifecycle**: Flamingock automatically manages transaction boundaries, committing on success or rolling back on failure

Without the `DataSource` or `Connection` parameter, operations will execute but won't participate in transactions.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject SQL-specific dependencies like `DataSource` and `Connection`, but are not limited to these. Any dependency can be added to the target system context via `.addDependency()`, taking precedence over global dependencies.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)
- See [SQL examples](https://github.com/flamingock/flamingock-examples/tree/master/sql)

---

// File: target-systems/dynamodb-target-system

# DynamoDB Target System

The DynamoDB target system (`DynamoDBTargetSystem`) enables Flamingock to apply changes to Amazon DynamoDB using the AWS SDK for Java. As a transactional target system, it supports automatic rollback through DynamoDB's transaction capabilities with `TransactWriteItems`.

## Minimum recommended setup

```java
DynamoDBTargetSystem dynamoTarget = new DynamoDBTargetSystem("inventory-database")
    .withDynamoDBClient(dynamoDbClient);
```

While dependencies can be provided through the global context, we highly recommend injecting them directly at the target system level. This provides clearer scoping, better isolation between systems, and makes dependencies explicit and easier to track.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `DynamoDbClient` | `.withDynamoDBClient(client)` | AWS DynamoDB client - **required** for both ChangeUnit execution and transaction management |

Remember: If not provided directly via `.withXXX()`, Flamingock searches the global context. If still not found:
- **Required dependencies** will throw an exception

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with specific dependencies
DynamoDBTargetSystem dynamoTarget = new DynamoDBTargetSystem("inventory-database")
    .withDynamoDBClient(inventoryDynamoClient)  // Target-specific client
    .addDependency(inventoryService);           // Custom service for this target

// Global context with different dependencies
Flamingock.builder()
    .addDependency(defaultDynamoClient)         // Different client in global
    .addDependency(emailService)                // Available to all targets
    .addTargetSystems(dynamoTarget)
    .build();
```

**What gets resolved for ChangeUnits in "inventory-database":**
- **DynamoDbClient**: Uses `inventoryDynamoClient` (from target system, not `defaultDynamoClient` from global)
- **InventoryService**: Available from target system context
- **EmailService**: Available from global context

The target system context always takes precedence, ensuring proper isolation between different systems.

## Transactional support

For a ChangeUnit to leverage DynamoDB's transactional capabilities, it must use the `TransactWriteItemsEnhancedRequest.Builder` parameter. Flamingock uses the injected `DynamoDbClient` dependency to create and manage this builder's lifecycle - creating it before execution and executing the transaction with all operations on success.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

```java
@TargetSystem("inventory-database")
@ChangeUnit(id = "update-inventory", order = "001")
public class UpdateInventory {
    
    @Execution
    public void execution(DynamoDbClient client, 
                         TransactWriteItemsEnhancedRequest.Builder txBuilder) {
        // The transaction builder is required for transactional execution
        // Flamingock uses the target system's DynamoDbClient to handle transaction operations
        // and manages transaction creation, execution, and rollback automatically
        
        DynamoDbEnhancedClient enhancedClient = DynamoDbEnhancedClient.builder()
            .dynamoDbClient(client)
            .build();
        
        DynamoDbTable<Product> table = enhancedClient.table("products", 
            TableSchema.fromBean(Product.class));
        
        // Add operations to the transaction
        txBuilder.addPutItem(table, new Product("123", "Updated Product"));
        txBuilder.addDeleteItem(table, Key.builder().partitionValue("456").build());
    }
}
```

**How transactions work:**
1. **Builder creation**: Flamingock uses the target system's `DynamoDbClient` to create a `TransactWriteItemsEnhancedRequest.Builder`
2. **Transaction management**: The same `DynamoDbClient` executes the transaction with all accumulated operations
3. **Lifecycle**: Flamingock automatically creates the builder, executes the transaction on success, or handles rollback on failure

Without the `TransactWriteItemsEnhancedRequest.Builder` parameter, operations will execute but won't participate in transactions.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject DynamoDB-specific dependencies like `DynamoDbClient` and `TransactWriteItemsEnhancedRequest.Builder`, but are not limited to these. Any dependency can be added to the target system context via `.addDependency()`, taking precedence over global dependencies.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)
- See [DynamoDB examples](https://github.com/flamingock/flamingock-examples/tree/master/dynamodb)

---

// File: target-systems/couchbase-target-system

# Couchbase Target System

The Couchbase target system (`CouchbaseTargetSystem`) enables Flamingock to apply changes to Couchbase databases using the official Couchbase Java SDK. As a transactional target system, it supports automatic rollback through Couchbase's transaction capabilities.

## Minimum recommended setup

```java
CouchbaseTargetSystem couchbaseTarget = new CouchbaseTargetSystem("user-database")
    .withCluster(cluster)
    .withBucket(bucket);
```

While dependencies can be provided through the global context, we highly recommend injecting them directly at the target system level. This provides clearer scoping, better isolation between systems, and makes dependencies explicit and easier to track.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### Required dependencies

| Dependency | Method | Description |
|------------|--------|-------------|
| `Cluster` | `.withCluster(cluster)` | Couchbase cluster connection - **required** for both ChangeUnit execution and transaction management |
| `Bucket` | `.withBucket(bucket)` | Target bucket instance - **required** for both ChangeUnit execution and transaction management |

Remember: If not provided directly via `.withXXX()`, Flamingock searches the global context. If still not found:
- **Required dependencies** will throw an exception

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with specific dependencies
CouchbaseTargetSystem couchbaseTarget = new CouchbaseTargetSystem("user-database")
    .withCluster(productionCluster)        // Target-specific cluster
    .withBucket(userBucket)                // Target-specific bucket
    .addDependency(auditService);          // Custom service for this target

// Global context with different dependencies
Flamingock.builder()
    .addDependency(defaultCluster)         // Different cluster in global
    .addDependency(defaultBucket)          // Different bucket in global
    .addDependency(emailService)           // Available to all targets
    .addTargetSystems(couchbaseTarget)
    .build();
```

**What gets resolved for ChangeUnits in "user-database":**
- **Cluster**: Uses `productionCluster` (from target system, not `defaultCluster` from global)
- **Bucket**: Uses `userBucket` (from target system, not `defaultBucket` from global)
- **AuditService**: Available from target system context
- **EmailService**: Available from global context

The target system context always takes precedence, ensuring proper isolation between different systems.

## Transactional support

For a ChangeUnit to leverage Couchbase's transactional capabilities, it must use the `AttemptContext` parameter. Flamingock uses the injected `Cluster` and `Bucket` dependencies to create and manage this context's lifecycle - creating the transaction context before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../flamingock-library-config/transactions.md).

```java
@TargetSystem("user-database")
@ChangeUnit(id = "create-users", order = "001")
public class CreateUsers {
    
    @Execution
    public void execution(Cluster cluster, Bucket bucket, AttemptContext txContext) {
        // AttemptContext is required for transactional execution
        // Flamingock uses the target system's Cluster and Bucket to handle transaction operations
        // and manages transaction start, commit, and rollback automatically
        Collection collection = bucket.defaultCollection();
        
        JsonObject user = JsonObject.create()
            .put("name", "John Doe")
            .put("email", "john@example.com");
            
        txContext.insert(collection, "user::001", user);
    }
}
```

You can also work with the Cluster and Bucket directly without transactions:

```java
@TargetSystem("user-database")
@ChangeUnit(id = "update-configs", order = "002")
public class UpdateConfigs {
    
    @Execution
    public void execution(Cluster cluster, Bucket bucket) {
        // Operations without AttemptContext won't participate in transactions
        Collection collection = bucket.defaultCollection();
        
        JsonObject config = JsonObject.create()
            .put("version", "2.0")
            .put("updated", Instant.now().toString());
            
        collection.upsert("config::app", config);
    }
}
```

**How transactions work:**
1. **Context creation**: Flamingock uses the target system's `Cluster` to create an `AttemptContext` for transaction management
2. **Transaction management**: The same `Cluster` and `Bucket` handle transaction operations and coordinate with the context
3. **Lifecycle**: Flamingock automatically creates the transaction context, commits on success, or rolls back on failure

Without the `AttemptContext` parameter, operations will execute but won't participate in transactions.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject Couchbase-specific dependencies like `Cluster`, `Bucket`, and `AttemptContext` (for transactions), but are not limited to these. Any dependency can be added to the target system context via `.addDependency()`, taking precedence over global dependencies.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)
- See [Couchbase examples](https://github.com/flamingock/flamingock-examples/tree/master/couchbase)

---

// File: target-systems/default-target-system

# Default Target System

The Default target system (`DefaultTargetSystem`) is Flamingock's generic target system for any system that doesn't require specialized handling. It serves as the universal option when no dedicated target system implementation exists or is needed for your specific technology.

## Why use DefaultTargetSystem?

DefaultTargetSystem is the fallback choice when there's no specialized target system implementation available for your technology. While Flamingock provides dedicated target systems for technologies that benefit from specific handling (like transactional systems that leverage native rollback capabilities), many systems don't require such specialization.

**When to use DefaultTargetSystem:**
- No dedicated target system exists for your technology
- Your system doesn't have unique characteristics that warrant specialized handling
- You need a simple, flexible solution without technology-specific optimizations

**Future extensibility:** The Flamingock ecosystem may expand with more specialized target systems as specific needs are identified. 


**Common systems using DefaultTargetSystem:** Kafka Schema Registry, message queues, object storage (S3), REST APIs, file systems, cache systems, feature flags, search engines

## Minimum recommended setup

```java
DefaultTargetSystem schemaRegistry = new DefaultTargetSystem("kafka-schema-registry");
```

Unlike specialized target systems, DefaultTargetSystem requires no mandatory dependencies. You have complete flexibility to inject whatever dependencies your ChangeUnits need.

## Dependencies

Following Flamingock's [dependency resolution hierarchy](../flamingock-library-config/context-and-dependencies.md), you can provide dependencies via direct injection or global context.

### No required dependencies

DefaultTargetSystem has no `.withXXX()` methods for required dependencies. This provides maximum flexibility for working with any type of system.

### Generic dependency injection

All dependencies are provided through generic methods:

| Method | Description |
|--------|-------------|
| `.addDependency(object)` | Add a dependency by type |
| `.addDependency(name, object)` | Add a named dependency |
| `.setProperty(key, value)` | Set a configuration property |

Remember: If not provided directly, Flamingock searches the global context for dependencies.

## Configuration example

Here's a comprehensive example showing dependency resolution:

```java
// Target system with Kafka Schema Registry dependencies
DefaultTargetSystem schemaRegistry = new DefaultTargetSystem("kafka-schema-registry")
    .addDependency(schemaRegistryClient)
    .addDependency("registry-url", "http://schema-registry:8081")
    .setProperty("compatibility.level", "BACKWARD");

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(metricsService)           // Available to all targets
    .addDependency(notificationService)      // Available to all targets
    .addTargetSystems(schemaRegistry)
    .build();
```

**What gets resolved for ChangeUnits in "kafka-schema-registry":**
- **SchemaRegistryClient**: Available from target system context
- **Registry URL**: Available as "registry-url" from target system context  
- **Compatibility level**: Available as property from target system context
- **MetricsService**: Available from global context
- **NotificationService**: Available from global context

The target system context always takes precedence, ensuring proper isolation between different systems.

**How compensation works:**
1. **No transaction boundaries**: Operations execute immediately with no automatic rollback
2. **Rollback execution**: If any failure occurs, Flamingock calls the `@RollbackExecution` method
3. **Manual compensation**: You provide the logic to undo or compensate for the changes made

**Important**: Always provide `@RollbackExecution` methods for DefaultTargetSystem ChangeUnits to ensure safe rollback capabilities.

## Available dependencies in ChangeUnits

Your ChangeUnits can inject any dependencies you add to the target system context via `.addDependency()`, taking precedence over global dependencies. Common examples include system clients, configuration values, custom services, and properties.

For more details on dependency resolution, see [Context and dependencies](../flamingock-library-config/context-and-dependencies.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [ChangeUnits](../change-units/introduction.md)  
- See [DefaultTargetSystem examples](https://github.com/flamingock/flamingock-examples/tree/master/default)

---

// File: templates/templates-introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Templates

:::caution Beta feature
Templates are available in **beta**.  
- You can already create **custom templates** for your own use cases.  
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.  
- We're building a **comprehensive template catalog** where teams can discover, share, and contribute templates for common integration patterns.
- Expect API and behavior changes before GA.  

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of ChangeUnits.
:::

## Introduction

Flamingock Templates are experimental modules designed to streamline the integration of common third-party services, databases, and configurations into the **Flamingock change management system**. These templates provide a structured way to define system changes in declarative format (such as **YAML** files), reducing the need for custom code-based ChangeUnits while ensuring execution and versioning of changes.

## How It Works

Flamingock Templates are designed to simplify change definitions by extracting reusable logic into modular building blocks. While **Flamingock’s core approach** relies on code-based ChangeUnits to manage database and system changes, Flamingock Templates provide a **low-code alternative** that simplifies the process for common integration scenarios. Instead of writing Java classes for each migration, users can leverage existing templates by defining changes in a declarative format(**YAML**, etc.).

### Who Provides Templates?

Templates can be:
- **Provided by the Flamingock core team** (e.g., SQL, Kafka, Redis)
- **Offered by the community**
- **Created internally by teams** to address common patterns in their own systems

This makes them highly adaptable: whether you're integrating a database, messaging system, or internal service, templates give you a low-code mechanism to structure your system changes cleanly and consistently.

### Why Do Templates Exist?

Templates exist to solve a common problem in traditional, code-based changes: **duplicated logic across ChangeUnits**.

Instead of repeating the same boilerplate code over and over, templates let you **externalize the logic** into a reusable definition and **parameterize** what's different.

Today, Flamingock templates can already be created and used in your own projects. However, the official templates provided by the Flamingock team are experimental, and their APIs may change before GA.

## Key Features

- **Experimental, reusable modules**: Each template provides a well-defined structure for managing system changes and configurations.
- **Declarative ChangeUnits**: Users define changes in YAML, avoiding Java boilerplate.
- **Support for third-party integrations**: Includes databases, messaging systems, and cloud configurations.
- **Automatic execution and versioning**: Templates are applied and tracked as part of Flamingock's change management process.
- **Designed to encourage best practices, though still experimental**.
- **Extensible by the community**: Developers can contribute new templates to expand Flamingock's ecosystem.

## When Template-based ChangeUnits Shine

Template-based ChangeUnits are ideal when you have **reusable patterns** in your system changes. They excel in scenarios where the same type of operation needs to be repeated with different parameters, allowing you to avoid duplicating boilerplate code across multiple ChangeUnits.

**Templates shine when:**

- **You have repetitive patterns**: Creating database tables, indexes, Kafka topics, S3 buckets, or API configurations that follow the same structure but with different values
- **Multiple team members need to make similar changes**: Templates provide a consistent, declarative way for developers to define changes without writing boilerplate code
- **You want to enforce best practices**: Templates encapsulate proven logic and prevent implementation inconsistencies across your changes
- **The change type already has a template**: Why reinvent the wheel when S3, Kafka, SQL, MongoDB, or other common templates already exist?

**Stick with code-based ChangeUnits when:**

- **You have unique, one-off logic**: Complex business transformations that are specific to your application and unlikely to be repeated
- **You need maximum flexibility**: Custom integrations or complex workflows that require full programmatic control
- **No suitable template exists**: When your use case doesn't match any available templates and creating a custom template isn't justified

**Remember**: Templates can handle any level of complexity - from simple configuration updates to sophisticated multi-step operations. The decision isn't about complexity, but about **reusability** and whether the pattern is worth abstracting into a declarative format.

Flamingock Templates unlock new possibilities for application evolution. Whether you're managing **databases, configurations, or third-party services**, templates simplify the process, though they are still experimental and not yet recommended for production use. 

:::tip 
Join the [**Flamingock community**](https://github.com/flamingock/flamingock-project/discussions) and start building your own templates today! 🚀
:::

---

// File: templates/templates-how-to-use

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# How to use Flamingock Templates

:::caution Beta feature
Templates are available in **beta**.  
- You can already create **custom templates** for your own use cases.  
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.  
- Expect API and behavior changes before GA.  

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of ChangeUnits.
:::

Using a Flamingock Template is straightforward. Here's an example of how you can apply an SQL-based change using the **SQL Template**.

:::note
This example uses the **SQL Template**, which is experimental. It is intended for testing and feedback, not yet production use.
:::

### Step 1: Add the Template dependency

Ensure your **Flamingock Template** dependency is included in your project. Example of using `sql-template`:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community-sql-template")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-community-sql-template</artifactId>
</dependency>
```
  </TabItem>
</Tabs>

### Step 2: define a Template-based change

In Flamingock, a **ChangeUnit** represents a single unit of work that needs to be applied to your system — for example, creating a table, updating a configuration, or setting up a cloud resource.

When using template-based changes, instead of implementing a code-based file to define the logic of the change, you describe the change in a declarative format (e.g., **YAML** file). The structure you use will depend on the template you’re leveraging.

Create a **YAML file** (e.g., `_0001_create_persons_table.yaml`) inside your application’s resources directory:

```yaml
id: create-persons-table-from-template
order: 1
targetSystem: "database-system"
templateName: sql-template
execution: |
  CREATE TABLE Persons (
    PersonID int,
    LastName varchar(255),
    FirstName varchar(255),
    Address varchar(255),
    City varchar(255)
  )
rollback: "DROP TABLE Persons;"
```

:::info
Note that your application must provide a `java.sql.Connection` instance as a dependency to Flamingock.
:::

#### 🔍 Understanding the configuration attributes

- **`id`**: Unique identifier for the change, used for tracking (same as in code-based changes).
- **`order`**: Execution order relative to other changes (also shared with code-based).
- **`targetSystem`**: Specifies which target system this change applies to - **required** for all template-based changes, just like code-based ChangeUnits.
- **`templateName`**: Indicates which template should be used to handle the change logic. This is **required** for all template-based changes.
- **`execution`**: Direct execution logic for the change. The format depends on the template type (string for SQL, map for MongoDB, etc.).
- **`rollback`**: Direct rollback logic for the change. The format depends on the template type (string for SQL, map for MongoDB, etc.).
- **Other fields**: Templates may define additional configuration fields as needed.

Template-based changes provide both **structure and flexibility**. They share the core concepts of change tracking with code-based ChangeUnits, but use a standardized format with `execution` and `rollback` sections that each template interprets according to its specific requirements.

### Step 3: Configure Flamingock to use the template file

To configure Flamingock to use the YAML template file, you need to define a stage that includes the path to the template file using the `@EnableFlamingock` annotation:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "src/main/resources/templates")
    }
)
public class MainApplication {
    // Configuration class
}
```

If you prefer to use a pipeline YAML file for configuration, refer to the [Setup & Stages guide](../flamingock-library-config/setup-and-stages.md) for more details.

### Step 4: Run Flamingock

At application startup, Flamingock will automatically detect the YAML file and process it as a standard change, following the same execution flow as code-based changes.

## Use case: SQL database changes

Let's compare how an SQL change is handled using a **template-based ChangeUnit** vs. a **traditional code-based ChangeUnit**.

### Approach 1: Using a Traditional Code-Based ChangeUnit

```java
@ChangeUnit(id = "create-persons-table", order = 1, author = "developer")
public class CreatePersonsTableChangeUnit {

    private final DataSource dataSource;

    public CreatePersonsTableChangeUnit(DataSource dataSource) {
        this.dataSource = dataSource;
    }

    @Execution
    public void execute() throws SQLException {
        try (Connection connection = dataSource.getConnection();
             Statement statement = connection.createStatement()) {

            statement.executeUpdate("""
                CREATE TABLE Persons (
                    PersonID int PRIMARY KEY,
                    LastName varchar(255),
                    FirstName varchar(255),
                    Address varchar(255),
                    City varchar(255)
                )
            """);
        }
    }
}

```

### Approach 2: Using a Flamingock SQL Template

With the **SQL Template**, users define the same change in **YAML** instead of Java:

```yaml
id: create-persons-table-from-template
order: 1
targetSystem: "database-system"
templateName: sql-template
execution: |
    CREATE TABLE Persons (
        PersonID int,
        LastName varchar(255),
        FirstName varchar(255),
        Address varchar(255),
        City varchar(255)
    )
rollback: "DROP TABLE Persons;"
```

### Key Benefits of Using a Template Instead of Code-Based ChangeUnits:
- **Less code maintenance**: No need to write Java classes, inject DataSource, manage connections, or handle SQL execution manually.
- **Faster onboarding**: YAML is easier for non-Java developers.
- **Standardised changes**: Ensures best practices and avoids custom implementation errors.
- **Improved readability**: Easier to review and version control.

---

// File: templates/create-your-own-template

# Create your own Flamingock template


:::caution Beta feature
Templates are available in **beta**.  
- You can already create **custom templates** for your own use cases.  
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.  
- Expect API and behavior changes before GA.  

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of ChangeUnits.
:::

While official Flamingock templates are experimental, you can already build and use your own custom templates in production if needed. This page explains how.

## Introduction

[Flamingock Templates](./templates-introduction.md) allow you to encapsulate common logic and reduce boilerplate when defining change units. This document explains how to create your own templates for reuse across projects or for contribution to the Flamingock community.

## Overview of the required components

To create a template, you need:

- A Java class extending `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>`
- An `@Execution` method to perform the main change
- (Optionally) A `@RollbackExecution` method for undo support
- A service loader registration file (`META-INF/services`)
- (Optional) Package and distribute your template

## 1. Implement the Template class

Extend `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>` with three generics:

- **SHARED_CONFIG**: Shared configuration that applies to both execution and rollback (e.g., database connection, common settings). Use `Void` if no shared config is needed.
- **EXECUTION**: The type representing the execution logic/data
- **ROLLBACK**: The type representing the rollback logic/data  

**Example:**

```java
public class MongoChangeTemplate extends AbstractChangeTemplate<Void, MongoOperation, MongoOperation> {

    public MongoChangeTemplate() {
        super(MongoOperation.class);
    }

    @Execution
    public void execute(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional changeUnit[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, execution, clientSession);
    }

    @RollbackExecution
    public void rollback(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional changeUnit[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, rollback, clientSession);
    }

    private void executeOp(MongoDatabase db, MongoOperation op, ClientSession clientSession) {
        op.getOperator(db).apply(clientSession);
    }
}
```

#### Important notes
- Access your execution and rollback data directly via `this.execution` and `this.rollback` fields.
- Access shared configuration via `this.configuration` field (if using a non-Void shared config type).
- If your template references custom types, make sure to register them for reflection—especially for **GraalVM** native builds. When extending `AbstractChangeTemplate`, you can pass your custom types to the superclass constructor to ensure proper reflection support.

:::note 
See [**2. Define Execution and Rollback methods** ](./create-your-own-template#2-define-execution-and-rollback-methods) section for how to implement the core logic inside your template class using the execution/rollback data and dependency injection
:::

## 2. Define Execution and Rollback methods
Each template must include an `@Execution` method, and may optionally include a `@RollbackExecution` method.
These methods define the core logic that will be executed when Flamingock runs the corresponding change.

Inside these methods, it’s expected that you use the data provided by the user in the template-based change unit through the following fields:

- `this.execution` — the execution logic/data to apply during execution
- `this.rollback` — the rollback logic/data to apply during rollback or undo  
- `this.configuration` — shared configuration data (if using a non-Void shared config type)

An example of a template for Kafka topic management:

:::info
This is an illustrative example to demonstrate the template structure. Real Kafka templates would use different parameters and configuration structures based on actual requirements.
:::

```java
public class KafkaTopicTemplate extends AbstractChangeTemplate<Void, TopicConfig, String> {

    public KafkaTopicTemplate() {
        super(TopicConfig.class);
    }

    @Execution
    public void execute(AdminClient adminClient) throws Exception {
        // Create topic using the execution configuration
        NewTopic newTopic = new NewTopic(
            this.execution.getName(),
            this.execution.getPartitions(),
            this.execution.getReplicationFactor()
        );
        newTopic.configs(this.execution.getConfigs());
        
        adminClient.createTopics(List.of(newTopic)).all().get();
    }

    @RollbackExecution
    public void rollback(AdminClient adminClient) throws Exception {
        // Delete topic using the rollback topic name
        adminClient.deleteTopics(List.of(this.rollback)).all().get();
    }
}
```

### Example with Shared Configuration

When you need to share configuration between execution and rollback (such as connection details, common settings, etc.), you can use a non-Void shared configuration type:

:::info
This is an illustrative example to demonstrate the shared configuration pattern. Real S3 templates would use different parameters and configuration structures based on actual AWS SDK requirements.
:::

```java
public class S3BucketTemplate extends AbstractChangeTemplate<S3ConnectionConfig, BucketCreationRequest, String> {

    public S3BucketTemplate() {
        super(S3ConnectionConfig.class, BucketCreationRequest.class);
    }

    @Execution
    public void execute() {
        // Access shared configuration for AWS connection
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();
        
        // Create bucket using execution configuration
        CreateBucketRequest request = new CreateBucketRequest(this.execution.getBucketName())
            .withCannedAcl(this.execution.getAcl());
        
        if (this.execution.getEncryption() != null) {
            // Apply encryption settings
            request.withObjectLockEnabledForBucket(this.execution.getEncryption().isEnabled());
        }
        
        s3Client.createBucket(request);
    }

    @RollbackExecution
    public void rollback() {
        // Use the same shared configuration for rollback
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();
        
        // Delete bucket using rollback bucket name
        s3Client.deleteBucket(this.rollback);
    }
}
```

This pattern is useful when:
- Both execution and rollback need the same configuration data (AWS credentials, region, etc.)
- You want to avoid duplicating connection details or common settings
- The template needs different data for execution vs rollback operations

### Injecting dependencies into Template methods
Template methods (such as those annotated with `@Execution` and `@RollbackExecution`) support method-level dependency injection using the same mechanism as change units.

Template classes do not support constructor injection.
All dependencies must be injected as parameters in the `@Execution` and `@RollbackExecution` methods.

You can inject any registered dependency as a method parameter:

```java
@Execution
public void execute(MongoDatabase db, ClientService clientService) {
  clientService.doSomething();
}
```
:::info
Flamingock will apply lock-safety guards unless you annotate the parameter with `@NonLockGuarded`.
:::

### Mapping between template-base changeUnit file and template methods

Flamingock automatically maps the `execution` and `rollback` sections in your declarative change unit to the corresponding methods in your template class.

## 3. Register the Template with ServiceLoader

Templates are discovered automatically at runtime using Java’s `ServiceLoader` system.

Steps:
1. Create a file at:

```
src/main/resources/META-INF/services/io.flamingock.core.api.template.ChangeTemplate
```

2. List the fully qualified class names of all templates in the file:

```plaintext
io.flamingock.template.kafka.CreateTopicTemplate
io.flamingock.template.kafka.UpdateTopicConfigTemplate
io.flamingock.template.kafka.DeleteTopicTemplate
```

:::tip 
Group templates by domain or technology for better maintainability.
:::

## 4. Package and distribute the Template

Depending on your target:

### Internal Templates (Private)
- No special packaging needed.
- Keep your template class inside your application.

### Public Templates (Contributing to the Community)
- Package your template as a JAR.
- Notify the Flamingock team via [development@flamingock.io](mailto:development@flamingock.io) or GitHub.
- Submit your template for validation.

#### Validation Requirements:
- Clear and justified use case
- Name must align and not conflict with existing templates
- Technically correct and production-grade implementation
- Public classes must be Javadoc-documented
- Submit a Pull Request adding the template's documentation to [flamingock.github.io](https://github.com/flamingock/flamingock.github.io)

## ✅ Best Practices

- Use `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>` with the appropriate generic types for your use case.
- Always provide an `@RollbackExecution` method if rollback or undo is expected.
- Use `Void` for generics when that type is not needed (e.g., `<Void, String, String>` for simple SQL templates).
- Use shared configuration (`<ConfigType, Void, Void>`) when both execution and rollback need the same configuration data.
- Document your template's purpose and generic types clearly for users.
- Ensure all custom types are registered for reflection by passing them to the superclass constructor, especially when targeting native builds.
- Group multiple templates by domain when packaging a library.

---

// File: testing/introduction

## Introduction

This section provides guidance on how to test applications that use **Flamingock**, including strategies for validating your change logic, ensuring proper execution coordination, and maintaining audit and rollback guarantees.

Whether you are running Flamingock in a local development environment, as part of CI pipelines, or through framework integrations like Spring Boot, testing is a key part of ensuring consistency and reliability across deployments.

Flamingock is not limited to database systems — it supports a wide range of targets (e.g., message brokers, file systems, APIs). Your testing strategy should reflect the behavior of the underlying systems you integrate with.


## What to test

There are **three primary levels** at which Flamingock-related functionality can be tested:

### 1. Unit test: Change logic
Isolate and test the logic inside your `@Execution` and `@RollbackExecution` methods without involving Flamingock’s runtime or audit mechanism.

- Use mocks for dependencies (e.g., `MongoTemplate`, `DynamoDbClient`, `S3Client`)
- Focus on business correctness and expected side effects
- No audit logs or locking are involved

👉 See [Unit testing your change units](./unit-testing.md)


### 2. Integration test: Flamingock execution
Run Flamingock end-to-end in a controlled environment to verify:

- Execution of the `@Execution` method
- Audit log persistence
- Rollback behavior on failure

This usually requires a real or containerized backend system (e.g., using **Testcontainers**).

👉 See [Integration testing Flamingock](./integration-testing.md)


### 3. Spring Boot integration
For applications using **Spring Boot**, test how Flamingock integrates with your app lifecycle:

- Use `@SpringBootTest` to validate full configuration
- Confirm that changes run on startup
- Optionally inject mocks to verify execution paths

👉 See [Testing with Spring Boot](./springboot-integration-testing.md)

---

// File: testing/unit-testing

## Introduction

Unit tests focus on verifying the internal logic of a **single change unit**, without relying on any external system.  
They are fast, isolated, and ideal for validating:

- That the `@Execution` method performs the correct logic
- That the `@RollbackExecution` method compensates properly on failure
- That injected dependencies are used as expected (using mocks or fakes)

Unit tests are most useful when your change unit contains business logic, computation, validation, or decisions.


## Example: Creating an S3 bucket

Suppose you have a change unit that creates an Amazon S3 bucket:

```java
@Change(id = "create-bucket", order = "0001", author = "dev-team")
public class _0001_CreateS3BucketChange {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }
}
```


## Writing a unit test

To unit test this class, we use JUnit and a mocking library (e.g., Mockito).  
We'll mock the `S3Client` and verify the correct calls were made.

```java
class _0001_CreateS3BucketChangeTest {

  private final S3Client s3Client = mock(S3Client.class);
  private final CreateS3BucketChange change = new CreateS3BucketChange();

  @Test
  void shouldCallCreateBucketOnExecution() {
    S3Client s3Client = mock(S3Client.class);
    new _0001_CreateS3BucketChange().execute(s3Client);

    verify(s3Client).createBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }

  @Test
  void shouldCallDeleteBucketOnRollback() {
    S3Client s3Client = mock(S3Client.class);
    new _0001_CreateS3BucketChange().rollback(s3Client);
    
    verify(s3Client).deleteBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }
}
```


## ✅ Best practices

- Use mocks or fakes to isolate the dependencies used in your change unit
- Focus only on the logic inside the `@Execution` and `@RollbackExecution` methods
- Keep assertions specific and minimal — check that the right dependencies are called
- Avoid testing Flamingock itself (e.g., locking or audit behavior — that’s handled in integration tests)
- Use descriptive test names like `shouldCallCreateBucketOnExecution()` for readability

---

// File: testing/integration-testing

## Introduction

Integration tests ensure that Flamingock operates correctly in a real environment by executing changes against live systems — such as databases, cloud APIs, or internal services. 

These tests involve spinning up the actual backend system and running Flamingock end-to-end:

- Change unit execution
- Audit log persistence
- Distributed lock acquisition

Integration tests should be used to validate that the full pipeline behaves as expected — from execution to rollback.


## Example: Creating an S3 bucket

Suppose you have a change unit that creates an Amazon S3 bucket:

```java
@Change(id = "create-bucket", order = "0001", author = "dev-team")
public class _0001_CreateS3BucketChange {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }
}
```


## Integration test with Testcontainers

To test this change end-to-end, we will:

1. Spin up a **MongoDB container** to be used as Flamingock’s audit backend
2. Inject a real **S3 client** (mocked, localstack, or real AWS)
3. Configure Flamingock and execute it

```java
class IntegrationTest {

    static final MongoDBContainer mongoContainer = new MongoDBContainer("mongo:6.0");

    @BeforeAll
    static void initMongo() {
        mongoContainer.start();
    }

    @AfterAll
    static void tearDown() {
        mongoContainer.stop();
    }

    @Test
    void shouldExecuteChangeAgainstS3AndAuditToMongo() {
        S3Client s3Client = S3Client.builder()
                .region(Region.EU_WEST_1)
                .build();

        MongoClient mongoClient = MongoClients.create(mongoContainer.getReplicaSetUrl());

        Runner runner = Flamingock.builder()
                .addDependency(s3Client)
                .addDependency(mongoClient)
                .setProperty("mongodb.databaseName", "test-db")
                .build();

        runner.execute();

        // ✅ Verify the S3 bucket was created
        ListBucketsResponse buckets = s3Client.listBuckets();
        boolean bucketExists = buckets.buckets().stream()
                .anyMatch(b -> b.name().equals("flamingock-test-bucket"));
        assertTrue(bucketExists, "Expected S3 bucket was not found");

        // ✅ Verify the change was audited in MongoDB
        MongoDatabase db = mongoClient.getDatabase("test-db");
        MongoCollection<Document> auditCollection = db.getCollection("flamingockAuditLogs");

        Document document = new Document("changeId", "create-bucket")
                .append("state","EXECUTED");
        Document auditEntry = auditCollection.find(document).first();
        assertNotNull(auditEntry, "Flamingock audit log entry was not found in MongoDB");
    }

}
```


## ✅ Best practices

- Use Testcontainers to spin up a real audit backend (e.g., MongoDB) — this avoids the need for manual test setup
- Run Flamingock fully using `.build().execute()` — don’t call internal methods manually
- Clean up the backend between tests or isolate data with unique test identifiers
- Validate changes by checking the actual target system or using custom assertions
- Use integration tests sparingly — unit tests are faster and should cover most logic

---

// File: testing/springboot-integration-testing

## Introduction

This guide explains how to write integration tests for Flamingock when using **Spring Boot** with the `@EnableFlamingock` annotation.

With this setup:

- Flamingock is auto-configured using Spring Boot properties
- Dependencies like `Kafka AdminClient` or `DynamoDbClient`  must be declared as Spring beans
- The change units are executed end-to-end using real systems (e.g., DynamoDB Local, Kafka, S3)

> This test style is ideal for verifying that Flamingock interacts correctly with both its audit backend and any external systems.


## Example: Modifying a Kafka topic and auditing to DynamoDB

Suppose you have a change unit that modifies a Kafka topic configuration:

```java
@Change(id = "modify-topic-config", order = "0002", author = "dev-team")
public class _0002_ModifyKafkaTopicConfig {

  @Execution
  public void execute(AdminClient adminClient) {
    Map<ConfigResource, Config> configs = Map.of(
      new ConfigResource(ConfigResource.Type.TOPIC, "orders"),
      new Config(List.of(new ConfigEntry("retention.ms", "86400000")))
    );

    adminClient.alterConfigs(configs).all().join();
  }

  @RollbackExecution
  public void rollback(AdminClient adminClient) {
    Map<ConfigResource, Config> configs = Map.of(
      new ConfigResource(ConfigResource.Type.TOPIC, "orders"),
      new Config(List.of(new ConfigEntry("retention.ms", "604800000")))
    );

    adminClient.alterConfigs(configs).all().join();
  }
}
```


## Writing the test

In this test, we’ll:

- Spin up **Kafka** and **DynamoDB Local** using Testcontainers
- Provide the required beans (`AdminClient`, `DynamoDbClient`) to Spring Boot
- Assert that the Flamingock change unit executed and was **audited to DynamoDB**

:::info 
Flamingock requires `DynamoDbClient` and other injected services (like `AdminClient`) to be present in the Spring ApplicationContext. Spring Boot will auto-detect them if they are declared as `@Bean`s.
:::
```java
@SpringBootTest
@Testcontainers
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
public class FlamingockSpringbootTest {

  static final KafkaContainer kafka = new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:7.2.1"));
  
  static final GenericContainer<?> dynamoDb = new GenericContainer<>("amazon/dynamodb-local")
      .withExposedPorts(8000);

  @BeforeAll
  static void startContainers() {
    kafka.start();
    dynamoDb.start();
  }

  @AfterAll
  static void stopContainers() {
    kafka.stop();
    dynamoDb.stop();
  }

  @Bean
  public DynamoDbClient dynamoDbClient() {
    return DynamoDbClient.builder()
        .region(Region.US_EAST_1)
        .endpointOverride(URI.create("http://" + dynamoDb.getHost() + ":" + dynamoDb.getFirstMappedPort()))
        .build();
  }

  @Bean
  public AdminClient kafkaAdminClient() {
    Properties config = new Properties();
    config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBootstrapServers());
    return AdminClient.create(config);
  }

  @Test
  void shouldExecuteChangeAndWriteAuditToDynamoDB() {
    DynamoDbClient client = dynamoDbClient();
    ScanResponse scan = client.scan(ScanRequest.builder()
        .tableName("flamingockAuditLogs")
        .build());

    boolean changeExecuted = scan.items().stream()
        .anyMatch(item -> "modify-topic-config".equals(item.get("changeId").s())
                       && "EXECUTED".equals(item.get("state").s()));

    assertTrue(changeExecuted, "Audit log entry for executed change not found in DynamoDB");
  }
}
```


## Advanced configuration

Flamingock can be configured using Spring Boot properties, either in your `application.yml` or dynamically via `@DynamicPropertySource`.

This is especially useful for setting values like:

```java
@DynamicPropertySource
static void overrideProperties(DynamicPropertyRegistry registry) {
  String endpoint = "http://" + dynamoDb.getHost() + ":" + dynamoDb.getFirstMappedPort();
  registry.add("flamingock.dynamodb.readCapacityUnits", () -> 5L);
  registry.add("flamingock.dynamodb.writeCapacityUnits", () -> 5L);
  registry.add("flamingock.dynamodb.autoCreate", () -> true);
  registry.add("flamingock.dynamodb.auditRepositoryName", () -> "flamingockAuditLogs");
  registry.add("flamingock.dynamodb.lockRepositoryName", () -> "flamingockLocks");
}
```

These properties allow Flamingock to connect to the appropriate DynamoDB instance and create its internal metadata tables automatically.


## Best practices

- Declare all required dependencies (like `DynamoDbClient`, `AdminClient`, etc.) as Spring beans
- Use `@DynamicPropertySource` to inject dynamic config for local/test environments
- Validate both the **external effect** (Kafka, S3, etc.) and the **audit record** in the backend
- Use `Testcontainers` for isolation and reproducibility across environments
- Keep tests focused: use Spring Boot only when testing real integration scenarios (not just logic)