// File: overview

# Flamingock Documentation


**Flamingock** brings *Change-as-Code (CaC)* to your entire stack.
It applies **versioned, auditable changes** to the external systems your application depends on ‚Äî such as schemas, message brokers, databases, APIs, cloud services, and any other external system your application needs.

Unlike infrastructure-as-code tools, Flamingock runs **inside your application** (or via the **CLI**).
It ensures these systems evolve **safely, consistently, and in sync with your code at runtime**.

üëâ For a deeper explanation, see the [Introduction](./get-started/Introduction)

---

## üîé What It Looks Like

A simple change in Flamingock:

```java
@TargetSystem("user-database")
@Change(id = "create-users-collection", author = "dev-team")
public class _0001__CreateUsersCollection {
    @Apply
    public void apply(MongoDatabase db) {
        db.createCollection("users");
    }
}
```

*When your app starts, Flamingock applies this change and records it in the Audit Store.*


## üöÄ Getting Started

- üëâ [What is Flamingock?](./get-started/introduction) ‚Äì learn the core ideas and principles
- üëâ [Quick Start](./get-started/quick-start) ‚Äì set up Flamingock in minutes
- üëâ [Core Concepts](./get-started/core-concepts) ‚Äì understand the building blocks
- üëâ [FAQ](./resources/faq) ‚Äì Frequently asked questions

---

## üõ† Editions

| Edition                        | Description                                                                |
|--------------------------------|----------------------------------------------------------------------------|
| üü¢ **Community Edition (CE)**  | Open-source, library only                                                  |
| ‚òÅÔ∏è **Cloud Edition**           | SaaS with dashboard, observability, and premium features **(coming soon)** |
| üè¢ **Self-Hosted Edition**     | Same as Cloud, deployable in your infrastructure **(coming soon)**         |


---

## üîç Resources

- [GitHub repository](https://github.com/flamingock/flamingock-java)
- [Examples GitHub repository](https://github.com/flamingock/flamingock-java-examples)
- [Releases](https://github.com/flamingock/flamingock-java/releases)
- [Issue tracker](https://github.com/flamingock/flamingock-java/issues)

---

// File: audit-stores/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Audit stores

The audit store is Flamingock's dedicated system for tracking execution history, preventing duplicate executions, and ensuring safe system evolution.

## What is the audit store?

The audit store tracks:
- **Execution history**: Which Changes ran, when, and with what outcome
- **Distributed locking**: Prevents concurrent executions across multiple instances
- **Issue tracking**: Failed or uncertain executions requiring resolution

### Relationship with Target Systems
Although they serve different purposes, the Audit Store is **built directly from a Target System**.

This means it **reuses the same underlying connection and driver** (e.g., the same MongoDB client or Couchbase cluster) to store its metadata. However, it uses a separate internal handle to ensure that audit data remains logically isolated from your business data.

Unlike target systems (which your code modifies), the audit store is managed automatically by Flamingock and never modified by your Changes.

> **Conceptual overview**: For architectural understanding, see [Target systems vs audit store](../get-started/audit-store-vs-target-system.md)


## Cloud audit store
The audit store is **automatically provided and managed** by Flamingock Cloud. No configuration needed - just focus on your changes while Flamingock handles the audit infrastructure.

## Community audit store
Alternatively, you can configure your own audit store using one of the supported databases:

- [MongoDB audit store](./community/mongodb-audit-store.md)
- [DynamoDB audit store](./community/dynamodb-audit-store.md)
- [Couchbase audit store](./community/couchbase-audit-store.md)
- [SQL audit store](./community/sql-audit-store.md)


### Registering the community audit store

<Tabs groupId="registration">
  <TabItem value="builder" label="Flamingock Builder" default>
Register the audit store with the Flamingock builder:

```java
// Generic example - audit store configuration
public class App {
  public static void main(String[] args) {

    // TargetSystem
    var targetSystem = new MongoDBSyncTargetSystem("mongodb-ts", mongoClient, "dbName");

    // Create your audit store connection
    var auditStore = MongoDBSyncAuditStore.from(targetSystem);

    // Register with Flamingock
    Flamingock.builder()
      .setAuditStore(auditStore)  // Set the audit store
      .addTargetSystems(targetSystem)
      .build()
      .run();
  }
}
```
  </TabItem>
  <TabItem value="springboot" label="Spring Boot">

For Spring Boot applications, register audit stores as beans:

```java
@Bean
public AuditStore auditStore(MongoDBSyncTargetSystem mongoDBSyncTargetSystem) {
    return MongoDBSyncAuditStore.from(mongoDBSyncTargetSystem);
}

// Flamingock Spring Boot auto-configuration will pick this up automatically
```

Spring Boot's auto-configuration will automatically register these audit stores with Flamingock.

For more details, see [Spring Boot Integration](../frameworks/springboot-integration/introduction.md).

  </TabItem>
</Tabs>

---

// File: audit-stores/community/mongodb-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Audit Store

The MongoDB audit store (`MongoDBSyncAuditStore`) enables Flamingock to record execution history and ensure safe coordination across distributed deployments using MongoDB as the storage backend.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../get-started/audit-store-vs-target-system.md).

## Version compatibility

| Component           | Version Requirement |
|---------------------|---------------------|
| MongoDB Java Driver | 4.0.0+              |

MongoDB 4.0+ is recommended for optimal performance and feature support.

## Installation

Add the MongoDB Java sync driver dependency to your project:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("org.mongodb:mongodb-driver-sync:5.2.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>org.mongodb</groupId>
    <artifactId>mongodb-driver-sync</artifactId>
    <version>5.2.0</version> <!-- 4.0.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the audit store using a MongoDB Target System to get the connection configuration:

```java
var auditStore = MongoDBSyncAuditStore.from(mongoDbTargetSystem);
```

A `MongoDBSyncAuditStore` must be created from an existing `MongoDBSyncTargetSystem`.

This ensures that both components point to the **same external MongoDB database**:

- The **Target System** applies your business changes.
- The **Audit Store** stores the execution history associated with those changes.

Internally, the Audit Store takes the Target System‚Äôs connection settings (MongoClient + database name) and creates its **own dedicated access handle**, keeping audit operations isolated while still referring to the same physical system.

> For a full conceptual explanation of this relationship, see
> **[Target Systems vs Audit Store](../../get-started/audit-store-vs-target-system.md)**.

Optional configurations can be added via `.withXXX()` methods.

:::info Register Audit Store
Once created, you need to register this audit store with Flamingock. See [Registering the community audit store](../introduction.md#registering-the-community-audit-store) for details.
:::

## Optional configuration (.withXXX() methods)

These configurations can be customized via `.withXXX()` methods with **no global context fallback**:

| Configuration           | Method                           | Default                 | Description                           |
|-------------------------|----------------------------------|-------------------------|---------------------------------------|
| `Auto Create`           | `.withAutoCreate(enabled)`       | `true`                  | Auto-create collections and indexes   |
| `WriteConcern`          | `.withWriteConcern(concern)`     | `MAJORITY` with journal | Write acknowledgment level            |
| `ReadConcern`           | `.withReadConcern(concern)`      | `MAJORITY`              | Read isolation level                  |
| `ReadPreference`        | `.withReadPreference(pref)`      | `PRIMARY`               | Server selection for reads            |
| `Audit Repository Name` | `.withAuditRepositoryName(name)` | `flamingockAuditLog`    | Collection name for audit entries     |
| `Lock Repository Name`  | `.withLockRepositoryName(name)`  | `flamingockLock`        | Collection name for distributed locks |

**Important**: These default values are optimized for maximum consistency and should ideally be left unchanged. Override them only for testing purposes or exceptional cases.

## Configuration example

Here's a comprehensive example showing the configuration:

```java
// Create a MongoDB Target System
MongoDBSyncTargetSystem mongoDbSyncTargetSystem = new MongoDBSyncTargetSystem("mongodb", mongoClient, auditDatabase);
// Audit store configuration (mandatory via constructor)
var auditStore = MongoDBSyncAuditStore.from(mongoDbSyncTargetSystem)
    .withWriteConcern(WriteConcern.W1)         // Optional configuration
    .withReadPreference(ReadPreference.secondary());  // Optional configuration

// Register with Flamingock
Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(targetSystems...)
    .build();
```

**Audit store configuration resolution:**
- **MongoDBSyncTargetSystem**: Must be provided via `from()` method. Gets `MongoClient` and `DatabaseName` from the target system.
- **WriteConcern**: Uses explicit configuration instead of default
- **ReadPreference**: Uses explicit configuration instead of default

This architecture ensures explicit audit store configuration with no fallback dependencies.

## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)
- üëâ See a [full example project](https://github.com/flamingock/flamingock-java-examples)

---

// File: audit-stores/community/sql-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# SQL Audit Store

The SQL audit store (`SqlAuditStore`) enables Flamingock to record execution history and ensure safe coordination across distributed deployments using any supported SQL database as the storage backend.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../get-started/audit-store-vs-target-system.md).

## Supported databases

:::info Automatic Dialect Detection
Flamingock automatically detects the database vendor from the DataSource connection metadata and applies the appropriate SQL dialect. No manual configuration required.
:::

The following databases are supported:

| Database     | Auto-detection | Notes                                    |
|--------------|----------------|------------------------------------------|
| MySQL        | ‚úÖ             | 5.7+ recommended                         |
| MariaDB      | ‚úÖ             | 10.3+ recommended                        |
| PostgreSQL   | ‚úÖ             | 12+ recommended                          |
| SQLite       | ‚úÖ             | Suitable for testing and local development |
| H2           | ‚úÖ             | Ideal for testing environments           |
| SQL Server   | ‚úÖ             | 2017+ recommended                        |
| Oracle       | ‚úÖ             | 19c+ recommended                         |
| Sybase       | ‚úÖ             | ASE 16+ recommended                      |
| Firebird     | ‚úÖ             | 3.0+ recommended                         |
| Informix     | ‚úÖ             | 12.10+ recommended                       |
| DB2          | ‚úÖ             | 11.5+ recommended                        |

## Installation

Add your preferred JDBC driver dependency to your project:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
// PostgreSQL example
implementation("org.postgresql:postgresql:42.7.0")

// MySQL example
implementation("mysql:mysql-connector-java:8.0.33")

```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- PostgreSQL example -->
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.7.0</version>
</dependency>

<!-- MySQL example -->
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>8.0.33</version>
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the audit store using a SQL Target System to get the connection configuration:

```java
var auditStore = SqlAuditStore.from(sqlTargetSystem);
```

A `SqlAuditStore` must be created from an existing `SqlTargetSystem`.

This ensures that both components point to the **same external SQL instance**:

- The **Target System** applies your business changes.
- The **Audit Store** stores the execution history associated with those changes.

Internally, the Audit Store takes the Target System‚Äôs connection settings (SQL Datasource) and creates its **own dedicated access handle**, keeping audit operations isolated while still referring to the same physical system.

> For a full conceptual explanation of this relationship, see
> **[Target Systems vs Audit Store](../../get-started/audit-store-vs-target-system.md)**.

Optional configurations can be added via `.withXXX()` methods.

:::info Register Audit Store
Once created, you need to register this audit store with Flamingock. See [Registering the community audit store](../introduction.md#registering-the-community-audit-store) for details.
:::

## Optional configuration (.withXXX() methods)

These configurations can be customized via `.withXXX()` methods with **no global context fallback**:

| Configuration           | Method                           | Default              | Description                           |
|-------------------------|----------------------------------|----------------------|---------------------------------------|
| `Auto Create`           | `.withAutoCreate(enabled)`       | `true`               | Auto-create tables and indexes        |
| `Audit Repository Name` | `.withAuditRepositoryName(name)` | `flamingockAuditLog` | Table name for audit entries          |
| `Lock Repository Name`  | `.withLockRepositoryName(name)`  | `flamingockLock`     | Table name for distributed locks      |

**Important**: These default values are optimized for maximum consistency and should ideally be left unchanged. Override them only for testing purposes or exceptional cases.

## Configuration example

Here's a comprehensive example showing the configuration:

```java
// Create a SQL Target System
SqlTargetSystem sqlTargetSystem = new SqlTargetSystem("sql", dataSource);
// Audit store configuration (mandatory via constructor)
var auditStore = SqlAuditStore.from(couchbaseTargetSystem)
    .withAutoCreate(true)                          // Optional configuration
    .withAuditRepositoryName("custom_audit_log")   // Optional configuration
    .withLockRepositoryName("custom_lock_table");  // Optional configuration

// Register with Flamingock
Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(targetSystems...)
    .build();
```

**Audit store configuration resolution:**
- **SqlTargetSystem**: Must be provided via `from()` method. Gets `Datasource` from the target system.
- **Database dialect**: Automatically detected from DataSource vendor
- **Table configurations**: Uses explicit configuration instead of defaults

This architecture ensures explicit audit store configuration with no fallback dependencies.

## Database-specific examples

### PostgreSQL
```java
// PostgreSQL DataSource configuration
HikariConfig config = new HikariConfig();
config.setJdbcUrl("jdbc:postgresql://localhost:5432/mydb");
config.setUsername("user");
config.setPassword("password");
config.setDriverClassName("org.postgresql.Driver");

DataSource dataSource = new HikariDataSource(config);
SqlTargetSystem sqlTargetSystem = new SqlTargetSystem("sql", dataSource);
var auditStore = SqlAuditStore.from(sqlTargetSystem);
```

### MySQL
```java
// MySQL DataSource configuration
HikariConfig config = new HikariConfig();
config.setJdbcUrl("jdbc:mysql://localhost:3306/mydb");
config.setUsername("user");
config.setPassword("password");
config.setDriverClassName("com.mysql.cj.jdbc.Driver");

DataSource dataSource = new HikariDataSource(config);
SqlTargetSystem sqlTargetSystem = new SqlTargetSystem("sql", dataSource);
var auditStore = SqlAuditStore.from(sqlTargetSystem);
```

## Schema management

When `autoCreate` is enabled (default), Flamingock automatically creates the required tables:

- **Audit table** (default: `flamingockAuditLog`): Stores execution history
- **Lock table** (default: `flamingockLock`): Manages distributed locking

The SQL schemas are automatically optimized for each supported database dialect.

:::tip Database Permissions
Ensure your database user has `CREATE TABLE` and `CREATE INDEX` permissions when using `autoCreate=true`.
:::

## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)
- üëâ See a [full example project](https://github.com/flamingock/flamingock-java-examples)

---

// File: audit-stores/community/dynamodb-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# DynamoDB Audit Store

The DynamoDB audit store (`DynamoSyncAuditStore`) enables Flamingock to record execution history and ensure safe coordination across distributed deployments using Amazon DynamoDB as the storage backend.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../get-started/audit-store-vs-target-system.md).

## Version compatibility

| Component                 | Version Requirement |
|---------------------------|---------------------|
| AWS SDK DynamoDB Enhanced | 2.25.0+             |

AWS SDK DynamoDB Enhanced 2.25.0+ is required and must be included in your project dependencies.

## Installation

Add the AWS SDK DynamoDB Enhanced dependency to your project:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("software.amazon.awssdk:dynamodb-enhanced:2.28.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>dynamodb-enhanced</artifactId>
    <version>2.28.0</version> <!-- 2.25.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the audit store using a DynamoDB Target System to get the connection configuration:

```java
var auditStore = DynamoDBAuditStore.from(dynamoDBTargetSystem);
```

A `DynamoDBAuditStore` must be created from an existing `DynamoDBTargetSystem`.

This ensures that both components point to the **same external DynamoDB instance**:

- The **Target System** applies your business changes.
- The **Audit Store** stores the execution history associated with those changes.

Internally, the Audit Store takes the Target System‚Äôs connection settings (DynamoClient) and creates its **own dedicated access handle**, keeping audit operations isolated while still referring to the same physical system.

> For a full conceptual explanation of this relationship, see
> **[Target Systems vs Audit Store](../../get-started/audit-store-vs-target-system.md)**.

Optional configurations can be added via `.withXXX()` methods.

:::info Register Audit Store
Once created, you need to register this audit store with Flamingock. See [Registering the community audit store](../introduction.md#registering-the-community-audit-store) for details.
:::

## Optional configuration (.withXXX() methods)

These configurations can be customized via `.withXXX()` methods with **no global context fallback**:

| Configuration           | Method                           | Default              | Description                                  |
|-------------------------|----------------------------------|----------------------|----------------------------------------------|
| `Auto Create`           | `.withAutoCreate(enabled)`       | `true`               | Auto-create table                            |
| `Read Capacity Units`   | `.withReadCapacityUnits(units)`  | `5`                  | Read capacity units (PROVISIONED mode only)  |
| `Write Capacity Units`  | `.withWriteCapacityUnits(units)` | `5`                  | Write capacity units (PROVISIONED mode only) |
| `Audit Repository Name` | `.withAuditRepositoryName(name)` | `flamingockAuditLog` | Table name for audit entries                 |
| `Lock Repository Name`  | `.withLockRepositoryName(name)`  | `flamingockLock`     | Table name for distributed locks             |

‚ö†Ô∏è **Warning**: Adjust capacity units based on your workload. Under-provisioning may cause throttling.
Consider using **ON_DEMAND** billing mode for unpredictable workloads.

## Configuration example

Here's a comprehensive example showing the configuration:

```java
// Create a DynamodDB Target System
DynamodDBTargetSystem dynamoDBTargetSystem = new DynamodDBTargetSystem("dynamodb", dynamoDbClient);
// Audit store configuration (mandatory via constructor)
var auditStore = DynamoSyncAuditStore.from(dynamoDBTargetSystem)
    .withReadCapacityUnits(10)     // Optional configuration
    .withWriteCapacityUnits(10);   // Optional configuration

// Register with Flamingock
Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(targetSystems...)
    .build();
```

**Audit store configuration resolution:**
- **DynamoDBTargetSystem**: Must be provided via `from()` method. Gets `DynamoClient` from the target system.
- **Capacity settings**: Uses explicit configuration via properties

This architecture ensures explicit audit store configuration with no fallback dependencies.

## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)
- üëâ See a [full example project](https://github.com/flamingock/flamingock-java-examples)

---

// File: audit-stores/community/couchbase-audit-store

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Couchbase Audit Store

The Couchbase audit store (`CouchbaseSyncAuditStore`) enables Flamingock to record execution history and ensure safe coordination across distributed deployments using Couchbase as the storage backend.

> For a conceptual explanation of the audit store vs target systems, see [Audit store vs target system](../../get-started/audit-store-vs-target-system.md).

## Version compatibility

| Component             | Version Requirement |
|-----------------------|---------------------|
| Couchbase Java Client | 3.6.0+              |

Couchbase Java Client 3.6.0+ is required and must be included in your project dependencies.

## Installation

Add the Couchbase Java Client dependency to your project:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("com.couchbase.client:java-client:3.7.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>com.couchbase.client</groupId>
    <artifactId>java-client</artifactId>
    <version>3.7.0</version> <!-- 3.6.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the audit store using a Couchbase Target System to get the connection configuration:

```java
var auditStore = CouchbaseAuditStore.from(couchbaseTargetSystem);
```

A `CouchbaseAuditStore` must be created from an existing `CouchbaseTargetSystem`.

This ensures that both components point to the **same external Couchbase bucket**:

- The **Target System** applies your business changes.
- The **Audit Store** stores the execution history associated with those changes.

Internally, the Audit Store takes the Target System‚Äôs connection settings (cluster + bucket name) and creates its **own dedicated access handle**, keeping audit operations isolated while still referring to the same physical system.

> For a full conceptual explanation of this relationship, see
> **[Target Systems vs Audit Store](../../get-started/audit-store-vs-target-system.md)**.

Optional configurations can be added via `.withXXX()` methods.

:::info Register Audit Store
Once created, you need to register this audit store with Flamingock. See [Registering the community audit store](../introduction.md#registering-the-community-audit-store) for details.
:::

## Optional configuration (.withXXX() methods)

These configurations can be customized via `.withXXX()` methods with **no global context fallback**:

| Configuration           | Method                           | Default              | Description                                   |
|-------------------------|----------------------------------|----------------------|-----------------------------------------------|
| `Auto Create`           | `.withAutoCreate(enabled)`       | `true`               | Auto-create collections and indexes           |
| `Scope Name`            | `.withScopeName(name)`           | `_default`           | Scope where audit collections will be created |
| `Audit Repository Name` | `.withAuditRepositoryName(name)` | `flamingockAuditLog` | Collection name for audit entries             |
| `Lock Repository Name`  | `.withLockRepositoryName(name)`  | `flamingockLock`     | Collection name for distributed locks         |

‚ö†Ô∏è **Warning**: Ensure your Couchbase user has permissions to create collections if `autoCreate` is enabled.

## Configuration example

Here's a comprehensive example showing the configuration:

```java
// Create a Couchbase Target System
CouchbaseTargetSystem couchbaseTargetSystem = new CouchbaseTargetSystem("couchbase", cluster, "bucketName");
// Audit store configuration (mandatory via constructor)
var auditStore = CouchbaseSyncAuditStore.from(couchbaseTargetSystem)
    .withScopeName("custom-scope")     // Optional configuration
    .withAutoCreate(true);             // Optional configuration

// Register with Flamingock
Flamingock.builder()
    .setAuditStore(auditStore)
    .addTargetSystems(targetSystems...)
    .build();
```

**Audit store configuration resolution:**
- **CouchbaseTargetSystem**: Must be provided via `from()` method. Gets `Cluster` and `BucketName` from the target system.
- **Scope settings**: Uses explicit configuration via properties

This architecture ensures explicit audit store configuration with no fallback dependencies.

## Next steps

- Learn about [Target systems](../../target-systems/introduction.md)
- üëâ See a [full example project](https://github.com/flamingock/flamingock-java-examples)

---

// File: changes/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Changes

A **Change** is the atomic, versioned, self-contained unit of change in Flamingock. It encapsulates logic to evolve [**target systems**](../get-started/audit-store-vs-target-system.md) safely, deterministically, and with complete auditability.

## Key characteristics

- **Atomic execution**: Each Change runs exactly once
- **Ordered sequence**: Executed based on their `order` property
- **Auditable**: Recorded in the audit store to prevent duplicate execution
- **Safe by default**: If Flamingock is uncertain about a change's outcome, it stops and requires manual intervention
- **Rollback capable**: Can be undone through rollback methods

## What Changes can do?

Changes enable you to version and track changes across your entire technology stack:

- **Message queue operations**: Topic creation, schema registry updates
- **Object storage**: Bucket setup, file migrations, policy updates
- **Database migrations**: Schema changes, data transformations, index creation
- **External API integrations**: Service configurations, webhook setups
- **Infrastructure changes**: Feature flag updates, configuration changes

## Types of Changes


<Tabs groupId="edition">
  <TabItem value="code" label="Code based" default>
Written in Java, Kotlin, or Groovy with annotations. Best for complex logic or when you need full programmatic control.

```java
@TargetSystem("user-database")
@Change(id = "add-user-status", author = "dev-team")
public class _0001__AddUserStatus {

    @Apply
    public void apply(MongoDatabase database) {
        // Your change logic here
    }

    @Rollback
    public void rollback(MongoDatabase database) {
        // Your rollback logic here
    }
}
```

  </TabItem>
  <TabItem value="template" label="Template based">
Use YAML or JSON definitions with reusable templates. Perfect for repetitive operations and standardized patterns.

```yaml
# File: _0002__AddStatusColumn.yaml
id: add_status_column
author: "db-team"
template: SqlTemplate
targetSystem: "sql-target-system"
apply: "ALTER TABLE orders ADD COLUMN status VARCHAR(20);"
rollback: "ALTER TABLE orders DROP COLUMN status;"
```

  </TabItem>
</Tabs>



## Safety and recovery

While Change executions typically complete successfully, Flamingock provides configurable recovery strategies to handle any exceptional circumstances that may arise. If results are uncertain, Flamingock stops and requires manual intervention rather than risking data corruption, ensuring you always know the exact state of your systems.

You can configure different recovery strategies based on your requirements. For complete details on failure handling and recovery workflows, see [Safety and Recovery](../safety-and-recovery/introduction.md).

## Next steps

Dive deeper into specific aspects of Changes:

- **[Anatomy & Structure](./anatomy-and-structure.md)** - Learn the technical structure, required properties, and annotations
- **[Types & Implementation](./types-and-implementation.md)** - Understand code-based vs template-based approaches
- **[Best Practices](./best-practices.md)** - Follow proven patterns for reliable Changes

Or continue to other key concepts:
- **[Target Systems](../target-systems/introduction.md)** - Configure where your changes will be applied
- **[Templates](../templates/templates-introduction.md)** - Explore reusable change patterns

---

// File: changes/anatomy-and-structure

# Change Anatomy & Structure

Every Change is configured through key components that work together, following the natural development workflow:

- **[File name](#file-name-and-order)**: Created first, determines execution order and change name.
- **[`@Change` annotation](#change-annotation-properties)**: Defines the Change's unique identifier (`id`) and author for accountability. 
- **[`@TargetSystem` annotation](#target-system-annotation)**: Specifies which system the Change will affect.
- **[Apply and rollback methods](#apply-and-rollback-methods)**: Implement the actual change logic.

Understanding this anatomy is essential for creating reliable changes that execute predictably and safely.

## Complete example

Here's what a complete Change looks like with minimal configuration - we'll explain each component in detail below:

```java
@TargetSystem("user-database")
@Change(id = "add-user-status", author = "backend-team")
public class _0001__AddUserStatus {

    @Apply
    public void apply(MongoDatabase database) {
        database.getCollection("users")
                .updateMany(
                    new Document("status", new Document("$exists", false)),
                    new Document("$set", new Document("status", "active"))
                );
    }

    @Rollback
    public void rollback(MongoDatabase database) {
        database.getCollection("users")
                .updateMany(
                    new Document(),
                    new Document("$unset", new Document("status", ""))
                );
    }
}
```

Now let's break down each component:

## File name and order

The execution order of Changes is determined by the filename pattern. Every Change file must follow the `_ORDER__CHANGE-NAME` format.

### File naming pattern

**Pattern**: `_ORDER__CHANGE-NAME.[java|yaml]`

- **ORDER**: Alphanumeric string (required: at least 4 characters, left-padded zeros)
- **Double underscore `__`**: Separates order from change name
- **CHANGE-NAME**: PascalCase descriptive name

**Examples:**
```
_0001__CreateInvoiceCollection.java
_0002__AddUserStatusColumn.yaml
_0003__MigrateUserData.java
_0010__OptimizeQueries.java
```

### How Flamingock extracts order

Flamingock uses a simple rule to determine execution order:

1. **Filename must start with underscore `_`**
2. **Everything between the first `_` and `__` (double underscore) becomes the order**
3. **Everything after `__` is the descriptive name**

**Name examples:**

| Filename | Extracted Order | Change Name |
|----------|----------------|-------------|
| `_0001__CreateUsers.java` | `0001` | `CreateUsers` |
| `_0010__SimpleChange.yaml` | `0010` | `SimpleChange` |
| `_V1_2__DatabaseUpgrade.java` | `V1_2` | `DatabaseUpgrade` |

**Order rules:**
- **Required**: Orders must be at least 4 characters (compilation requirement)
- **Recommended format**: `NNNN` with left-padding zeros (e.g., `0001`, `0002`, `0010`)
- **Flexibility**: Can contain any characters valid for OS filenames and Java class names
- **Evaluation**: Orders are compared alphanumerically for execution sequence
- **Immutability**: Cannot be changed once deployed

## Change annotation properties

The `@Change` annotation must define these two properties, with optional properties available (covered later):

### `id` - Unique identifier
The `id` must be unique across all Changes in your application.

```java
@Change(id = "add-user-status", author = "dev-team")
```

**Rules:**
- Must be unique application-wide
- Use descriptive names (e.g., `add-user-status`, not `change1`)
- Cannot be modified once deployed

### `author` - Responsibility tracking
Identifies who is responsible for this change.

```java
@Change(id = "update-schema", author = "database-team")
@Change(id = "migrate-users", author = "john.doe@company.com")
```

**Best practices:**
- Use team names for shared responsibility: `database-team`, `api-team`
- Use individual emails for personal changes: `john.doe@company.com`
- Keep consistent within your organization

## Target system annotation

### `@TargetSystem` - System specification
Declares which target system this Change affects.

```java
@TargetSystem("user-database")
@Change(id = "add-user-fields", author = "api-team")
public class _0001__AddUserFields {
    // Implementation
}
```

## Apply and rollback methods

Both methods implement your change logic and automatically receive the dependencies they need through parameters.

### `@Apply` - Change logic
Contains the actual change implementation.

```java
@Apply
public void apply(S3Client s3) {
    // Your change logic here
    s3.putBucketPolicy(/* configure bucket */);
}
```

### `@Rollback` - Undo logic
Provides logic to reverse the change, essential for safety and CLI undo operations.

```java
@Rollback
public void rollback(S3Client s3) {
    // Undo the change
    s3.deleteBucketPolicy(/* remove configuration */);
}
```

**Why rollback is required:**
- Executed automatically on failure for non-transactional systems
- Required for CLI/UI undo operations
- Ensures every change can be reversed

For detailed information about method parameters, dependency injection, and advanced parameter features, see [Apply and rollback methods](./apply-and-rollback-methods.md).



## Optional properties

The `@Change` annotation supports additional optional properties to control behavior:

### `transactional` - Transaction behavior
Controls whether the change runs within a transaction (default: `true`).

```java
@Change(
    id = "create-large-index",
    author = "db-team",
    transactional = false  // DDL operations may require this
)
```

**Important:** For non-transactional target systems (S3, Kafka, etc.), this flag has no effect.

### `recovery` - Failure handling strategy
Controls how Flamingock handles execution failures (default: `MANUAL_INTERVENTION`).

```java
// Default behavior (manual intervention)
@Change(id = "critical-change", author = "team")
public class _0001__CriticalChange {
    // Execution stops on failure, requires manual resolution
}

// Automatic retry
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
@Change(id = "idempotent-change", author = "team")
public class _0002__IdempotentChange {
    // Automatically retries on failure until successful
}
```

**Recovery strategies:**
- `MANUAL_INTERVENTION` (default): Stops execution on failure, requires CLI resolution
- `ALWAYS_RETRY`: Automatically retries on subsequent executions until successful

For detailed information on recovery strategies, see [Safety and Recovery](../safety-and-recovery/introduction.md).

## Next steps

- **[Change types & implementation](./types-and-implementation)** - Deep dive into code-based vs template-based approaches
- **[Change best practices](./best-practices)** - Learn proven patterns for reliable Changes
- **[Target systems](../target-systems/introduction)** - Configure where your changes will be applied

---

// File: changes/apply-and-rollback-methods

# Apply and rollback methods

## Quick start

Your Change methods receive the dependencies they need as parameters - Flamingock automatically provides them.

### Basic examples

```java
@Apply
public void apply(S3Client s3Client, AdminClient adminClient, FeatureFlagService flags) {

}

@Rollback
public void rollback(S3Client s3Client, AdminClient adminClient, FeatureFlagService flags) {

}
```

**Why rollback is required:**
- Executed automatically on failure for non-transactional systems
- Required for  undo operations
- Ensures every change can be reversed

## Where parameters come from

Flamingock resolves method parameters from three sources (in priority order):

1. **Target system context** - System-specific dependencies
2. **Global context** - Shared application dependencies
3. **Framework context** - e.g., Spring beans

The exact dependencies available depend on your target system and configuration.

See [Context and Dependencies](../flamingock-library-config/context-and-dependencies.md) for complete details on configuring and understanding available dependencies.

## Method rules

- **Must be public** - Flamingock needs to invoke them
- **Any name works** - `apply`, `execute`, `migrate`, your choice
- **Return type ignored** - Can be void or return a value
- **All parameters injected** - No manual parameters

---

## Advanced topics

### Type-based injection

Parameters are injected based on their type:

```java
@Apply
public void apply(KafkaTemplate kafka, ConfigService config) {
    // Flamingock looks for matching types in the context
}
```

### Named parameters

Use `@Named` when multiple beans of the same type exist:

```java
@Apply
public void apply(
    @Named("orders") KafkaTemplate ordersKafka,
    @Named("notifications") KafkaTemplate notificationsKafka
) {
    // Specific instances by name
}
```

### Optional parameters

By default, all parameters are required. Missing dependencies throw exceptions.

Use `@Nullable` for optional dependencies:

```java
@Apply
public void apply(
    S3Client s3,                      // Required
    @Nullable CacheService cache      // Optional - null if not available
) {
    if (cache != null) {
        cache.invalidate();
    }
    // proceed with S3 operation
}
```

### Lock-guarded dependencies

Flamingock uses a background daemon to automatically refresh the distributed lock, ensuring your Changes maintain exclusive access during execution. As an additional safety layer, Flamingock wraps injected dependencies with proxies that verify the lock is still valid before each method call.

This proxy mechanism provides extra robustness - ensuring that operations don't even start if the lock is lost for any reason (though this is very unlikely given the background refresh daemon).

For non-critical or local components, use `@NonLockGuarded` to skip the proxy:

```java
@Apply
public void apply(
    ElasticsearchClient elastic,               // Lock-guarded (default)
    @NonLockGuarded List<String> localData     // Not guarded - no proxy overhead
) {
    // elastic calls are protected by lock validation
    // localData is used directly without checks
}
```

See [Lock documentation](../flamingock-library-config/lock.md) for more details on lock protection.

### Dependency resolution details

When Flamingock looks for a dependency to inject, it follows a specific hierarchy. This ensures system-specific dependencies take precedence over general ones.

For complete understanding of dependency resolution, see [Dependency Resolution Hierarchy](../flamingock-library-config/context-and-dependencies.md#dependency-resolution-hierarchy).

---

// File: changes/transactions

# Transactions

Flamingock provides intelligent transaction management that adapts to your target systems' capabilities. Understanding when and how changes are executed transactionally is key to building reliable system evolution.

## How Flamingock handles transactions

Flamingock's transaction handling is determined by the **target system's capabilities**, not just the `transactional` flag. The behavior differs fundamentally between transactional and non-transactional target systems.

### üîÑ Transactional target systems
**Examples**: PostgreSQL, MySQL, MongoDB, SQL databases, DynamoDB, Couchbase

These systems support native transaction capabilities:

**When `transactional = true` (default)**:
- Execution runs within a native database transaction
- **On failure**: Automatic rollback using database's native transaction mechanism
- Session/connection managed automatically by Flamingock
- `@Rollback` used only for manual operations (CLI undo)

**When `transactional = false`**:
- Execution runs without transaction
- **On failure**: Safety through compensation logic (@Rollback)
- Useful for DDL operations or any operation that requires not participating in a transaction

### ‚ö° Non-transactional target systems
**Examples**: Kafka, S3, REST APIs, file systems, message queues

These systems have no native transaction support:

**The `transactional` flag is ignored** - behavior is always the same:
- Execution runs normally (no native transaction possible)
- **On failure**: Safety through compensation logic (@Rollback)
- Safety relies entirely on idempotent operations and rollback methods

### Behavior summary table

| Target System Type | `transactional = true` (default) | `transactional = false` |
|---------------------|-----------------------------------|-------------------------|
| **Transactional** | Native transaction rollback on failure | `@Rollback` on failure |
| **Non-transactional** | **Flag ignored** - `@Rollback` on failure | **Flag ignored** - `@Rollback` on failure |

## Best practices

### Always provide @Rollback
- **Transactional systems with `transactional = true`**: Used for manual rollback operations (CLI undo)
- **Transactional systems with `transactional = false`**: Called automatically on failure
- **Non-transactional systems**: Always called automatically on failure (flag ignored)
- **All cases**: Essential for complete change management

### Use appropriate transactionality
- **Keep default `transactional = true`** for regular data changes on transactional systems
- **Use `transactional = false`** only when necessary on transactional systems (DDL, bulk operations)
- **For non-transactional systems**: The flag doesn't matter - design idempotent operations and robust rollback logic

**Key takeaway**: Flamingock's transaction behavior is determined by your target system's capabilities. For transactional systems, the `transactional` flag controls failure handling (native rollback vs @Rollback). For non-transactional systems, the flag is ignored and @Rollback is always used.

---

// File: changes/types-and-implementation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Change Types & Implementation

Flamingock supports two approaches for implementing Changes: **code-based** and **template-based**. Each serves different use cases and provides the same safety guarantees.







<Tabs groupId="edition">
  <TabItem value="template" label="Template based" default>
Template-based Changes use YAML or JSON files with reusable templates. Templates provide a low-code, declarative approach for common patterns and repetitive operations. Templates can be as powerful and complex as code-based Changes - the difference is that templates are developed for reusable patterns and integrations.

### Basic YAML structure

```yaml
# File: _0001__AddUserIndex.yaml
id: add_user_index
author: "database-team"
description: "Add index on user email field for faster lookups"
targetSystem: "user-database"
template: mongodb-index
apply:
  type: createIndex
  collection: users
  indexSpec:
    email: 1
  options:
    unique: true
    name: "idx_user_email"
rollback:
  type: removeIndex
  collection: users
  indexName: "idx_user_email"
```

For more details about available templates and creating custom templates, see [Templates](../templates/templates-introduction).

  </TabItem>
  <TabItem value="code" label="Code based">
Code-based Changes are written in Java, Kotlin, or Groovy with annotations. They provide full programmatic control for custom logic or specific operations that don't fit existing templates.

### Basic structure

```java
@TargetSystem("user-database")
@Change(id = "migrate-user-emails", author = "data-team")  // order extracted from filename
public class _0001__MigrateUserEmails {

    @Apply
    public void apply(MongoDatabase database, ClientSession session) {
        // Custom implementation logic with full programmatic control
        MongoCollection<Document> users = database.getCollection("users");
        users.updateMany(session,
            new Document("email", new Document("$exists", true)),
            new Document("$set", new Document("emailVerified", false)));
    }

    @Rollback
    public void rollback(MongoDatabase database, ClientSession session) {
        // Rollback logic
        database.getCollection("users")
                .updateMany(session, new Document(),
                    new Document("$unset", new Document("emailVerified", "")));
    }
}
```

  </TabItem>
</Tabs>








## File organization

### Recommended project structure:
```
src/main/java/com/yourapp/changes/
‚îú‚îÄ‚îÄ _0001__CreateUserIndexes.java
‚îú‚îÄ‚îÄ _0002__AddUserStatus.yaml
‚îú‚îÄ‚îÄ _0003__MigrateUserData.java
‚îú‚îÄ‚îÄ _0004__SetupNotifications.yaml
‚îî‚îÄ‚îÄ _0003__OptimizeQueries.java
```

### Best practices:
- **Keep together**: Store both code and template files in the same directory
- **Consistent naming**: Follow `_ORDER__CHANGE_NAME` pattern for both types (recommended: `NN`)
- **Order in filename**: When using the naming pattern, order in annotation/yaml is optional

:::info Order Field Rules
Using the `_ORDER__CHANGE-NAME` pattern, the order is extracted from the filename. For complete rules about order and file naming, see [Anatomy & Structure - File name and order](./anatomy-and-structure#file-name-and-order).
:::

## Template development

Flamingock and the community provide useful templates for common operations. Organizations can also develop their own templates to standardize patterns and integrations specific to their needs.

For more information about available templates and how to create custom templates, see [Templates](../templates/templates-introduction).

## Next steps

- **[Best Practices](./best-practices)** - Learn proven patterns for reliable Changes
- **[Templates](../templates/templates-introduction)** - Explore available templates and create custom ones
- **[Target Systems](../target-systems/introduction)** - Configure where your changes will be applied

---

// File: changes/best-practices

# Change Best Practices

Following these proven patterns will help you create reliable, maintainable Changes that work safely in production environments.

## Core principles

### Treat Changes as immutable

Once a Change is deployed, never modify it. Create new Changes for corrections.

**‚ùå Don't do this:**
```java
// Modifying an existing Change after deployment
@Change(id = "add-user-field", author = "team")  // order extracted from filename
public class _0001__AddUserField {
    @Apply
    public void apply(MongoDatabase db) {
        // Original: db.getCollection("users").updateMany(/* add field */)
        // Modified: db.getCollection("users").updateMany(/* different logic */)
    }
}
```

**‚úÖ Do this instead:**
```java
// Keep the original unchanged
@Change(id = "add-user-field", author = "team")  // order extracted from filename
public class _0001__AddUserField {
    @Apply
    public void apply(MongoDatabase db) {
        // Original logic remains unchanged
    }
}

// Create a new Change for corrections
@Change(id = "fix-user-field-values", author = "team")  // order extracted from filename
public class _0002__FixUserFieldValues {
    @Apply
    public void apply(MongoDatabase db) {
        // Correction logic
    }
}
```
---

### Avoid domain object coupling

Building on the idea of immutability, another common pitfall is coupling Changes too tightly to domain objects. Changes are historical records that must remain stable over time, even as your application evolves. When Changes depend on domain classes that later change (fields removed, renamed, or restructured), your previously successful Changes can break compilation or execution.

**The issue:** If a Change uses a `Customer` domain class and you later remove the `middleName` field from that class, the Change will no longer compile - breaking Flamingock's ability to verify or re-execute historical changes.

**‚úÖ Use generic structures instead:**
```java
// Instead of domain objects, use framework-native structures
@Apply
public void apply(JdbcTemplate jdbc) {
    Map<String, Object> customer = jdbc.queryForMap(
        "SELECT * FROM customers WHERE id = ?", customerId
    );
    // Work with the Map directly, not a Customer object
}
```

‚Üí **Learn more:** [Domain Coupling and Historical Immutability](domain-coupling.md) - Understand why this happens and explore different approaches to keep your Changes stable.

---

### Always provide rollback logic

Every Change must have a `@Rollback` method, regardless of target system type.

**Why rollback matters:**
- **Non-transactional systems**: Automatic cleanup on failure
- **All systems**: CLI/UI undo operations
- **Safety**: Proves you understand the change impact
- **Governance**: Required for audit compliance

**Example with comprehensive rollback:**
```java
@Change(id = "setup-user-indexes", author = "db-team")  // order extracted from filename
public class _0001__SetupUserIndexes {
    
    @Apply
    public void apply(MongoDatabase database) {
        MongoCollection<Document> users = database.getCollection("users");
        
        // Create compound index for user queries
        users.createIndex(
            new Document("email", 1).append("status", 1),
            new IndexOptions().name("idx_user_email_status").unique(false)
        );
        
        // Create text index for search
        users.createIndex(
            new Document("firstName", "text").append("lastName", "text"),
            new IndexOptions().name("idx_user_search")
        );
    }
    
    @Rollback
    public void rollback(MongoDatabase database) {
        MongoCollection<Document> users = database.getCollection("users");

        // Drop only if the index exists
        if (isIndexCreated(users, "idx_user_search")) {
            users.dropIndex("idx_user_search");
        }

        if (isIndexCreated(users, "idx_user_email_status")) {
            users.dropIndex("idx_user_email_status");
        }
    }
}
```

---

### Keep scope focused

Each Change should address one logical change. Avoid combining unrelated operations.

**‚ùå Avoid mixing concerns:**
```java
@Change(id = "big-refactor", author = "team")  // order extracted from filename
public class _0001__BigRefactor {
    @Apply
    public void apply(MongoDatabase db, KafkaProducer producer) {
        // Adding user field
        db.getCollection("users").updateMany(/* ... */);
        
        // Creating Kafka topic  
        producer.send(/* create topic message */);
        
        // Updating configuration
        db.getCollection("config").updateOne(/* ... */);
    }
}
```

**‚úÖ Separate concerns:**
```java
@TargetSystem("user-database")
@Change(id = "add-user-status", author = "team")  // order extracted from filename
public class _0001__AddUserStatus {
    // Focus: User schema change only
}

@TargetSystem("kafka-events")
@Change(id = "create-user-topic", author = "team")  // order extracted from filename
public class _0001__CreateUserTopic {
    // Focus: Kafka topic creation only
}
```

## Technical guidelines

### Design for idempotency

Make operations safe to re-run whenever possible.

**Example: Idempotent field addition:**
```java
@Change(id = "add-user-preferences", author = "team")  // order extracted from filename
public class _0001__AddUserPreferences {
    
    @Apply
    public void apply(MongoDatabase database) {
        // Only update users that don't already have preferences
        database.getCollection("users").updateMany(
            new Document("preferences", new Document("$exists", false)),
            new Document("$set", new Document("preferences", getDefaultPreferences()))
        );
    }
    
    private Document getDefaultPreferences() {
        return new Document()
            .append("theme", "light")
            .append("notifications", true);
    }
}
```


---

### Handle errors gracefully

Don't catch exceptions unless you have specific recovery logic. Let Flamingock handle error management.

**‚ùå Don't suppress errors:**
```java
@Apply
public void apply(MongoDatabase database) {
    try {
        // Some operation
        database.getCollection("users").updateMany(/* ... */);
    } catch (Exception e) {
        // Silently ignoring errors prevents proper error handling
        System.out.println("Error occurred: " + e.getMessage());
    }
}
```

**‚úÖ Let exceptions bubble up:**
```java
@Apply
public void apply(MongoDatabase database) {
    // Let Flamingock handle exceptions and recovery
    database.getCollection("users").updateMany(/* ... */);
}
```


---

### Use meaningful method names

Method names should clearly indicate their purpose.

**Good examples:**
```java
@Apply
public void migrateUserProfilesToNewSchema(MongoDatabase db) { }

@Apply  
public void addEmailIndexForFasterLookups(MongoDatabase db) { }

@Rollback
public void removeEmailIndexAndRevertSchema(MongoDatabase db) { }
```

## Naming and organization

### Follow consistent naming patterns

**File names:**
- Use `_ORDER_DescriptiveName` format where ORDER is extracted between first and last underscores
- **Recommended format for order**: `NNNN` with left-padding zeros (e.g., `0001`, `0002`, `0010`)
- When using this naming pattern, the order in `@Change` annotation or YAML is optional
- Use PascalCase for class names

**Good examples:**
```
_0001__CreateUserIndexes.java
_0002__MigrateUserData.java
_0002__AddUserPreferences.java
_0005__OptimizeUserQueries.java
_0004__MigrateToNewFormat.yaml
```

:::tip Recommendation
We recommend specifying the order in the file/class name using the `NN` format:

**Benefits:**
- **Simple and clear** - Easy to understand and implement
- **Natural sorting** - Files automatically sort numerically
- **No complexity** - Just sequential numbering
- **Easy identification** - Quick visual scan shows execution order
- **No annotation needed** - Order is extracted from filename

Examples:
- `_0001__CreateUserTable.java` ‚Üí order: "0001" (no need for order in @Change)
- `_0002__MigrateData.yaml` ‚Üí order: "0002" (no need for order in YAML)
- `_0004__AddIndexes.java` ‚Üí order: "0004"
:::


For detailed rules about order and file naming, see [Anatomy & Structure - File name and order](./anatomy-and-structure#file-name-and-order).

---

### Use descriptive IDs and descriptions

Make your Changes self-documenting:

```java
@Change(
    id = "migrate-legacy-user-format-to-v2",
    order = "20250923_01",
    author = "data-migration-team",
    description = "Migrate user documents from legacy format to v2 schema with new preference structure"
)
```


---

### Organize by chronological order

Changes should be organized chronologically by their order within stages. If you need logical grouping, use stages - but remember that execution order is only guaranteed within a stage, not between stages.

```
src/main/java/com/company/changes/
‚îú‚îÄ‚îÄ _0001__CreateUserCollection.java
‚îú‚îÄ‚îÄ _0002__AddUserIndexes.java
‚îú‚îÄ‚îÄ _0003__MigrateUserData.java
‚îú‚îÄ‚îÄ _0004__CreateOrdersTable.java
‚îî‚îÄ‚îÄ _0005__AddOrderStatusColumn.java
```

## Testing and validation

### Test both execution and rollback

Create comprehensive tests for your Changes:

```java
@Test
public void testUserMigrationChange() {
    // Arrange
    MongoDatabase testDb = getTestDatabase();
    insertTestUsers(testDb);
    
    var change = new _0001__MigrateUsers();
    
    // Act - Test execution
    change.execute(testDb);
    
    // Assert - Verify execution results
    MongoCollection<Document> users = testDb.getCollection("users");
    assertEquals(5, users.countDocuments(new Document("status", "active")));
    
    // Act - Test rollback  
    change.rollback(testDb);
    
    // Assert - Verify rollback results
    assertEquals(0, users.countDocuments(new Document("status", new Document("$exists", true))));
}
```


---

### Validate with real-like data

Test with data that resembles production:

```java
@Test
public void testWithRealisticData() {
    // Use realistic data volumes and edge cases
    insertUsers(1000);  // Test batch processing
    insertUsersWithMissingFields(); // Test data inconsistencies
    insertUsersWithEdgeCaseValues(); // Test boundary conditions
    
    // Run your Change
    change.execute(database);
    
    // Verify all scenarios handled correctly
}
```


## Next steps

- **[Templates](../templates/templates-introduction)** - Explore reusable change patterns
- **[Target Systems](../target-systems/introduction)** - Configure where changes are applied
- **[Testing](../testing/introduction)** - Comprehensive testing strategies for Changes

---

// File: changes/domain-coupling

# Domain Coupling and Historical Immutability

## Why this matters

Here's something that might surprise you: Changes that ran successfully in the past can break your build today. This happens when Changes depend on domain classes that evolve over time. Let's understand why this matters and how to keep your Changes stable.

## The coupling problem

Changes in Flamingock are meant to be **historically immutable** - they represent past changes that have been applied and audited. Their code should remain untouched over time to ensure:

- **Repeatability**: The same Change produces the same result
- **Auditability**: Historical changes can be verified
- **Reliability**: Past Changes continue to work in new environments

However, when a Change depends on a domain class and that class evolves (fields removed, renamed, or restructured), your older Changes will no longer compile or run correctly.

### A practical example

Consider a PostgreSQL database with a `customers` table. Initially, your domain model includes:

```java
public class Customer {
    private Long id;
    private String firstName;
    private String middleName;  // Will be removed later
    private String lastName;
    private String email;
    // getters/setters...
}
```

You create a Change that uses this domain class:

```java
@Change(id = "add-premium-customers", order = "20250923_01", author = "team")
public class _0001__AddPremiumCustomers {

    @Apply
    public void apply(CustomerRepository repository) {
        Customer customer = new Customer();
        customer.setFirstName("John");
        customer.setMiddleName("William");  // Uses the field
        customer.setLastName("Smith");
        customer.setEmail("john.smith@example.com");
        repository.save(customer);
    }
}
```

Six months later, your team decides `middleName` is unnecessary and removes it from the `Customer` class. Now:

- ‚úÖ Your application works fine with the updated model
- ‚ùå The Change `_0001__AddPremiumCustomers` no longer compiles
- ‚ùå You can't run Flamingock in new environments
- ‚ùå CI/CD pipelines break

This breaks the principle of historical immutability and undermines Flamingock's reliability.

## The solution: Generic structures

To ensure stability, avoid injecting domain classes or anything tightly coupled to your evolving business model. Instead, use schema-free or generic structures.

Here's how the same Change looks using generic structures:

```java
@Change(id = "add-premium-customers", order = "20250923_01", author = "team")
public class _0001__AddPremiumCustomers {

    @Apply
    public void apply(RestTemplate restTemplate) {
        // Using a Map instead of the Customer domain class
        Map<String, Object> customerData = new HashMap<>();
        customerData.put("firstName", "John");
        customerData.put("middleName", "William");
        customerData.put("lastName", "Smith");
        customerData.put("email", "john.smith@example.com");
        customerData.put("status", "PREMIUM");

        // Send to customer service API
        restTemplate.postForObject(
            "/api/customers",
            customerData,
            Map.class
        );
    }

    @Rollback
    public void rollback(RestTemplate restTemplate) {
        // Remove the customer using email as identifier
        restTemplate.delete("/api/customers/john.smith@example.com");
    }
}
```

This Change remains stable even if the `Customer` domain class evolves or the `middleName` field is removed. The Map structure is decoupled from your domain model.

## When you need reusable logic

If you have complex logic that needs to be shared across Changes, consider these approaches:

### Utility classes for Changes

Create utilities specifically for your Changes that are isolated from your domain:

```java
public class ChangeUtils {
    public static Map<String, Object> createCustomerData(
        String firstName, String lastName, String email) {
        return Map.of(
            "firstName", firstName,
            "lastName", lastName,
            "email", email,
            "createdAt", Instant.now().toString()
        );
    }
}
```

### SQL files or scripts

For complex SQL operations, consider external scripts:

```java
@Apply
public void apply(JdbcTemplate jdbc) throws IOException {
    String sql = Files.readString(
        Paths.get("changes/sql/001_create_premium_customers.sql")
    );
    jdbc.execute(sql);
}
```

## Best practices summary

1. **Treat Changes as historical artifacts** - They are versioned records of the past, not part of your live business logic

2. **Use generic structures** - Maps, Documents, ResultSets, or direct queries instead of domain objects

3. **Keep Changes self-contained** - Minimize dependencies on external classes that might change

4. **Test with evolution in mind** - Ensure your Changes compile and run even as your domain evolves

5. **Document data structures** - When using generic structures, add comments explaining the expected schema

## The balance

We're not suggesting you should never use any classes in your Changes. The key is understanding the trade-off:

- **Domain classes**: Type safety now, brittleness over time
- **Generic structures**: Less type safety, long-term stability

Choose based on your context, but be aware of the implications. For most production systems where Changes need to remain stable for years, generic structures are the safer choice.

## Next steps

- Review existing Changes for domain coupling
- Establish team conventions for Change implementations
- Consider using [Templates](../templates/templates-introduction.md) for standardized, decoupled change patterns

---

// File: cli/cli

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Flamingock CLI

Command-line tool for audit management and maintenance operations.

> **Beta Release**
> This is the beta version of Flamingock CLI, providing essential management operations for audit control and issue resolution. A more comprehensive CLI with full change execution capabilities is in development.

## Overview

The Flamingock CLI provides operational commands for audit management and maintenance. Use these commands to view audit history, identify issues, and perform resolution operations.

## Installation

### Download

```bash
# Download the latest CLI distribution
curl -L https://github.com/flamingock/flamingock-java/releases/latest/download/flamingock-cli.tar.gz -o flamingock-cli.tar.gz

# Extract the archive and get into the directory
tar -xzf flamingock-cli.tar.gz
cd flamingock-cli/bin

# Make script executable
chmod +x flamingock

# Run the CLI
./flamingock --help
```

### Configuration

Modify the `flamingock-cli.yml` configuration file in flamingock-cli/bin directory according to your audit store setup:

<Tabs groupId="cli_config">
  <TabItem value="mongodb" label="MongoDB" default>
#### MongoDB configuration
```yaml
serviceIdentifier: my-service  # Optional, defaults to "flamingock-cli"
audit:
  mongodb:
    connectionString: mongodb://localhost:27017
    database: myapp
    # Or use individual properties:
    # host: localhost
    # port: 27017
    # username: admin
    # password: secret
    collection: "flamingockAuditLog" # Optional, defaults to "flamingockAuditLog"
```
  </TabItem>
  <TabItem value="dynamodb" label="Amazon DynamoDB">
#### DynamoDB configuration
```yaml
serviceIdentifier: my-service  # Optional, defaults to "flamingock-cli"
audit:
  dynamodb:
    region: us-east-1
    # Optional endpoint for local development:
    # endpoint: http://localhost:8000
    # accessKey: local
    # secretKey: local
    table: "flamingockAuditLog" # Optional, defaults to "flamingockAuditLog"
```
  </TabItem>
  <TabItem value="couchbase" label="Couchabse">
#### Couchbase configuration
```yaml
serviceIdentifier: my-service  # Optional, defaults to "flamingock-cli"
audit:
  couchbase:
    endpoint: "couchbase://localhost:12110"
    username: "your-username"
    password: "your-password"
    bucket-name: "my-app"
    table: "flamingockAuditLog" # Optional, defaults to "flamingockAuditLog"
```
  </TabItem>
  <TabItem value="sql" label="SQL">
#### SQL configuration
```yaml
serviceIdentifier: my-service  # Optional, defaults to "flamingock-cli"
audit:
  sql:
    endpoint: "jdbc:sqlserver://localhost:1433/test-db"
    username: "your-username"
    password: "your-password"
    sql-dialect: "SqlServer" # Optional, if not set will be auto-detected based on endpoint
    table: "flamingockAuditLog" # Optional, defaults to "flamingockAuditLog"
```
To see actual supported databases, check [SQL Audit Store](../audit-stores/community/sql-audit-store#supported-databases).
  </TabItem>
</Tabs>

You can specify a custom configuration file using the `-c` or `--config` option:
```bash
flamingock -c custom-config.yaml audit list
```

## Core commands

### View audit entries

List the current state of all changes (snapshot view):
```bash
flamingock audit list
```

View the complete chronological history:
```bash
flamingock audit list --history
```

View changes since a specific date:
```bash
flamingock audit list --since 2025-01-01T00:00:00
```

Show extended information including execution details:
```bash
flamingock audit list --extended
```

### Find issues

List all change units with inconsistent audit states:
```bash
flamingock issue list
```

Output in JSON format for automation:
```bash
flamingock issue list --json
```

### Investigate issues

Get detailed information about a specific issue:
```bash
flamingock issue get -c user-change-v2
```

Include resolution guidance:
```bash
flamingock issue get -c user-change-v2 --guidance
```

Get the next priority issue (when no change ID specified):
```bash
flamingock issue get --guidance
```

### Resolve issues

After manually verifying or fixing the state, mark the change as resolved:

If the change was successfully applied:
```bash
flamingock audit fix -c user-change-v2 -r APPLIED
```

If the change was not applied or rolled back:
```bash
flamingock audit fix -c user-change-v2 -r ROLLED_BACK
```

For detailed workflows on issue resolution, see [Issue resolution](../safety-and-recovery/issue-resolution.md).

## Command Reference

### Global options

```bash
flamingock [global-options] <command> [command-options]
```

- `-c, --config <file>` - Configuration file path (default: `bin/flamingock-cli.yml`)
- `--verbose` - Enable verbose logging
- `--debug` - Enable debug logging
- `--trace` - Enable trace logging (most detailed level)
- `--quiet` - Suppress non-essential output
- `--help` - Show help information
- `--version` - Show version information

### `audit list`

Display audit entries from the audit store.

**Options:**
- `--history` - Show full chronological history (all entries)
- `--since <datetime>` - Show entries since date (ISO-8601 format: `2025-01-01T00:00:00`)
- `-e, --extended` - Show extended information (execution ID, duration, class, method, hostname)

**Examples:**
```bash
# View current state (latest per change unit)
flamingock audit list

# View all historical entries
flamingock audit list --history

# View changes from last 24 hours
flamingock audit list --since 2025-01-07T00:00:00

# View with extended details
flamingock audit list --extended
```

### `audit fix`

Resolve an inconsistent audit state after manual intervention.

**Options:**
- `-c, --change-id <id>` - Change unit ID to fix (required)
- `-r, --resolution <type>` - Resolution type: `APPLIED` or `ROLLED_BACK` (required)

**Examples:**
```bash
# Mark as successfully applied
flamingock audit fix -c create-user-index -r APPLIED

# Mark as rolled back (will be retried on next execution)
flamingock audit fix -c create-user-index -r ROLLED_BACK
```

### `issue list` (alias: `ls`)

List all change units with inconsistent audit states.

**Options:**
- `-j, --json` - Output in JSON format

**Examples:**
```bash
# List issues in table format
flamingock issue list

# Output as JSON for automation
flamingock issue list --json
```

### `issue get` (alias: `describe`)

Show detailed information about an issue.

**Options:**
- `-c, --change-id <id>` - Specific change unit ID (optional, shows next issue if omitted)
- `-g, --guidance` - Include resolution guidance
- `-j, --json` - Output in JSON format

**Examples:**
```bash
# Get next priority issue
flamingock issue get --guidance

# Get specific issue details
flamingock issue get -c user-change-v3

# Get with resolution guidance
flamingock issue get -c user-change-v3 --guidance

# Output as JSON
flamingock issue get -c user-change-v3 --json
```

## Example output

### Audit list output
```
Audit Entries Snapshot (Latest per Change Unit):
==================================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Change ID                    ‚îÇ State  ‚îÇ Author           ‚îÇ Time                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ create-users-collection      ‚îÇ ‚úì      ‚îÇ platform-team    ‚îÇ 2025-01-07 10:15:23 ‚îÇ
‚îÇ add-user-indexes             ‚îÇ ‚úì      ‚îÇ platform-team    ‚îÇ 2025-01-07 10:15:24 ‚îÇ
‚îÇ seed-initial-data            ‚îÇ ‚úó      ‚îÇ data-team        ‚îÇ 2025-01-07 10:15:25 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Legend: ‚úì = EXECUTED | ‚úó = FAILED | ‚ñ∂ = STARTED | ‚Ü© = ROLLED_BACK

Total entries: 3
```

### Issue details output
```
Issue Details: seed-initial-data
==================================================

üìã OVERVIEW
  Change ID: seed-initial-data
  State: STARTED (‚ùå)
  Target System: user-database
  Author: data-team
  Time: 2025-01-07 10:15:25
  Execution ID: exec-123456
  Duration: 1523ms

‚ö†Ô∏è  ERROR DETAILS
  Execution interrupted unexpectedly

  Technical Details:
  - Class: i.f.changes.SeedData
  - Method: execute
  - Hostname: prod-server-01

üîß Resolution Process:

     1. Review the error details above to understand the root cause

     2. Verify the actual state in your target system (user-database):
        ‚Ä¢ Check if the change was successfully applied despite the audit failure
        ‚Ä¢ Determine if the change was partially applied or not applied at all

     3. Fix the audit state based on your findings:

        ‚úÖ If change was successfully applied:
           flamingock audit fix -c seed-initial-data -r APPLIED

        ‚Ü©Ô∏è  If change was not applied or you've manually rolled it back:
           flamingock audit fix -c seed-initial-data -r ROLLED_BACK
           (Flamingock will retry this change in the next execution)

     ‚ö†Ô∏è  Important: For partially applied changes, you must either:
         ‚Ä¢ Manually complete the change, then fix it with resolution(-r) APPLIED
         ‚Ä¢ Manually revert the change, then fix it with resolution(-r) ROLLED_BACK
```

## Logging levels

Control the verbosity of output using logging options:

```bash
# Normal output (default)
flamingock audit list

# Verbose output with info logs
flamingock --verbose audit list

# Debug output with detailed logs
flamingock --debug audit list

# Minimal output
flamingock --quiet audit list
```

## Troubleshooting

### Connection issues

If you see "Cannot connect to audit store":
1. Verify your configuration file exists and is valid YAML
2. Check database connection parameters
3. Ensure the database is accessible from your location
4. Test with verbose logging: `flamingock --verbose audit list`

### No issues found

If `issue list` shows no issues but you expect some:
1. Verify you're connecting to the correct audit store
2. Check if issues were already resolved
3. Use `audit list --history` to see all historical entries

### Permission errors

If you get permission errors when running `audit fix`:
1. Ensure your database credentials have write access
2. Verify the audit collection/table permissions
3. Check if the database user can modify audit entries

---

// File: cloud-edition/cloud-edition

# Cloud Edition
:::warning[**Cloud Edition Coming Soon**]
The Cloud Edition is currently under development and not yet publicly available.

**If you'd like to participate in early testing or be notified when Cloud Edition is available, email us at [support@flamingock.io](mailto:support@flamingock.io)**

üîî Stay tuned ‚Äî it‚Äôs launching very soon!


:::
Flamingock Cloud Edition is a **fully managed SaaS platform** that brings advanced features, collaboration, and visibility to your change management workflow.

While the Community Audit Stores offers core functionality with local storage and self-managed execution, the Cloud Edition extends that with powerful enterprise-grade capabilities.

## What the Cloud Edition will offer

Once released, the Cloud Edition will enable:

- **Centralized dashboards** to track and visualize changes across services and environments
- **Built-in user and team management** with Role-Based Access Control (RBAC)
- **Cross-environment visibility** for staging, production, and everything in between
- **Advanced template and extension support** for faster integration and reuse
- **Governance, auditability, and compliance** built into every change lifecycle
- **Multi-tenant and multi-service support**, ready for real-world deployment complexity

:::note
The Cloud Edition still relies on the Flamingock client library to run within your application.  
:::

## What's coming in this section

This section will guide you through:

- How to set up your **Cloud Edition environment**
- How to configure the Flamingock **client for Cloud Edition**
- How to use the **dashboard**, explore audits, and manage services
- Best practices for working with **multi-environment** and **multi-team** setups

---

// File: flamingock-library-config/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Flamingock library configuration

Flamingock provides flexible configuration options to support a variety of environments and workflows ‚Äî from local setups to cloud-native distributed systems.

Configuration is divided into two distinct scopes:

- **Setup configuration** defines how Flamingock discovers and organizes change units. This is configured using the `@Flamingock` annotation.

- **Runtime configuration** includes optional parameters such as locking, metadata, author, etc., and can be provided via builder or (depending on the environment) a file.


## What you can configure

| Area                             | Description                                         | Link |
|----------------------------------|-----------------------------------------------------|------|
| ‚≠ê Setup & stages                | Organize changes into ordered stages - **Essential** | [Setup & stages](./setup-and-stages.md) |
| ‚≠ê Target systems               | Configure target systems for your changes - **Essential** | [Target systems](../target-systems/introduction.md) |
| ‚≠ê Audit store                  | Configure audit storage - **Essential** | [Audit stores](../audit-stores/introduction.md) |
| Global dependency injection      | Dependency injection to Changes and environment | [Context and dependencies](./context-and-dependencies.md) |
| Cloud Edition                    | Cloud-specific setup: token, env, service           | [Cloud Edition](../cloud-edition/cloud-edition.md) |
| Framework integration            | Integration with frameworks (currently Spring Boot) | [Spring Boot integration](../frameworks/springboot-integration/introduction.md) |
| Lock                             | Distributed locking and timing options              | [Lock configuration](./lock.md) |
| Extra                            | Metadata, default author, enable/disable            | [Additional configuration](./additional-configuration.md) |


Each of these topics is explained in its own section.




## Applying runtime configuration
Runtime configuration (everything except the pipeline) can be applied in the following ways:

| Runtime environment |  Builder  |         File          |
|---------------------|:---------:|:---------------------:|
| Standalone          |     ‚úÖ     |    ‚ùå (coming soon)    |
| Springboot          |     ‚úÖ     |  ‚úÖ(framework native)  |

:::info
You can combine both approaches. If a property is defined in both, the builder value takes precedence.
:::


## Next steps

Start with the essential configurations marked with ‚≠ê, then explore additional options based on your needs:

### Essential configurations (start here)
- [‚≠ê Setup & stages](./setup-and-stages.md) - Define how changes are organized and discovered
- [‚≠ê Target systems](../target-systems/introduction.md) - Configure systems where changes will be applied
- [‚≠ê Audit stores](../audit-stores/introduction.md) - Set up audit storage (not needed for Cloud Edition)

### Additional configurations
- [Global dependency injection](./context-and-dependencies.md) - Configure dependency resolution
- [Framework integration](../frameworks/springboot-integration/introduction.md) - Spring Boot integration
- [Lock configuration](./lock.md) - Distributed locking options
- [Additional configuration](./additional-configuration.md) - Metadata, author, and other settings

### Choose your edition
- [‚òÅÔ∏è Cloud Edition](../cloud-edition/cloud-edition.md) - Fully-featured managed solution
- [üß™ Community Edition](../audit-stores/introduction.md) - Community audit stores (feature-limited)

---

// File: flamingock-library-config/setup-and-stages

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Setup & Stages

The Flamingock **setup** organizes and executes your changes using **stages**. By default, you'll use a single stage that groups all your changes and executes them sequentially.

Changes within a stage are executed sequentially with order guaranteed. However, execution order between stages is not guaranteed.


## Setup configuration

Flamingock is configured using the `@EnableFlamingock` annotation on any class in your application. This annotation is required for all environments ‚Äî whether you're using the standalone runner or Spring Boot integration.

The annotation is **only** used to define the setup (stages and their sources); it does not include or support runtime configuration.

## Defining the setup

Here's the default single-stage configuration:

```java
@EnableFlamingock(
    stages = { @Stage(location = "com.yourcompany.changes") }
)
public class FlamingockConfig {
    // Configuration class
}
```

Alternatively, using a YAML file:

```java
@EnableFlamingock( pipelineFile = "config/setup.yaml" )
public class FlamingockConfig {}
```

Where `config/setup.yaml` contains:
```yaml
pipeline:
  stages:
    - name: main
      location: com.yourcompany.changes
```

:::info Advanced options:
- **Multiple stages**: For complex scenarios requiring independent change sets go to the [stage section below](#multiple-stages-advanced)
- **File-based configuration**: Use `pipelineFile` parameter for YAML configuration
- **Explicit naming**: Use `@Stage(name = "custom", location = "com.yourcompany.changes")`
:::


## Where changes are located

- **`location`** refers to a source package (e.g., `com.company.changes`), a relative(e.g., `my/path/changes`) or absolute(e.g., `/my/path/changes`) resources directory.
  - Template-based and code-based changes can co-exist if location is a source package.
  - If location references a resource directory, it only accepts template-based changes.
  - Default source roots: `src/main/java`, `src/main/kotlin`, `src/main/scala`, `src/main/groovy`.
  - Source root can be customized via the `sources` compiler option.
  - Resource root can be customized via the `resources` compiler option.


## Multiple stages (Advanced)

Most applications will naturally fit into a single stage, which keeps things simple and ensures a clear, deterministic execution order.
However, if you prefer to organize changes into multiple stages‚Äîfor example, to separate concerns or enforce isolated execution
flows‚ÄîFlamingock fully supports that as well. We‚Äôll explain how it works and what to consider when taking that approach.

:::tip Default approach:
Most applications use a single stage: `@Stage(location = "com.yourcompany.changes")`. The name is auto-derived ("changes") and this is the recommended default setup.
:::


### When to use multiple stages

Multiple stages are beneficial in specific scenarios:

#### Multi-module applications
In monolithic applications with well-defined module boundaries, you can give each module its own stage for full autonomy:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "user-module", location = "com.yourapp.users.changes"),
        @Stage(name = "billing-module", location = "com.yourapp.billing.changes"),
        @Stage(name = "notification-module", location = "com.yourapp.notifications.changes")
    }
)
```

This approach allows:
- Independent change management across modules
- Different release cycles for different modules
- Clear separation of concerns and responsibilities

#### Functional separation
You might want to separate changes by function or lifecycle:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "core-setup", location = "com.yourapp.setup.changes"),
        @Stage(name = "business-logic", location = "com.yourapp.business.changes"),
        @Stage(name = "monitoring-setup", location = "com.yourapp.monitoring.changes")
    }
)
```

### Restrictions and important considerations

#### No execution order guarantees
**Critical limitation**: Flamingock does not guarantee execution order between stages. This means:

- Stage A might execute before, after, or concurrently with Stage B
- You cannot rely on changes in one stage being applied before another stage starts
- Each stage should be completely independent from others

#### Why this matters?
Consider this problematic scenario:
```java
// ‚ùå PROBLEMATIC: Relies on execution order
@EnableFlamingock(
    stages = {
        @Stage(name = "create-tables", location = "com.yourapp.schema"),     // Creates tables
        @Stage(name = "seed-data", location = "com.yourapp.data")           // Inserts data - DEPENDS on tables existing!
    }
)
```

The `seed-data` stage might execute before `create-tables`, causing failures.

#### Correct approach
Instead, group dependent changes in the same stage:
```java
// ‚úÖ CORRECT: All related changes in one stage
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")  // Contains both table creation AND data seeding in order
    }
)
```


### When NOT to use multiple stages

Avoid multiple stages when:
- **You need execution order across different change types** - Use a single stage instead
- **Changes are logically related** - Keep them together for easier maintenance
- **Simple applications** - The complexity isn't worth the overhead
- **Cross-cutting concerns** - Changes that affect multiple areas should be in one stage

:::info Future Enhancements
Conditional stage execution based on dependencies or conditions is planned for future releases, which would allow:
- Running stages based on success/failure of other stages
- Defining explicit dependencies between stages
- More sophisticated stage orchestration patterns
:::

## Required fields

`@EnableFlamingock` annotation must define:
- `stages`: Array of stage configurations
- `strictStageMapping` (optional): Validation mode for unmapped changes (default: `true`)

Each stage must define:
- `name` (optional): A unique identifier - if not provided, it will be auto-derived from the location
- `location`: The package or directory where changes are located


## Stage fields

| Field            | Required            | Description                                                                 |
|------------------|---------------------|-----------------------------------------------------------------------------|
| `location`       | :white_check_mark:  | Package or directory scanned for both code-based and template-based changes |
| `name`           | :x:                 | Unique identifier for the stage (auto-derived from location if not provided) |
| `description`    | :x:                 | Optional text explaining the stage's purpose                                |



## Example pipeline

```yaml
pipeline:
  stages:
    - name: user-setup
      description: User-related DB setup
      location: com.yourapp.flamingock.users
```

Folder view:

```
src/
  main/
    java/
      com/
        yourapp/
          flamingock/
            users/
              _0001__CreateUsersTable.java
              _0002__AddIndex.yaml
```


## ‚úÖ Best Practices

### Single stage execution (default and recommended)

In most applications, **changes that require a specific, deterministic execution order** should be grouped into a **single stage**. This ensures they are applied sequentially and in the exact order they are defined.

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")
    }
)
```

Grouping related changes into a single stage:
- Ensures **predictable, sequential execution**
- Avoids ambiguity from cross-stage execution timing
- Eliminates the need to manage inter-stage dependencies
- Keeps setup simple and easier to maintain
- Supports mixing all types of changes (Kafka, MongoDB, SQL, S3, etc.) in a well-defined order

:::info Advanced scenarios
If your application benefits from separating changes‚Äîfor example, by module or lifecycle‚Äîyou can define [Multiple Stages (Advanced)](#multiple-stages-advanced). Just remember: deterministic execution is guaranteed only within a stage, not across them.
:::

### Placing your changes
We strongly recommend placing all your changes ‚Äî code-based and template-based ‚Äî in a **single location** defined by the `@Stage` annotation.
  - Ensures changes are always scanned, regardless of type
  - Avoids needing two locations if one template-based change requires fallback to code
  - Keeps everything in one logical location


### Naming convention for Changes
To ensure clarity and enforce ordering, we recommend naming changes using the following format:

```
_0001__CreateClientsTable.java
_0002__AddIndexToEmail.yaml
_0003__MigrateData.java
_0004__ComplexChange.yaml
```

- `ORDER`: The execution order extracted between the first `_` and last `_`
  - **Recommended format**: `NNNN` with left-padding zeros (e.g., `0001`, `0002`, `0010`)
- `CHANGE_NAME`: Descriptive name of what the change does

This convention:
- **Eliminates the need for order in annotations/YAML** - the order is extracted from the filename
- **Natural sequential sorting** - files automatically sort numerically
- **Clear execution order** - instantly see the sequence of changes
- Works across both code-based and template-based formats
- **Sufficient capacity** - supports up to 99 changes with two-digit format
- Ensures consistent naming and project hygiene

:::tip
While Java typically avoids underscores and leading digits, change units are not traditional classes. Prioritizing **readability and order** is more valuable in this context.
:::

:::info Complete Order Field Rules
For detailed rules about order and file naming, see [Change Anatomy - File name and order](../changes/anatomy-and-structure#file-name-and-order).
:::



## üõ† Troubleshooting

### My stage isn't picked up
- Make sure the stage has a `location` field defined
- Check the file path is correct and uses `/` as a separator, not `.` in YAML
- If using resource directory paths, make sure the file is placed under `src/main/resources/your-dir`
- If your project uses non-standard paths (for example, source code or resources are not under `src/main/java` or `src/main/resources`), Flamingock may not detect your change files automatically.  
You can customize the compiler arguments to tell Flamingock where to look:
<Tabs groupId="gradle_maven">
    <TabItem value="gradle" label="Gradle" default>
```kotlin
tasks.withType<JavaCompile> {
    options.compilerArgs.addAll(listOf(
        "-Asources=custom/src",
        "-Aresources=custom/resources"
    ))
}
```
    </TabItem>
    <TabItem value="maven" label="Maven">
```xml
<build>
  <plugins>
    <plugin>
      <artifactId>maven-compiler-plugin</artifactId>
      <configuration>
        <compilerArgs>
          <arg>-Asources=custom/src</arg>
          <arg>-Aresources=custom/resources</arg>
        </compilerArgs>
      </configuration>
    </plugin>
  </plugins>
</build>
```
    </TabItem>
</Tabs>

By default, Flamingock automatically scans the following source and resource roots:
- src/main/java
- src/main/kotlin
- src/main/scala
- src/main/groovy
- src/main/resources


### No changes found in stage
- Verify that the class or YAML file is located in the expected package/directory
- For code-based changes, ensure the class is annotated with `@Change`
- For template-based changes, check file names and YAML formatting


## Setup validation

Flamingock validates that all code-based changes (classes annotated with `@Change`) are properly mapped to a stage during compilation.

### Strict stage mapping

By default, Flamingock enforces strict stage mapping validation:

```java
@EnableFlamingock(
    stages = { @Stage(location = "com.yourcompany.changes") },
    strictStageMapping = true  // Default behavior
)
public class FlamingockConfig {
    // Configuration class
}
```

When `strictStageMapping` is enabled (default):
- **Compilation fails** if any `@Change` class is found outside the configured stage locations
- Ensures all changes are properly organized and will be executed

When `strictStageMapping` is disabled:
- **Only warnings are emitted** for unmapped changes during compilation
- Unmapped changes will be ignored at runtime

### Compilation fails with "unmapped changes" error
- Check that all `@Change` classes are located within the configured stage locations
- If you have changes in multiple locations, consider adding an additional stages to cover them. Visit our [multiple-stages](#multiple-stages-advanced) sections for more information
- Temporarily set `strictStageMapping = false` to see warnings instead of errors during migration
- Move unmapped changes to the correct stage location or remove unused changes

### Example scenarios

**Scenario 1: Change outside configured location (strict mode)**
```java
@EnableFlamingock(
    stages = { @Stage(location = "com.yourcompany.changes") },
    strictStageMapping = true  // Default
)
```

If you have a change at `com.yourcompany.yourpackage.OldChange` (outside the configured location):
- ‚ùå **Compilation fails** with detailed error message
- Must move the change to `com.yourcompany.changes` or add a new stage with location `com.yourcompany.yourpackage.OldChange`

**Scenario 2: Relaxed validation**
```java
@EnableFlamingock(
    stages = { @Stage(location = "com.yourcompany.changes") },
    strictStageMapping = false  // Relaxed mode
)
```

If you have a change at `com.yourcompany.yourpackage.OldChange`:
- ‚ö†Ô∏è **Warning emitted** during compilation
- Compilation succeeds but change is ignored at runtime

:::tip Best Practice
Keep `strictStageMapping = true` (default) to ensure all changes are properly mapped and executed. Only disable it temporarily during large refactoring or migration scenarios.
:::

---

// File: flamingock-library-config/context-and-dependencies

# Context and dependencies

Flamingock provides a sophisticated dependency injection system that automatically resolves dependencies for Changes from multiple sources. Understanding this system is crucial for building maintainable and well-structured changes.

## What is the context?

The context is Flamingock's dependency container that holds all the dependencies your Changes might need. It's organized hierarchically, allowing for proper scoping and isolation of dependencies.

Contexts can contain:
- System connectors (databases, message queues, storage services, APIs)
- Configuration properties and objects
- Service instances and business logic components
- Framework-specific beans (like Spring components)
- Custom utilities and helpers

## Dependency resolution hierarchy

Flamingock uses a **hierarchical resolution strategy** that searches for dependencies in this order:

1. **Target system context** - Dependencies provided by the specific target system. For more information, see [Target systems](../target-systems/introduction.md#dependency-injection).
2. **General application context** - Shared dependencies registered globally directly in the builder  
3. **Framework context** - When using Spring Boot, beans from the Spring container. For more information, see [Spring Boot integration](../frameworks/springboot-integration/introduction.md).

This approach ensures that system-specific dependencies are properly scoped while allowing shared utilities to be available everywhere.

### How it works in practice

When a Change needs a dependency, Flamingock follows a specific search pattern. For example, imagine your Change requires a `NotificationService`:

**Scenario 1**: If the Kafka target system provides its own notification service specifically for event streaming, and your Change belongs to that Kafka target system, Flamingock will use the Kafka-specific notification service. The target system context always wins.

**Scenario 2**: If your MongoDB target system doesn't provide a notification service, but you've registered one globally in Flamingock's builder, the Change will receive that global notification service. Flamingock searches the target system first, doesn't find it, then falls back to the global context.

**Scenario 3**: In a Spring Boot application, if neither the target system nor the global context provides the dependency, Flamingock will look for a Spring bean of that type. This allows seamless integration with your existing Spring components.

This hierarchy ensures that specialized implementations (like a Kafka-optimized notification service) are used when available, while still allowing shared services to be accessible across all Changes.

## Providing dependencies

### Target system dependencies

Every target system provides two ways to add dependencies:

**Specific methods** - Each concrete implementation offers `.withXXX()` methods for common dependencies:
```java
var mongoTarget = new MongoDBSyncTargetSystem("user-db", mongoClient, databaseName)
                .withReadConcern(ReadConcern.MAJORITY)              // MongoDB specific method
                .withReadPreference(ReadPreference.primary())       // MongoDB specific method
                .withWriteConcern(WriteConcern.MAJORITY);           // MongoDB specific method
```

**Generic methods** - All target systems (including NonTransactionalTargetSystem) support generic dependency injection:
```java
var kafkaTarget = new NonTransactionalTargetSystem("events-id")
    .addDependency(kafkaProducer)
    .addDependency("notification-service", notificationService)
    .setProperty("batch.size", 1000);
```

This flexibility allows NonTransactionalTargetSystem to inject any dependencies needed for non-transactional systems, while specialized target systems provide convenience methods for their common dependencies.

### Global dependencies

You can register dependencies globally to make them available to all Changes:

```java
Flamingock.builder()
    .addDependency(userService)
    .addDependency(emailService)
    .addDependency(configurationProperties)
    .addTargetSystems(mongoTarget)
    .build();
```

### Framework dependencies

When using frameworks like Spring Boot, Flamingock automatically accesses beans from the framework container:

```java
@Service
public class UserService {
    // This service is automatically available to Changes
}
```

:::warning
Remember that target system contexts are isolated. Dependencies in one target system aren't available to Changes in another target system.
:::

## Best practices

### Scope dependencies appropriately
- **Target system specific**: System connectors (DB, Kafka, S3, etc.), system-specific configurations
- **Global**: Shared services, utilities, application-wide configuration
- **Framework**: Let Spring manage beans, services, and repositories


**Key takeaway**: Flamingock's hierarchical dependency resolution provides flexibility while maintaining clear separation of concerns. Use target system contexts for system-specific dependencies and global context for shared resources.

---

// File: flamingock-library-config/lock

# Lock

Flamingock uses a distributed lock to ensure that changes are only applied **once and only once**, even when multiple instances of your application start simultaneously in a distributed system.

The lock mechanism is **mandatory** and is stored in your configured audit store (e.g., MongoDB, DynamoDB).


## Configurable properties

| Property                             | Default          | Description                                                                         |
|--------------------------------------|------------------|-------------------------------------------------------------------------------------|
| `lockAcquiredForMillis`              | `60000` (1 min)  | Time the lock remains valid once acquired. Automatically released if not refreshed. |
| `lockQuitTryingAfterMillis`          | `180000` (3 min) | How long to retry acquiring the lock if another instance holds it.                  |
| `lockTryFrequencyMillis`             | `1000` (1 sec)   | Interval between attempts while waiting for the lock.                               |
| `throwExceptionIfCannotObtainLock`   | `true`           | Whether Flamingock should fail if the lock can't be acquired.                       |


## Why locking matters

In distributed systems, multiple app instances may start simultaneously ‚Äî but only **one** should apply pending changes. Flamingock uses locking to:

- Prevent race conditions
- Ensure consistent and safe state transitions
- Guarantee single execution of each change

:::info
If no pending changes exist, the lock is not acquired and startup proceeds normally.
:::

## Refresh daemon (safety net)

The **refresh daemon** is a background thread that extends the lock before it expires.
It‚Äôs critical for **long-running changes** that might exceed the lock duration.

Without the daemon:

- A long-running change (e.g., 90s) could outlive a default lock (e.g., 60s)
- Another instance might acquire the lock prematurely, causing conflict

:::note
By default, Flamingock uses proxy-based injection guards. Before executing any injected dependency, Flamingock verifies that the lock is still valid.
:::

If you're injecting **non-critical components** (e.g., a local list or stateless helper), you can annotate them with `@NonLockGuarded` to avoid the proxy overhead.


## Configuration examples

### Builder
```java
Flamingock.builder()
  .setLockAcquiredForMillis(120000)
  .setLockQuitTryingAfterMillis(300000)
  .setLockTryFrequencyMillis(2000)
  .setThrowExceptionIfCannotObtainLock(true)
  ...
```


## When to tweak Lock settings

Most projects can use the default configuration. You may need to adjust values if:

- You expect **long-running changes** (increase `lockAcquiredForMillis`)
- You run **many app instances** and want to reduce startup wait (decrease `lockTryFrequencyMillis`)
- You want Flamingock to **fail fast** if it can't acquire a lock (keep `throwExceptionIfCannotObtainLock` as `true`)


## ‚úÖ Best Practices

- Keep the refresh daemon **enabled**, especially for distributed or slow-processing environments
- Avoid setting `lockAcquiredForMillis` too short if any changes might run longer
- Use `@NonLockGuarded` sparingly ‚Äî only when you're sure no side-effects will occur

[//]: # (TODO: Add "üõ† Troubleshooting" section)

---

// File: flamingock-library-config/additional-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Additional configuration

This section includes additional settings for customizing defaults and adding contextual information to your Flamingock setup.

| Setting         | Purpose                                      | Default            |
|-----------------|-----------------------------------------------|--------------------|
| `metadata`      | Attach tags and labels for audit tracking     | _empty map_        |
| `enabled`       | Globally enable/disable Flamingock            | `true`             |

:::note
These options can currently be defined using the Flamingock builder. Support for config file (outside Spring Boot) will be added in a future release
:::

## Metadata

Flamingock provides a Metadata object - which is a flexible `Map<String, Object>` that allows you to attach custom information to your Flamingock process.

The metadata is stored as part of the **audit log**, and can be used for labeling, traceability, and future reporting.

### Use cases
You can use metadata to:
- Tag executions by **team**, **service**, or **region**
- Include a **deployment ID**, **build number**, or **triggering user**
- Attach **comments** or **labels** for easier traceability

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
metadata:
  owner: platform-team
  triggeredBy: ci-cd-pipeline
  notes: initial deployment setup
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
Map<String, Object> metadata = new HashMap<>();
metadata.put("owner", "platform-team");
metadata.put("triggeredBy", "ci-cd-pipeline");

Flamingock.builder()
.setMetadata(metadata)
...
```
    </TabItem>
</Tabs>


## Disable flamingock process

This global toggle allows you to enable or disable Flamingock.

- If set to `false`, Flamingock will **not run**
- A log message will appear in the **application logs**, indicating that Flamingock is disabled
- No changes will be applied and no audit entries will be created

:::note
Useful in test environments, local runs, or cases where you want to conditionally skip changes.
:::

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
enabled: false
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
Flamingock.builder()
  .setEnabled(false)
```
    </TabItem>
</Tabs>

---

// File: flamingock-library-config/events

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Events

This guide provides a comprehensive explanation of how Flamingock events function.

## Introduction

Flamingock utilizes events to notify the main application about the current state of the Flamingock process, as well as the eventual outcome of its execution.

The event-handling approach differs significantly depending on the type of runner being used:

- For Spring-based applications, Flamingock leverages the ```ApplicationEventPublisher```, which is provided during the build process.
- For standalone applications, Flamingock requires an explicit event handler to be defined at build time.

Flamingock offers event handling capabilities for both Pipelines and Stages.

## Type of events

Flamingock emits three types of events:

- **Start Event**: Emitted just before the execution of Changes begins, either at the Stage or Pipeline level, after successful validation of configuration and preconditions.
- **Success Event**: Emitted when the execution of all Changes in a Stage or Pipeline completes successfully, with no unhandled errors, indicating that all operations finished as expected.
- **Failure Event**: Emitted when an unhandled error occurs during the execution of a Change and the process cannot continue normally.

:::warning
The Success and Failure events are mutually exclusive, only one of them will be raised for a given execution.
:::

## Standalone basic example

In the Flamingock builder, you must configure the events you intend to use and implement the corresponding listeners.

### Builder

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
      Flamingock.builder()
          .setPipelineStartedListener(new PipelineStartedListener())
          .setPipelineCompletedListener(new PipelineCompletedListener())
          .setPipelineFailedListener(new PipelineFailedListener())
          .setStageStartedListener(new StageStartedListener())
          .setStageCompletedListener(new StageCompletedListener())
          .setStageFailedListener(new StageFailedListener())
          .build()
          .run();
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
      Flamingock.builder()
          .setPipelineStartedListener(PipelineStartedListener())
          .setPipelineCompletedListener(PipelineCompletedListener())
          .setPipelineFailedListener(PipelineFailedListener())
          .setStageStartedListener(StageStartedListener())
          .setStageCompletedListener(StageCompletedListener())
          .setStageFailedListener(StageFailedListener())
          .build()
          .run()
  ```
  </TabItem>
</Tabs>

### Listener

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
public class StageCompletedListener implements ApplicationListener<StageCompletedEvent> {

    public static int executed = 0;
    @Override
    public void accept(StageCompletedEvent stageCompletedEvent) {
        executed++;
    }
}
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
class StageCompletedListener : (StageCompletedEvent) -> Unit {

    companion object {
        var executed = 0
    }

    override fun invoke(stageCompletedEvent: StageCompletedEvent) {
        executed++
    }
}
  ```
  </TabItem>
</Tabs>

## Spring-based basic example

### Beans

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
    ```java
      @Bean
          public PipelineStartedListener pipelineStartedListener() {
          return new PipelineStartedListener();
      }

      @Bean
      public PipelineCompletedListener pipelineCompletedListener() {
          return new PipelineCompletedListener();
      }

      @Bean
      public PipelineFailedListener pipelineFailedListener() {
          return new PipelineFailedListener();
      }

      @Bean
      public StageStartedListener stageStartedListener() {
          return new StageStartedListener();
      }

      @Bean
      public StageCompletedListener stageCompletedListener() {
          return new StageCompletedListener();
      }

      @Bean
      public StageFailedListener stageFailedListener() {
          return new StageFailedListener();
      }
    ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin" default>
    ```kotlin
        @Bean
        fun pipelineStartedListener(): PipelineStartedListener {
            return PipelineStartedListener()
        }

        @Bean
        fun pipelineCompletedListener(): PipelineCompletedListener {
            return PipelineCompletedListener()
        }

        @Bean
        fun pipelineFailedListener(): PipelineFailedListener {
            return PipelineFailedListener()
        }

        @Bean
        fun StageStartedListener(): StageStartedListener {
            return StageStartedListener()
        }

        @Bean
        fun stageCompletedListener(): StageCompletedListener {
            return StageCompletedListener()
        }

        @Bean
        fun stageFailedListener(): StageFailedListener {
            return StageFailedListener()
        }
    ```
  </TabItem>
</Tabs>

### Listener

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
public class StageCompletedListener implements ApplicationListener<SpringStageCompletedEvent> {

    public static int executed = 0;
    @Override
    public void accept(SpringStageCompletedEvent springStageCompletedEvent) {
        executed++;
    }
}
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
class StageCompletedListener : (SpringStageCompletedEvent) -> Unit {

    companion object {
        var executed = 0
    }

    override fun invoke(springStageCompletedEvent: SpringStageCompletedEvent) {
        executed++
    }
}
  ```
  </TabItem>
</Tabs>

---

// File: frameworks/graalvm

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# GraalVM support

Flamingock provides **first-class support for GraalVM native images**, enabling your application to compile into fast, self-contained executables without sacrificing change tracking, rollback, or template support.

This page explains how to generate a GraalVM native image for a Flamingock-enabled application, using the **reflection metadata** produced by the **annotation processor** and Flamingock‚Äôs built-in GraalVM **registration feature**.


## How it works

When building your application, Flamingock's annotation processor:

- Scans for all annotated code-based changes (`@Change`)
- Discovers template-based changes from `sourcesPackage` and `resourcesDir`
- Generates metadata files containing all required classes for reflection

At native image generation time, Flamingock‚Äôs **GraalVM feature** picks up these files and registers the required types with GraalVM, so they‚Äôre available at runtime.

:::tip
Learn more about the basics of GraalVM native image compilation in the [GraalVM Native Image basics guide](https://www.graalvm.org/latest/reference-manual/native-image/basics/).
:::


## Step-by-step setup

### 1. Add Flamingock GraalVM dependency

<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```kotlin
implementation("io.flamingock:flamingock-graalvm:$version")
```

</TabItem>
<TabItem value="maven" label="Maven">

```xml
<dependencies>
  <dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-graalvm</artifactId>
    <version>${flamingock.version}</version>
  </dependency>
</dependencies>
```

</TabItem>
</Tabs>


### 2. Add plugin management (only for Gradle)

If using Gradle, ensure your `settings.gradle.kts` includes:

```kotlin
pluginManagement {
    repositories {
        mavenLocal()
        gradlePluginPortal()
        mavenCentral()
    }
}
```


### 3. Add GraalVM resource config

Create a file named `resource-config.json` in your project root:

```json
{
  "resources": {
    "includes": [
      { "pattern": "META-INF/flamingock/metadata.json" }
    ]
  }
}
```

:::info
This file declares which resource files should be accessible to your native image. You can add other application-specific resources here as needed.

See the [GraalVM resource configuration documentation](https://www.graalvm.org/latest/reference-manual/native-image/metadata/#resources) for more details.
:::


### 4. Build the application (Uber JAR / fat JAR)

GraalVM native-image works best when you provide a **self-contained executable JAR** (often called **Uber JAR** or **fat JAR**) that already includes:

- Your application classes
- All dependency classes
- A proper `Main-Class` entry in the JAR manifest

In Gradle, this can be achieved by customizing the `jar` task to produce an Uber JAR:

```kotlin
tasks.named<Jar>("jar") {
    manifest {
        // Replace with your own main application class
        attributes["Main-Class"] = "com.example.app.MyFlamingockApp"
    }

    duplicatesStrategy = DuplicatesStrategy.EXCLUDE

    from(sourceSets.main.get().output)

    from({
        configurations.runtimeClasspath.get().map { if (it.isDirectory) it else zipTree(it) }
    })
}
```

:::warning Why this matters for GraalVM
GraalVM‚Äôs `native-image` command expects a **single, runnable JAR** with a correct `Main-Class` in the manifest.  
If your JAR:

- does **not** contain all dependencies, or  
- does **not** declare a `Main-Class`  

then `native-image` may fail or produce a binary that cannot start correctly.
:::

Now build the application:

```bash
./gradlew clean build
```

#### Expected build output

During the build process, Flamingock will emit logs similar to the following ‚Äî indicating successful annotation processing and metadata generation.

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change annotations)
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change annotations)
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>



### 5. Create the native image

```bash
native-image \
  --no-fallback \
  --features=io.flamingock.graalvm.RegistrationFeature \
  -H:ResourceConfigurationFiles=resource-config.json \
  -H:+ReportExceptionStackTraces \
  --initialize-at-build-time=org.slf4j.simple \
  -jar build/libs/your-app.jar
```

#### What these options do:

- `--features=io.flamingock.graalvm.RegistrationFeature`: Registers all Flamingock-related classes for reflection using metadata gathered during build time.
- `-H:ResourceConfigurationFiles=resource-config.json`: Informs GraalVM of required static resource files to include.
- `--initialize-at-build-time`: ‚Äì **Optional**. Build‚Äëtime init for listed classes/packages (freeze static state; faster start; avoids early reflection/I/O). Flamingock does not require specific entries. Use only if a library benefits (e.g., logging). Example: --initialize-at-build-time=org.slf4j.impl,org.slf4j.simple. Omit if unsure.

#### Expected native image output

When creating the native image, you should see log output from Flamingock's GraalVM `RegistrationFeature`, confirming that Flamingock successfully scanned and registered internal classes, templates, system modules, and user-defined change units.

The actual output may differ slightly depending on the modules you‚Äôve included, but it should look similar to the following:
<details>
<summary>Click to see the expected logs</summary>
```
 - io.flamingock.graalvm.RegistrationFeature
[Flamingock] Starting GraalVM classes registration
[Flamingock] Starting registration of internal classes
    Registering class: io.flamingock.core.task.TaskDescriptor
    Registering class: io.flamingock.core.task.AbstractTaskDescriptor
    Registering class: io.flamingock.core.preview.PreviewPipeline
    Registering class: io.flamingock.core.preview.PreviewStage
    Registering class: io.flamingock.core.preview.CodePreviewChange
    Registering class: io.flamingock.core.preview.PreviewMethod
    Registering class: io.flamingock.core.api.template.ChangeTemplateConfig
    Registering class: io.flamingock.core.preview.TemplatePreviewChange
    Registering class: io.flamingock.core.pipeline.Pipeline
    Registering class: io.flamingock.core.pipeline.LoadedStage
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedTask
    Registering class: io.flamingock.core.task.loaded.AbstractReflectionLoadedTask
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedChange
    Registering class: io.flamingock.core.task.loaded.CodeLoadedChange
    Registering class: io.flamingock.core.task.loaded.TemplateLoadedChange
    Registering class: java.nio.charset.CoderResult
[Flamingock] Completed internal classes
[Flamingock] Starting registration of templates
    Registering class: io.flamingock.core.api.template.TemplateFactory
    Registering class: io.flamingock.core.api.template.ChangeTemplate
    Registering class: io.flamingock.core.api.template.AbstractChangeTemplate
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplate
    Registering class: io.flamingock.template.mongodb.model.MongoOperation
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplateConfig
[Flamingock] Completed templates
[Flamingock] Starting registration of system modules
    Registering class: io.flamingock.core.engine.audit.importer.changeunit.MongockImporterChange
    Registering class: io.flamingock.core.engine.audit.importer.ImporterModule
[Flamingock] Completed system modules
[Flamingock] Starting registration of user classes
    Registering class: io.flamingock.changes._1_create_clients_collection_change
    Registering class: io.flamingock.changes._2_insertClientFederico_change
    Registering class: io.flamingock.changes._3_insert_client_jorge
[Flamingock] Completed user classes
[Flamingock] Completed GraalVM classes registration
```
</details>

:::tip
For more information on image creation and options, refer to the [GraalVM build overview documentation](https://www.graalvm.org/latest/reference-manual/native-image/overview/Build-Overview/).
:::


### 6. Run the native image

```bash
./your-app
```

---

// File: frameworks/springboot-integration/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Spring Boot integration

Flamingock integrates seamlessly with Spring Boot, offering a powerful and flexible setup for managing your change units in Spring-based applications.

This integration leverages Spring Boot‚Äôs features‚Äîsuch as dependency injection, profiles, event publishing, and property configuration‚Äîto provide a streamlined and production-ready experience.


## Why integrate Flamingock with Spring Boot?

Using Flamingock with Spring Boot allows you to:

- Inject Spring-managed beans directly into change units
- Configure Flamingock via Spring Boot's native configuration files
- Use Spring profiles to control when specific change units run
- Receive execution lifecycle events using `ApplicationEventPublisher`
- Choose between Spring Boot lifecycle hooks (`ApplicationRunner` or `InitializingBean`) to run Flamingock.


## Two setup approaches

Flamingock offers **two ways to integrate with Spring Boot**, depending on how much control you want over the configuration and lifecycle.

### Builder-based setup (manual)

This approach gives you full control and uses the standard Flamingock builder with `@EnableFlamingock(setup = SetupType.BUILDER)`.
You manually inject the required Spring Boot components(ApplicationContext and ApplicationEventPublisher) as well as any Flamingock core configuration.

In addition, you can register other dependencies manually ‚Äî these will take precedence over beans from the Spring context when resolving what to inject into change units.

This is recommended for advanced users or highly customized environments.

> See: [Builder-based setup](./builder-based-setup.md)


### Automatic setup

This is the simplest way to enable Flamingock in Spring Boot.
Just annotate any class with `@EnableFlamingock` (commonly your main application class), and Flamingock will:

- Auto-detect the application context and event publisher
- Read configuration from Spring Boot config files
- Automatically wire the `FlamingockRunner` bean
- Process the setup configuration from the annotation

Ideal for most users who prefer convention over configuration.

> See: [Automatic setup](./enable-flamingock-setup.md)


## Runner strategy: ApplicationRunner vs InitializingBean

Flamingock supports two strategies for executing its process during Spring Boot startup. You can control this via the `runnerType` property in your Spring configuration (`flamingock.runnerType`), or programmatically if using the manual builder.

### Comparison

|                                            | `ApplicationRunner`                                                        | `InitializingBean`                                                |
|--------------------------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------------|
| **Phase**                                  | After all beans are initialized ‚Äî just before the app is marked as started | During bean initialization ‚Äî before the app is considered started |
| **Context availability**                   | ‚úÖ Full ‚Äî all Spring beans and profiles available                           | ‚ö†Ô∏è Limited ‚Äî not all beans may be available                       |
| **Typical use case**                       | Most common ‚Äî recommended for production environments                      | For lightweight internal logic or strict startup ordering         |
| **Events fully supported?**                | ‚úÖ Yes                                                                      | ‚ö†Ô∏è Risky ‚Äî context may not be fully ready                         |
| **Spring beans available in change units** | ‚úÖ Yes                                                                      | ‚ö†Ô∏è May fail or be incomplete                                      |

### Startup failure behavior

If Flamingock encounters an error during execution ‚Äî whether using `ApplicationRunner` or `InitializingBean` ‚Äî the Spring Boot application **will fail to start**.

This is intentional: Flamingock runs before the application is marked as ready. In deployment platforms such as **Kubernetes**, a failure at this stage will:

- Prevent the container from reaching a *Ready* state
- Trigger restart policies, health checks, or rollbacks as configured
- Ensure that the system is never exposed in a partially initialized or inconsistent state

This behavior ensures your application only starts when all change units have been applied successfully.


## Dependency

To use the Spring Boot integration, add the following dependency:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation("io.flamingock:flamingock-springboot-integration:$version")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version compatibility

The `flamingock-springboot-integration` artifact is compatible with both Spring Boot 2.x and 3.x. Your project's Spring Boot version determines the appropriate Spring framework and JDK requirements.

| Package Name                         | Spring Boot Version  |
|-------------------------------------|----------------------|
| `flamingock-springboot-integration` | 2.x and 3.x         |


## :white_check_mark: Best practices

Consider the following recommendations to get the most out of Flamingock‚Äôs Spring Boot integration:

- **Prefer `ApplicationRunner` as your runner strategy**
  It ensures Flamingock runs after the application context is fully initialized, giving it access to all beans, profiles, and configuration. It also integrates more safely with event publishing and external monitoring tools like Actuator or Prometheus.

- **Use automatic setup for simpler setups**
  Unless you have advanced needs (such as injecting non-Spring-managed dependencies), the automatic setup provides a clean and reliable integration path.

- **Use Spring profiles to scope change units**
  Profiles let you control when specific change units execute, avoiding the need for environment-specific pipelines.

- **Avoid manual execution unless absolutely necessary**
  Letting Spring handle the execution via `ApplicationRunner` or `InitializingBean` ensures Flamingock runs at the appropriate time in your application lifecycle.

- **Register custom platform components using `.addDependency(...)` only when required**
  Most applications using automatic setup will not need to register components manually.

---

// File: frameworks/springboot-integration/enable-flamingock-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Automatic Setup

Flamingock provides a convenient automatic integration with Spring Boot using the `@Flamingock` annotation. This setup is ideal when you want Flamingock to automatically detect and wire required components without writing explicit builder logic.


## Import the springboot integration library

Add the Flamingock Spring Boot integration dependency:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation("io.flamingock:flamingock-springboot-integration:$version")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version compatibility

The `flamingock-springboot-integration` artifact is compatible with both Spring Boot 2.x and 3.x. See [Version compatibility](introduction.md#version-compatibility) for details.

## Configure setup and activate integration

To activate the integration, add `@EnableFlamingock` to any class in your application (commonly on your main class or a configuration class):

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@SpringBootApplication
public class MyApplication {
  public static void main(String[] args) {
    SpringApplication.run(MyApplication.class, args);
  }
}
```

The `@EnableFlamingock` annotation enables automatic Spring Boot integration, which:

- Detect and use Spring‚Äôs `ApplicationContext` and `ApplicationEventPublisher`
- Loads Flamingock configuration directly from your Spring Boot config file
- Automatically configures the runner (e.g., ApplicationRunner or InitializingBean)
- Processes the setup configuration from the annotation


## Bean registration requirements

With automatic setup, Flamingock needs access to your target systems and (for Community Edition) audit stores. Since these aren't configured directly via the builder, they must be registered as Spring beans:

Example target system bean registration:
```java
@Bean
public NonTransactionalTargetSystem redisTargetSystem() {
    return new NonTransactionalTargetSystem("redis-cache-id");
}
```

Flamingock will automatically detect and use these beans during execution.

## Providing configuration

Runtime configuration is defined using standard Spring Boot configuration files. Use the `flamingock` section for all core and edition-specific options.

```yaml
flamingock:
  lockAcquiredForMillis: 1200
  runnerType: InitializingBean
  # other configuration...
```

:::info
If the `runnerType` property is not provided, Flamingock defaults to using `ApplicationRunner`.
:::


## Next steps

- Want full control over the builder? See [Builder-based setup](builder-based-setup.md)
- Explore [Spring Boot profile support](profiles.md)
- Learn about [Flamingock lifecycle events](../../flamingock-library-config/events.md)

---

// File: frameworks/springboot-integration/builder-based-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Flamingock supports manual integration with Spring Boot using the same builder API shared with standalone setups.

This unified approach makes it easy to switch between environments without changing your integration logic, while giving you full control over how Flamingock is initialized and executed within your application.

It‚Äôs especially useful when integrating Flamingock alongside other frameworks, when you need fine-grained control over the setup process, or when you want to override or prioritize specific dependencies manually.


## Import the springboot integration library

Add the Flamingock Spring Boot integration dependency:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation("io.flamingock:flamingock-springboot-integration:$version")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version compatibility

Check [Version compatibility](introduction.md#version-compatibility)

## Configure setup and build Flamingock manually

With the manual setup, you first need to configure Flamingock using `@EnableFlamingock` annotation with `setup = SetupType.BUILDER`, then manually configure and run Flamingock using the builder API.

### 1. Configure the annotation

```java
@EnableFlamingock(
    setup = SetupType.BUILDER,
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@Configuration
public class FlamingockConfig {
    // Configuration class
}
```

### 2. Manual builder configuration

With the manual setup, you are responsible for configuring and running Flamingock using the builder API. This includes:

- Providing your configuration (e.g., lock settings, metadata) directly via the builder
- Registering the required **platform components** using `.addDependency(...)`
- `ApplicationContext`
- `ApplicationEventPublisher`

```java
FlamingockBuilder builder = Flamingock
    .setLockAcquiredForMillis(120000) // example config
    .addDependency(applicationContext)
    .addDependency(applicationEventPublisher);
```

:::info
Platform components are registered using the same `.addDependency(...)` method used for change unit dependencies.
For details, see the [Context and dependencies](../../flamingock-library-config/context-and-dependencies.md) page.
:::
## Overriding Spring-provided dependencies
When using the builder-based setup, Flamingock will attempt to resolve dependencies using the Spring context.

However, if you manually register a dependency via `.addDependency(...)`, that dependency will take precedence over anything resolved from the Spring context. This gives you fine-grained control when you want to:

- Override a Spring-managed bean with a custom instance
- Inject mock or test-specific versions of services
- Provide external or non-Spring-managed components directly

```java
builder
  .addDependency(customClientService) // Overrides Spring's bean of same type
  .addDependency(applicationContext); // Registers Spring context for base dependency injection
```
In a nutshell, Flamingock resolves dependencies using the following order:
- Manually added dependencies via .addDependency(...)
- Beans from the Spring context (if ApplicationContext was registered)


## Running Flamingock

Once you've configured the builder, you can choose how to execute Flamingock:

### Option 1: Run manually

You can run Flamingock manually:

```java
builder.build().run();
```

### Option 2: Expose as a Spring bean

Alternatively, you can integrate Flamingock into the Spring Boot lifecycle by exposing it as an `ApplicationRunner` or `InitializingBean`:

```java
@Bean
public ApplicationRunner flamingockRunner() {
  return SpringbootUtil.toApplicationRunner(builder.build());
}
```

Or:

```java
@Bean
public InitializingBean flamingockRunner() {
  return SpringbootUtil.toInitializingBean(builder.build());
}
```

This ensures Flamingock executes automatically as part of the Spring Boot startup sequence.


## Next steps

**Want to avoid manual setup?** Explore the [Automatic Setup](./enable-flamingock-setup.md) for automatic integration with minimal code.

---

// File: frameworks/springboot-integration/profiles

# Spring Boot profiles

Flamingock supports **Spring Boot profiles** out of the box. This allows you to conditionally run specific change units depending on which profile(s) are active in your application.

This is useful for managing environment-specific changes, such as different initialization data for `dev`, `staging`, or `prod` environments.


## What is a Spring profile?

Spring profiles provide a way to segregate parts of your application configuration and behavior based on the active environment.

You can define profiles like `dev`, `test`, `staging`, or `prod`, and activate **one or more** of them using any of the following methods:

- Inside `application.yaml` or `application.properties`:
  ```yaml
  spring:
    profiles:
      active: dev,staging
  ```

- Using profile-specific configuration files like `application-dev.yaml` or `application-prod.yaml`

- As command-line arguments:
  ```bash
  --spring.profiles.active=dev,staging
  ```

- Through environment variables:
  ```bash
  SPRING_PROFILES_ACTIVE=dev,staging
  ```

When multiple profiles are active, Flamingock evaluates each change unit against **all active profiles**, and includes it if any match.


## How Flamingock uses profiles

Flamingock automatically retrieves the active profiles from Spring‚Äôs `ApplicationContext`. You don‚Äôt need to manually provide them.

You can then annotate any change unit with Spring‚Äôs native `@Profile` annotation to control whether it runs:

```java
@Change(id = "add-test-data", order = "20250207_01")
@Profile("dev")
public class AddTestDataChange {
  // will only run if "dev" profile is active
}
```

Flamingock applies the same logic as Spring Boot when evaluating whether a change unit should run.


## Multiple profiles

You can declare multiple profiles in a single `@Profile` expression:

```java
@Profile({"dev", "staging"})
```

This change unit will run if **any** of the listed profiles is active.


## Excluding profiles

To exclude a change unit from a specific profile, you can use Spring Expression Language (SpEL):

```java
@Profile("!prod")
```

This will run the change unit in **all environments except `prod`**.


## ‚úÖ Best practices

- Use profiles to isolate test data, preview features, or tenant-specific changes
- Avoid mixing profile-specific logic inside a single change ‚Äî split them into separate classes
- Keep profile names consistent across your team and environments (e.g., use `dev` everywhere, not `development`, `dev-env`, etc.)
- Consider grouping related change units under a shared profile for easier activation

---

// File: get-started/Introduction

# Introduction

**Flamingock** brings *Change-as-Code (CaC)* to your entire stack.  
It applies **versioned, auditable changes** to the external systems your application depends on ‚Äî such as schemas, message brokers, databases, APIs, cloud services, and any other external system your application needs.  

Unlike infrastructure-as-code tools, Flamingock runs **inside your application** (or via the **CLI**).  
It ensures these systems evolve **safely, consistently, and in sync with your code at runtime**.  


---

### What Flamingock manages
Flamingock focuses on **application-level changes** that your code requires to run safely:

- Database schemas and reference data  
- Message queues and schemas  
- APIs and configuration values  
- Cloud service resources directly tied to your application  
- Configuration changes (feature flags, secrets, runtime values)  

### What Flamingock does *not* manage
Flamingock is **not an infrastructure-as-code tool**. It does not provision servers, clusters, or networks ‚Äî those belong in Terraform, Pulumi, or similar. Instead, Flamingock **complements them by handling the runtime changes your application depends on**.

---

## Core principles

### üîí Safety by default
When Flamingock cannot guarantee a safe outcome, it stops and requires manual intervention. This prevents silent data corruption and ensures predictable deployments.

### üìù Complete auditability
Every change execution is tracked in an audit store, providing a complete history of what was applied, when, by whom, and with what result.

### üîÑ Recovery strategies
Configurable mechanisms determine how Flamingock handles failures:
- **Manual intervention** (default): stops on failure and requires human review  
- **Always retry**: automatically retries idempotent operations  

---

## Target systems

Flamingock can apply changes to any external service your application interacts with. Examples include:

- **Message brokers**: e.g. Kafka, RabbitMQ, AWS SQS  
- **Cloud services**: e.g. S3, Lambda, API Gateway  
- **Databases**: SQL (e.g. PostgreSQL, MySQL) and NoSQL (e.g. MongoDB, DynamoDB)  
- **APIs**: e.g. REST endpoints, GraphQL schemas  
- **Configuration systems**: e.g. feature flags, vault secrets  
- **And any other external system** your application needs to evolve  

---

## Architecture overview

### Changes
The fundamental unit of change. Each **Change**:
- Has a unique identifier and execution order  
- Targets a specific system  
- Contains execution logic (and optionally rollback logic)  
- Is executed exactly once  

### Audit store vs target system
- **Audit store** ‚Üí where Flamingock tracks execution history (managed by Flamingock).  
- **Target system** ‚Üí where your business changes are applied (any external service your application interacts with).  

### Execution flow
1. Application startup (or CLI invocation) triggers Flamingock  
2. Flamingock discovers all Changes  
3. Checks audit store for pending changes  
4. Acquires a distributed lock  
5. Executes changes in order  
6. Records results in the audit store  
7. Handles failures according to the configured recovery strategy  

---

## Next steps
- [Quick start](quick-start.md) ‚Äì minimum setup to run Flamingock  
- [Core concepts](core-concepts.md) ‚Äì detailed explanation of key concepts  
- [Changes](../changes/introduction.md) ‚Äì anatomy and execution of Changes

---

// File: get-started/quick-start

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Quick start

This guide shows you the minimum setup required to get Flamingock running. In just a few steps you will have it integrated in your application.

Let's walk through a simple scenario: evolving your inventory service with a few typical changes:

- Add a new column to a MySQL database  
- Provision a new S3 bucket for product images  
- Create a Kafka topic for stock updates  

Even in this basic example, Flamingock ensures all these changes are applied **safely, consistently, and audibly** at your application startup.  
This guide walks you through the process in 5 simple steps.


## 1. Set up Flamingock in your project

Add Flamingock to your build:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$version"))
implementation("io.flamingock:flamingock-community")

annotationProcessor("io.flamingock:flamingock-processor:$version")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingockVersion}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- Annotation processor -->
<build>
  <plugins>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <version>3.11.0</version>
      <configuration>
        <annotationProcessorPaths>
          <path>
            <groupId>io.flamingock</groupId>
            <artifactId>flamingock-processor</artifactId>
            <version>${flamingockVersion}</version>
          </path>
        </annotationProcessorPaths>
      </configuration>
    </plugin>
  </plugins>
</build>
```

  </TabItem>
</Tabs>



## 2. Create target systems

Target systems represent the external systems Flamingock will apply your changes to.
They are configured in the builder and shared across Changes.

For our example:
- A MySQL database (`mysql-inventory`)
- An S3 bucket service (`aws-s3`)
- A Kafka cluster (`kafka`)

```java
var sql = new SqlTargetSystem("mysql-inventory", mysqlDataSource);
var s3 = new NonTransactionalTargetSystem("aws-s3-id");
var kafka = new NonTransactionalTargetSystem("kafka-id");
```

See [Target systems](../target-systems/introduction.md) for more details.


## 3. Define your first Changes

Each Change represents a single change.
For our example, we'll define three:

- **MySQL**: Add a column `category` to products
- **S3**: Create a `product-images` bucket
- **Kafka**: Create a `stock-updates` topic

Changes can be:
- **Code-based**: Java classes with annotations
- **Template-based**: YAML files using reusable templates

<Tabs groupId="change">
  <TabItem value="template_based" label="Template based" default>
 
```yaml
# File `_0001__CreateS3Bucket.yaml`
id: add-product-category
author: team
targetSystem: mysql-inventory
template: SqlTemplate
apply: |
  ALTER TABLE products ADD COLUMN category VARCHAR(255)
rollback: |
  ALTER TABLE products DROP COLUMN category
```

  </TabItem>
  <TabItem value="code_based" label="Code based">

```java
@TargetSystem("aws-s3")
@Change(id = "create-s3-bucket", author = "team")  // order extracted from filename
public class _0001__CreateS3Bucket {

  @Apply
  public void apply(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("product-images")
        .createBucketConfiguration(
            CreateBucketConfiguration.builder()
                .locationConstraint(BucketLocationConstraint.EU_WEST_1)
                .build())
        .build());
  }

  @Rollback
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("product-images")
        .build());
  }
}
```

  </TabItem>
</Tabs>

For more details, see [Core concepts](core-concepts.md).


## 4. Configure stages

Flamingock organizes your changes in stages.  
Most applications only need one stage:

```java
@EnableFlamingock(
  stages = { @Stage(location = "com.company.inventory.changes") }
)
public class App {}
```

- **location**: Where Flamingock should look for changes (package or resources)
- **name**: Optional ‚Äî defaults to the location name

See [Stages](../flamingock-library-config/setup-and-stages.md) for more details and advanced setups.


## 5. Configure Flamingock runtime

Finally, configure Flamingock before running your application.

- **Community Audit Stores**: Set your audit store (MongoDB, DynamoDB, Couchbase, etc.) in the builder

- **Cloud Edition** (coming soon): Provide your API token, service name, and environment

<Tabs groupId="edition">
  <TabItem value="community" label="Community" default>

```java
Flamingock.builder()
  .setAuditStore(new MongoDBSyncAuditStore(mongoClient, mongoDatabase))
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
  <TabItem value="cloud" label="Cloud (coming soon)">

```java
Flamingock.builder()
  .setApiToken("your-flamingock-api-token") 
  .setEnvironment("dev")
  .setService("inventory-service")
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
</Tabs>


## 6. Run your application

When your service starts, Flamingock automatically:

1. Discovers your Changes
2. Checks pending changes  
3. Executes them safely in order
4. Records everything in the audit store

**If Flamingock cannot guarantee a safe outcome, it stops and alerts you. Safety first.**

### Example output

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change annotations)
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change annotations)
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>


## Next steps

- [Spring Boot integration](../frameworks/springboot-integration/introduction.md)
- [Configuration options](../flamingock-library-config/setup-and-stages.md)
- [Recovery and safety](../safety-and-recovery/recovery-strategies.md)

---

// File: get-started/core-concepts

# Core concepts

## Changes
**Changes** are the fundamental building blocks of Flamingock's Change-as-Code architecture. They represent atomic and immutable versioned changes applied to target systems with complete safety guarantees and audit capabilities.

Each **Change** includes:
- **Unique identity**: ID, order, and metadata for tracking
- **Target system**: Where the changes is applied to
- **Execution logic**: The actual change implementation
- **Rollback capability**: Compensation logic for governance and undo operations
- **Recovery strategy**: Configurable behavior for handling failures
- **Immutability**: Once applied, a **Change** must never be modified

Changes can be implemented in two forms:
- **Code-based**: Java classes with annotations that contain the change logic
- **Template-based**: Declarative low-code approach using YAML configurations

For a deeper dive around Changes, see the [Changes](../changes/anatomy-and-structure.md) and [best practices](../changes/best-practices.md) section.


## Templates
Templates provide a reusable layer on top of Changes for common change patterns. When you have multiple changes that share similar logic (for example, executing SQL statements), templates allow you to abstract that common logic and reuse it.

With templates, you create multiple Changes using a declarative, low-code approach. Each Change uses a template and passes its specific configuration. For example, an SQL template receives the SQL statement as configuration, executes it, and handles errors consistently.

This approach is particularly useful for:
- Standardizing common operations across your codebase
- Reducing boilerplate code
- Enabling non-developers to define changes through configuration

For more information about templates, see the [Templates](../templates/templates-introduction.md) section.


## Recovery strategies

Recovery strategies define how Flamingock responds when a Change fails during execution. They determine whether the system should stop and wait for manual intervention or automatically retry the operation.

Flamingock provides two main strategies:
- **Manual intervention** (default): Stops execution and requires human review when failures occur
- **Always retry**: Automatically retries the change on the next execution attempt

The choice of strategy depends on whether your changes are idempotent and how critical they are to your system's integrity.

For detailed configuration and implementation, see the [Recovery strategies](../safety-and-recovery/recovery-strategies.md) section.


## Audit store
The **audit store** is where Flamingock records metadata about change executions. Its purpose is to track which Changes have been executed, when they ran, and their outcomes. This ensures idempotency, enables rollbacks, and provides audit capabilities. The audit store is managed entirely by Flamingock - your code never directly interacts with it.
  :::info
  In Cloud Edition, the audit store is automatically provided - no configuration needed in your builder. Community Edition users must configure their own audit store.
  :::

## Target system  
The **target system** is where your actual business changes are applied. These are the systems your Changes modify - databases, message queues, APIs, configuration services, etc. Each Change declares which target system it operates on.

For more details about how these systems work together, see the [Audit store vs target system](audit-store-vs-target-system.md) section.


## Transaction handling
Flamingock adapts its behavior based on the transactional capabilities of your target systems:

### Transactional target systems
Systems that support ACID transactions, such as MongoDB 4.0+, PostgreSQL, MySQL, or other transactional stores. When working with these systems, Flamingock can leverage native transaction support to ensure atomicity of changes. If a failure occurs mid-execution, the native rollback mechanism ensures no partial changes are left in the system.

### Non-transactional target systems
Systems like Kafka, S3, REST APIs, or file systems that don't support transactions. For these systems, Flamingock relies on explicit rollback methods and careful change design to maintain consistency. Recovery strategies become particularly important for handling failures in non-transactional contexts.

For implementation details, see the [Transactions](../changes/transactions.md) section.


## Stages
Stages organize your changes into logical groups within Flamingock's execution pipeline. By default, you work with a single stage that contains all your changes, ensuring they execute sequentially in a deterministic order.

Key characteristics:
- Changes within a stage execute sequentially with guaranteed order
- Most applications only need a single stage
- Multiple stages can be used for modular architectures, but execution order between stages is not guaranteed
- Each stage defines where to find its changes (package or directory location)

For detailed information about stages and advanced configurations, see the [Setup and stages](../flamingock-library-config/setup-and-stages.md) section.

---

// File: get-started/audit-store-vs-target-system

# Target systems vs audit store
*Understanding Flamingock‚Äôs dual-system model for safe, controlled evolution*

Flamingock works with two closely related concepts:

- The **Target System** ‚Äî where your application applies real, versioned changes.
- The **Audit Store** ‚Äî where Flamingock records the execution history of those changes.

Although they are conceptually distinct, the Audit Store is not an entirely separate system.  
Instead, it is **a specialized form of a Target System**, created from a Target System that supports this role and used exclusively for audit tracking.

This relationship is not about sharing configuration: the Audit Store is built from a Target System because **both must point to the same external system**. A Target System represents an external system that Flamingock can modify, while the Audit Store represents *that same external system* in audit mode, used only to store execution history. Internally, the Audit Store derives its connection settings from the Target System but uses its own access handle, keeping audit operations isolated while ensuring both components operate on the same underlying environment.

This separation ‚Äî yet tight relationship ‚Äî is key to Flamingock‚Äôs safety model.

:::tip Clarification
Flamingock can register multiple Target Systems, but only one of them is used as the base for the Audit Store
:::


---

## Quick definitions (TL;DR)

**Target System ‚Üí**  The external system where Flamingock applies your changes (e.g., a database, a schema registry, object storage, or an API).

**Audit Store ‚Üí**  A Target System that supports audit tracking and is used to record what Flamingock executed.  
*(Only some Target Systems support this role.)*

---

## Target Systems: where your changes happen

A **Target System** is any external system your application depends on and where Flamingock applies your changes.

Typical examples:

- Databases (MongoDB, SQL, DynamoDB, Couchbase)
- Kafka Schema Registry
- Kafka topics
- S3/object storage
- External configuration stores
- REST APIs or service endpoints

The Target System represents your *business system*:  
it stores the data, schemas, state or configuration that your application relies on.

Flamingock applies real changes here ‚Äî safely, sequentially, and in a controlled manner.

For setup details, see:  
**[Target Systems ‚Ä∫ Introduction](../target-systems/introduction.md)**

---

## Audit Store: where execution is tracked

The **Audit Store** is where Flamingock records the state of every changes:

- when it ran  
- in what order  
- in which environment  
- its execution status  
- and all relevant metadata

Its purpose:

- Ensure idempotency  
- Prevent duplicate execution  
- Provide a reliable audit trail  
- Enable safe recovery after failures  
- Give full visibility into system evolution  

For setup details, see:  
**[Audit Stores ‚Ä∫ Introduction](../audit-stores/introduction.md)**

---

# The Audit Store is a specialized Target System

Although conceptually separate, the Audit Store is **not a new database**, nor a new cluster, nor a separate connection.

Instead:

### ‚úî It is built from an existing Target System  

### ‚úî It reuses the same driver and connection settings, but creates its own internal access handle 

### ‚úî It adds only the minimal configuration needed for auditing  

In practice, the Audit Store is simply:

> **the same Target System (when it supports audit tracking) running in audit mode.**

It uses the same underlying configuration (driver, client, database/namespace),
but through **its own internal object**, ensuring isolation from the Target System‚Äôs business operations.

---

## Why separate the concepts?

Even though the Audit Store is technically built from a Target System, separating the **concepts** gives you clear guarantees:

### 1. Different responsibilities
- **Target System ‚Üí** business data  
- **Audit Store ‚Üí** execution history  

This prevents mixing operational data with audit metadata.

### 2. Predictable recovery
If something fails halfway:

- Flamingock consults the **Audit Store**, not the business system.
- Flamingock knows exactly what ran and what hasn‚Äôt.
- Flamingock can safely resume or stop.

### 3. Governance and compliance
Audit data often has:

- different retention rules  
- different permissions  
- stricter access controls  
- different visibility requirements  

The conceptual separation supports this.

### 4. Deployment flexibility
You can store the audit history in:

- **Flamingock Cloud**, or  
- a local collection/table in the same Target System, or  
- a separate Target System altogether  

The model works consistently in all cases.

---

## How it works (visual overview)

```
     Your Changes:
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ 1. Change[UpdateKafkaSchema] ‚Üí Target System[Kafka Schema Registry]      ‚îÇ
     ‚îÇ 2. Change[SeedKafkaEvents]   ‚Üí Target System[Kafka Topics]               ‚îÇ
     ‚îÇ 3. Change[AddUserStatus]     ‚Üí Target System[User Database]              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ      Flamingock       ‚îÇ
                    ‚îÇ    (Orchestrator)     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ Executes sequentially
                                ‚îÇ
                 Change #1      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            (UpdateKafkaSchema) ‚îÇ                           ‚îÇ
                                ‚îÇ                           ‚îÇ
                                ‚îÇ             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                ‚îÇ             ‚ñº                          ‚ñº
                                ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                ‚îÇ     ‚îÇ   Target System:    ‚îÇ      ‚îÇ Audit Store  ‚îÇ
                                ‚îÇ     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ      ‚îÇ              ‚îÇ
                                ‚îÇ     ‚îÇ ‚îÇ Schema Registry ‚îÇ ‚îÇ      ‚îÇ   Records:   ‚îÇ
                                ‚îÇ     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ      ‚îÇ #1 applied   ‚îÇ
                                ‚îÇ     ‚îÇ  (applies change)   ‚îÇ      ‚îÇ              ‚îÇ
                                ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ
                  Change #2     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              (SeedKafkaEvents) ‚îÇ                           ‚îÇ
                                ‚îÇ                           ‚îÇ
                                ‚îÇ             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                ‚îÇ             ‚ñº                          ‚ñº
                                ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                ‚îÇ     ‚îÇ   Target System:    ‚îÇ      ‚îÇ Audit Store  ‚îÇ
                                ‚îÇ     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ      ‚îÇ              ‚îÇ
                                ‚îÇ     ‚îÇ ‚îÇ  Kafka Topics   ‚îÇ ‚îÇ      ‚îÇ   Records:   ‚îÇ
                                ‚îÇ     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ      ‚îÇ #2 applied   ‚îÇ
                                ‚îÇ     ‚îÇ  (applies change)   ‚îÇ      ‚îÇ              ‚îÇ
                                ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ
                  Change #3     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                (AddUserStatus)                             ‚îÇ
                                                            ‚îÇ
                                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                              ‚ñº                          ‚ñº
                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                      ‚îÇ   Target System:    ‚îÇ      ‚îÇ Audit Store  ‚îÇ
                                      ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ      ‚îÇ              ‚îÇ
                                      ‚îÇ ‚îÇ  User Database  ‚îÇ ‚îÇ      ‚îÇ   Records:   ‚îÇ
                                      ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ      ‚îÇ #3 applied   ‚îÇ
                                      ‚îÇ  (applies change)   ‚îÇ      ‚îÇ              ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```


**Summary of the flow:**

1. **You define changes**  
2. **Flamingock executes them safely**  
3. **Target Systems evolve**  
4. **Audit Store captures the complete execution history**  

This is the foundation of Flamingock‚Äôs safety guarantees.

---

## Key takeaways

### For developers
- Target Systems ‚Üí where changes actually happen  
- Audit Store ‚Üí automatically maintained by Flamingock  
- You never write to the Audit Store yourself

### For architects
- Clean separation of business vs control responsibilities  
- Consistent behaviour across environments  
- Predictable recovery even in distributed systems

### For operations
- Diagnose issues using audit data  
- Always know the exact execution state  
- Avoid duplicates and inconsistent partial updates  

---

## Bottom line

> **Flamingock‚Äôs dual-system model (where the Audit Store is a specialization of the Target System) is what enables safe, predictable and auditable evolution of distributed systems.**

It ensures that changes are applied once, tracked forever, and recoverable at any time ‚Äî regardless of failures, concurrency, or distributed complexity.

---

// File: get-started/Change-as-Code

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

**Automate changes. Version changes. Control changes.**
Change-as-Code (CaC) means every system change‚Äîwhether it‚Äôs an S3 bucket toggle, a new database schema, or a Kafka topic configuration‚Äîis authored, versioned, and audited just like application code.

At Flamingock, we champion CaC as the foundation for truly reliable, auditable, and repeatable deployments. No more one-off shell scripts or manual "clicks" in a console‚Äîevery change is written in code, tracked in your VCS, and executed in a controlled pipeline.

## Why CaC matters today

Modern applications increasingly span dozens of external systems‚Äîranging from relational and NoSQL databases to SaaS feature flags, message buses, and infrastructure APIs. Managing these changes manually or with ad-hoc scripts leads to:

- **Drift and ‚Äúsnowflake‚Äù environments**
  When teams manually tweak production configurations, environments diverge, making rollbacks or audits nearly impossible.

- **Lack of auditability**
  Regulatory and security teams require a full record of ‚Äúwhat changed, when, and who made it.‚Äù Spreadsheets and one-off commands don‚Äôt cut it.

- **Inefficient collaboration**
  Developers, operations, and security need a single source of truth: change definitions in code, reviewed and versioned via pull requests.

- **Increased risk of human error**
  Pasting commands into a console or clicking UI checkboxes invites typos, misconfigurations, and stress during deployment windows.

Flamingock's CaC approach solves these problems by treating every external-system change as first-class code‚Äîcomplete with version control, automated execution, and a centralized audit trail.

## Four pillars of Change-as-Code

1. **One-Hundred-Percent Versioned**
   All Changes live in your Git repository (or other VCS). This means you can review, diff, and roll back changes just like application code.

2. **Automated Execution**
   Flamingock scans and applies Changes at application startup or on-demand via the CLI. No manual intervention‚Äîjust code running code.

3. **Auditable & Traceable**
   Every Change outcome is recorded in an audit store (your database or Flamingock Cloud). Teams can query "who ran what change, and when," ensuring full compliance.

4. **Cross-Component Support**
   Whether it's SQL/NoSQL DDL, S3 buckets, Kafka topics, feature-flag toggles, or REST API calls‚ÄîFlamingock treats them all as code. Your entire system evolves in lockstep.

## "Hello, CaC" Code Snippet

Imagine you need to toggle a feature flag in a downstream service (not a database). In Flamingock, you‚Äôd write:

```java
@Change(id = "enable-autosave", author = "ops-team")  // order extracted from filename
public class _0001__EnableAutoSaveFeature {

  @Apply
  public void enableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", true);
  }

  @Rollback
  public void disableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", false);
  }
}
```

- **Versioned**: This code-based or template-based Change lives in your VCS.
- **Automated**: Flamingock executes it in order (0005) at startup or via CLI.
- **Auditable**: Upon success, an audit entry is written to your audit store.
- **Cross-Component**: The same pattern works for a DynamoDB schema change, a Kafka topic creation, or any REST API call.

## Illustration: CaC vs. IaC

![](../../static/img/Change%20as%20code-2.png)

- **Infrastructure as Code (IaC)**: Use Terraform, CloudFormation, Pulumi, etc., to provision VMs, networks, and databases (the ‚Äúfoundation‚Äù).
- **Change as Code (CaC)**: Use Flamingock to version and apply everything that lives on that foundation‚Äîdatabase schemas, feature flags, SaaS configurations, message topics, and more.

## Real-world use cases

### Multi-tenant SaaS onboarding

**Problem**: Over the lifetime of your application, you might need to create and then later modify external resources‚Äîsuch as an S3 bucket, Kafka topics, IAM roles, and initial database state‚Äîas part of each new release. Doing this manually or with ad-hoc scripts risks drift, missing audits, and inconsistent environments..

**CaC Solution**: Define a sequence of Changes that run in order on mutiple deployments, inserting audit entries and ensuring reproducible, versioned updates:
<Tabs groupId="config">
<TabItem value="code-base" label="Code" default>
```java
@Change(id = "provision-bucket", author = "team-a", transactional = false)  // order extracted from filename
public class _0001__ProvisionBucketChange {

    @Apply
    public void apply(S3Client s3) {
        s3.createBucket(CreateBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }

    @Rollback
    public void rollback(S3Client s3) {
        s3.deleteBucket(DeleteBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }
}

@Change(id = "create-kafka-topics", author = "devops", transactional = false)  // order extracted from filename
public class _0002__CreateKafkaTopicsChange {

    @Apply
    public void apply(KafkaAdminClient admin) {
        var topic1 = new NewTopic("app-events", 3, (short) 1);
        var topic2 = new NewTopic("user-notifications", 2, (short) 1);
        admin.createTopics(Arrays.asList(topic1, topic2));
    }

    @Rollback
    public void rollback(KafkaAdminClient admin) {
        admin.deleteTopics(Arrays.asList("app-events", "user-notifications"));
    }
}

@Change(id = "setup-iam-roles", author = "devops", transactional = false)  // order extracted from filename
public class _0003__SetupIamRolesChange {

    @Apply
    public void apply(IamClient iam) {
        CreateRoleResponse response = iam.createRole(CreateRoleRequest.builder()
                .roleName("flamingock-app-role")
                .assumeRolePolicyDocument("{...}") // truncated for brevity
                .build());
    }

    @Rollback
    public void rollback(IamClient iam) {
        iam.deleteRole(DeleteRoleRequest.builder()
                .roleName("flamingock-app-role")
                .build());
    }
}

@Change(id = "seed-database", author = "devops", transactional = true)  // order extracted from filename
public class _0004__SeedTenantDataChange {

    @Apply
    public void apply(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate(
                    "INSERT INTO tenants (id, name, created_at) " +
                            "VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW())"
            );
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }

    @Rollback
    public void rollback(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate("DELETE FROM tenants WHERE id IN (1, 2)");
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }
}

@Change(id = "update-bucket-settings", author = "team-a", transactional = false)  // order extracted from filename
public class _0005__UpdateBucketSettingsChange {

    @Apply
    public void apply(S3Client s3) {
        // Example: enable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Enabled")
                        .build())
                .build());
    }

    @Rollback
    public void rollback(S3Client s3) {
        // Example: disable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Suspended")
                        .build())
                .build());
    }
}

```
</TabItem>
<TabItem value="template-base" label="Template">

```yaml

# File: _0001__ProvisionBucket.yaml
id: "ProvisionBucket"
author: "team-a"
transactional: false
template: aws-s3-template
targetSystem: "s3"
apply:
  bucketName: "flamingock-app-bucket"
  region: "us-east-1"
rollback:
  bucketName: "flamingock-app-bucket"

---

# File: _0002__CreateKafkaTopics.yaml
id: "CreateKafkaTopics"
author: "devops"
transactional: false
template: kafka-template
targetSystem: "kafka"
apply:
  topics:
    - "app-events"
    - "user-notifications"
  configs:
    app-events:
      partitions: 3
      replicationFactor: 1
    user-notifications:
      partitions: 2
      replicationFactor: 1
rollback:
  topics:
    - "app-events"
    - "user-notifications"
  rollbackTopics:
    - "app-events"
    - "user-notifications"

---

# File: _0003__SetupIamRoles.yaml
id: "SetupIamRoles"
author: "devops"
transactional: false
templateName: aws-iam-template
apply:
  roleName: "flamingock-app-role"
  assumeRolePolicy: |
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": { "Service": "ec2.amazonaws.com" },
          "Action": "sts:AssumeRole"
        }
      ]
    }
rollback:
  roleName: "flamingock-app-role"
  rollbackRoleName: "flamingock-app-role"

---

# File: _0004__SeedDatabase.yaml
id: "SeedDatabase"
author: "devops"
transactional: true
template: SqlTemplate
targetSystem: "sql-target-system"
apply: |
  INSERT INTO tenants (id, name, created_at)
  VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW());
rollback: |
  DELETE FROM tenants WHERE id IN (1, 2);

---

# File: _0005__UpdateBucketSettings.yaml
id: "UpdateBucketSettings"
author: "team-a"
transactional: false
template: aws-s3-template
targetSystem: "s3"
apply:
  # Enable versioning on an existing bucket
  bucketName: "flamingock-app-bucket"
  versioningConfiguration:
    status: "Enabled"
rollback:
  # Rollback: suspend versioning
  bucketName: "flamingock-app-bucket"
  versioningConfiguration:
    status: "Suspended"
  rollbackVersioningConfiguration:
    bucketName: "flamingock-app-bucket"
    versioningConfiguration:
      status: "Suspended"

---

```

</TabItem>
</Tabs>

Flamingock ensures these four steps run in sequence‚Äînever twice‚Äîand logs them in your audit store for future reference.

## Change-as-Code checklist

- ‚úÖ **Change lives in VCS**: Every Change class (or YAML template) is versioned.
- ‚úÖ **Automated pipeline**: Flamingock applies changes automatically at startup or via CLI.
- ‚úÖ **Audit trail**: Query your audit store for a complete history of applied changes.
- ‚úÖ **Rollback logic**: Each Change provides `@Rollback` to undo or compensate if needed.
- ‚úÖ **Consistent ordering**: All Changes follow a strict, declared ordering (via the `order` attribute).
- ‚úÖ **Cross-component**: You can target databases, SaaS APIs, feature flags, message systems‚Äîanything with a client API.

## Next steps

- [Quick start](quick-start.md) ‚Üí Learn how to create your first Change and run Flamingock.
- [Core concepts](./core-concepts.md)   ‚Üí Dive deeper into auditing, drivers, transactions, and distributed locking.
- [Real use case examples](https://github.com/flamingock/flamingock-java-examples) ‚Üí Explore real-world code samples: MongoDB, DynamoDB, Couchbase, Kafka, and more.

---

// File: resources/faq

## Getting started

- **Should I use a template-based or code-based Change?**

    Choose template-based Changes to eliminate boilerplate for common tools and integrations (SQL DDL, SaaS/API, etc) and for your custom Changes by defining changes declaratively in YAML or JSON.
    Use code-based Changes when you need custom or conditional logic in Java.
    See: [Template introduction](templates/templates-introduction.md)

- **Can I integrate Flamingock into a Spring Boot application?**

    Yes, you can. You just need to import the Spring Boot integration module and annotate you main application with [`@EnableFlamingock`](../frameworks/springboot-integration/introduction#automatic-setup).
    See: [Spring Boot integration](../frameworks/springboot-integration/introduction.md)

- **Can I use Flamingock without Spring Boot?**

    Yes. You can use Flamingock in any Java application by configuring it manually using the [`FlamingockBuilder`](../overview/quick-start#5-configure-flamingock-runtime). This approach is ideal for applications that do not rely on Spring Boot or that require finer control.

- **What Java version is required?**

    Flamingock runs on Java 8 and above.

- **Is it possible to use Flamingock in GraalVM native images?**

    Yes, Flamingock provides a dedicated [GraalVM integration guide](../frameworks/graalvm.md). Ensure your dependencies and reflection requirements are correctly configured.


## Compatibility


- **Can I switch between different audit stores?**

    If you are working with different audit stores that use the - **same underlying database- ** (such as MongoDB), and they share the same structure and collection for storing metadata, it is possible to switch between them with minimal adjustments. This enables flexible integration depending on your preferred access layer, such as switching from the MongoDB Java Driver to the Spring Data implementation.


## Behaviour and execution

- **Does Flamingock guarantee idempotent execution?**

    Yes. Each `Change` has a unique ID and Flamingock ensures it runs only once per system, even across multiple instances.

- **What happens if a Change execution fails midway?**

    Flamingock's behavior depends on your recovery strategy configuration:

    - **With MANUAL_INTERVENTION (default)**:
        1. - **Transactional changes**: Database automatically rolls back, issue logged for manual review
        2. - **Non-transactional changes**: `@Rollback` method called, issue logged for manual review
        3. - **Resolution required**: Use CLI (`flamingock issue get`, then `flamingock audit fix`) to resolve after investigation

  - **With ALWAYS_RETRY**:
        1. - **Transactional changes**: Database automatically rolls back, automatic retry on next execution
        2. - **Non-transactional changes**: `@Rollback` method called, automatic retry on next execution
        3. - **No manual intervention**: Continues until successful

    This intelligent failure handling prevents silent data corruption and provides operational control.

- **How can I ensure changes are transactional?**

    If your target system supports transactions, you can use a transaction dependency in your Changes. See [Flamingock‚Äôs transaction](../changes/transactions.md) for more information.

- **Should I implement the @Rollback method in transactional environments?**

    Yes, we highly recommend to implement the `@Rollback` method. The main reason for this is that some other operations like undo, rely on this method to work. However it's a very good practice as it provides a robust system that is less affected when moving to non-transactional environments.

- **Can I react to the execution of Flamingock from my application?**

    Yes. Flamingock provides an event system that allows your application to listen to key lifecycle moments, such as when a `Change` starts or finishes execution. These events can be used to trigger logging, monitoring, or other side effects external to the change execution logic itself.

    This enables loose coupling between Flamingock‚Äôs core execution and your application-level behaviour, without modifying the `Change` directly.

    For more details, see the [Events](../flamingock-library-config/events.md) guide.

- **Is Flamingock compatible with Spring Boot profiles?**

    Yes. You can conditionally run Changes using [`@Profile`](../frameworks/springboot-integration/profiles.md), allowing changes to vary by environment.


## Configuration

- **Where do I set MongoDB connection options like write concern or read preference?**

    You can define these directly in the Audit Store config using dedicated methods (.withXXX methods). Refer to the [audit stores](../audit-stores/introduction.md) section for more info.

- **Can I inject Spring beans or other services into my Changes?**

    Yes. Flamingock supports full [dependency injection](../flamingock-library-config/context-and-dependencies.md) in both Spring and non-Spring environments.

- **Can I define Change dependencies and execution order?**

    Yes. Changes can declare dependencies via annotations or configuration metadata. See [Change anatomy](../changes/anatomy-and-structure.md) for more.


## Testing and development

- **How do I test Flamingock Changes?**

    You can perform unit, integration, and Spring Boot integration tests using test runners and mocking utilities. See the [Testing](../testing/introduction.md) section for more details.

- **Can I use templates to generate Changes?**

    Yes. Flamingock offers a templating mechanism for [creating new Changes](../templates/templates-introduction.md) and defining reusable components.


## Migrating from Mongock

- **What‚Äôs the relationship between Flamingock and Mongock?**

    Flamingock is the direct evolution of Mongock. While it inherits the core idea of tracking and executing changes reliably, Flamingock is a complete architectural and conceptual redesign aimed at overcoming the limitations of Mongock.

    Some of the key advancements introduced by Flamingock include:
        - **Cloud-native capabilities**: Support for cloud-managed storage and execution, enabling Flamingock to run in distributed, serverless, or ephemeral environments without additional setup.
        - **Execution stages and pipelines**: A structured way to group and orchestrate Changes by context, environment, or lifecycle stage.
        - **Modular architecture**: Clean separation of core, editions, templates, and integrations, enabling better extensibility and maintainability.
        - **Template-based Changes**: An additional declarative mechanism to define reusable changes without writing Java code, accelerating development and standardisation.

    While Flamingock retains conceptual compatibility with Mongock, it represents a significant leap forward in flexibility, scalability, and developer experience.

    If you are currently using Mongock, we encourage you to [review the migration guide](coming-from-mongock.md) and explore what Flamingock can offer in modern change management.


## Recovery strategies & safety

- **What are recovery strategies and why do I need them?**

    Recovery strategies determine how Flamingock handles failures - the key differentiator from traditional tools that retry blindly or fail silently. You choose between:
        - **MANUAL_INTERVENTION** (default): Stop and alert for human review when uncertain
        - **ALWAYS_RETRY**: Continue automatically until successful for idempotent operations

    This prevents silent data corruption and gives you operational control based on your risk tolerance.

- **What is the issue resolution workflow?**

    1. - **Detection**: `flamingock issue list` shows all unresolved issues
    2. - **Triage**: `flamingock issue get` provides next priority issue with guidance
    3. - **Investigation**: Check target system state (not audit store)
    4. - **Resolution**: `flamingock audit fix -c change-id --resolution APPLIED|ROLLED_BACK`

    This structured workflow eliminates guesswork and provides complete audit trails.

- **Can I change recovery strategies after deployment?**

    Yes, you can update the `@Recovery` annotation in your code and redeploy. Existing audit entries maintain their state, but new executions use the updated strategy.

- **How does Cloud Edition improve recovery without changing my code?**

    Cloud Edition uses the same recovery strategies but provides enhanced outcomes through:
        - **Intelligent automation**: Advanced reconciliation and marker mechanisms
        - **Enhanced retry logic**: Sophisticated backoff and circuit breaker patterns
        - **Automatic issue resolution**: Many failures requiring manual intervention in Community Audit Stores are resolved automatically

    Your change definitions remain identical - Cloud Edition just delivers better results.


## Enterprise & operational concerns

- **How does Flamingock ensure data integrity in distributed systems?**

    Flamingock uses a dual-architecture separating target systems (where changes are applied) from audit store (execution tracking):
        - **Complete audit trail**: Every change attempt recorded regardless of business system failures
        - **Recovery capabilities**: CLI operates on audit state, you fix business systems
        - **Compliance independence**: Audit integrity maintained during business system issues
        - **Governance separation**: Business and compliance data have different access patterns

- **What compliance and audit capabilities does Flamingock provide?**

    - **Complete execution history** with timestamp, author, system, and outcome
    - **Issue tracking and resolution** workflows for failed changes
    - **CLI-based audit management** for governance and compliance
    - **Integration ready** for external observability platforms (ELK, Prometheus, Datadog)
    - **Regulatory reporting** capabilities in Cloud Edition

- **How does Flamingock compare to traditional migration tools?**

    | Aspect                    | Flyway/Liquibase   | Mongock                | Flamingock              |
    |---------------------------|--------------------|------------------------|-------------------------|
    | - **Focus**               | SQL databases      | MongoDB only           | All systems             |
    | - **Distributed Systems** | ‚ùå Not designed for | ‚ùå Limited              | ‚úÖ First-class support   |
    | - **Non-transactional**   | ‚ùå No support       | ‚ùå Assumes transactions | ‚úÖ Full support          |
    | - **Failure Handling**    | Retry blindly      | Retry blindly          | Configurable strategies |
    | - **Issue Resolution**    | Manual SQL         | None                   | CLI + Cloud automation  |
    | - **Safety Default**      | None               | None                   | MANUAL_INTERVENTION     |

- **Can Flamingock handle multi-system coordination?**

    Yes, Flamingock is designed for distributed systems. A single Change can coordinate changes across multiple target systems (databases, APIs, message queues) while maintaining a unified audit trail and recovery strategy.

- **How do I ensure my team adopts Flamingock safely?**

    1. - **Start conservative**: Use MANUAL_INTERVENTION (default) initially
    2. - **Establish governance**: Define organization-wide recovery strategy guidelines
    3. - **Create runbooks**: Document investigation procedures for your changes
    4. - **Train on CLI**: Ensure team knows issue resolution workflow
    5. - **Monitor patterns**: Review failure patterns to optimize strategies over time

- **What happens if the audit store goes down?**

    Flamingock's safety guarantee: **No business changes applied without proper audit tracking**. If the audit store is unavailable:
        - Flamingock stops execution safely
        - No changes are applied to target systems
        - System remains in safe, known state
        - Resume automatically once audit store connectivity is restored

- **Can I use Flamingock in microservices architectures?**

    Absolutely. Flamingock is designed for distributed systems:
        - Each microservice can have its own Changes for its domain
        - Shared audit store provides cross-service visibility (especially in Cloud Edition)
        - CLI provides centralized operational control across all services
        - Recovery strategies can be tailored per service's risk profile

- **What are the organizational benefits of adopting Flamingock?**

    - **Risk reduction**: Prevent silent data corruption through safety-first defaults
    - **Team velocity**: Eliminate deployment bottlenecks with autonomous change management
    - **Operational excellence**: Centralized governance with distributed execution
    - **Compliance automation**: Complete audit trails and governance workflows
    - **Reduced dependencies**: Teams control their domain without infrastructure dependencies

- **How does Flamingock support regulatory compliance requirements?**

    - **Complete audit trails** with immutable execution history
    - **Governance workflows** for change approval and review
    - **Issue resolution documentation** for regulatory reporting
    - **CLI integration** for compliance automation
    - **Separation of concerns** between business and compliance data
    - **Cloud Edition features**: Advanced reporting, RBAC, multi-environment governance


## Other

- **Is Flamingock open-source?**

    Yes. The Flamingock client library ‚Äî used across all editions, including Community, Self-managed, and Cloud ‚Äî is fully open-source.

    For the Cloud and Self-managed editions, additional enterprise components such as the server runtime, dashboards, and governance tools are provided under a commercial licence. These components build on top of the open-source core to deliver advanced features like observability, orchestration, and centralised management.

- **Is there a CLI available?**

    Yes! The [Flamingock CLI](../cli/cli.md) provides enterprise-grade operational control for issue resolution, audit management, and maintenance tasks.

---
If your question is not listed here, please check the corresponding edition‚Äôs guide or open an issue on our GitHub repository.

---

// File: resources/coming-from-mongock

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Coming from Mongock

Flamingock provides first-class support for teams migrating from **Mongock**.  
If your application was previously using Mongock, Flamingock allows you to transition **quickly, safely, and with minimal effort** ‚Äî without rewriting any legacy migration code.

In most cases, the migration consists of only adding **one dependency and one annotation**, and Flamingock takes care of everything else.

This feature is designed to:

- **Import your existing Mongock audit log**  
- **Recognize which Mongock change units were already applied**  
- **Execute only the ones that were still pending**  
- **Let you continue using Flamingock natively for all new changes**  

:::info
Flamingock does **not** support creating new Mongock ChangeUnits going forward.  
This integration exists purely to make the migration **fast, simple and safe**.
:::

## Quick start for Mongock users

Migrating from Mongock is intentionally simple, it only requires two additional steps on top of the [standard Flamingock setup](../get-started/quick-start).

### 1. Add Mongock Support dependency




<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
annotationProcessor("io.flamingock:mongock-support:$version")
implementation("io.flamingock:mongock-support:$version")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml

<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>mongock-support</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- Annotation processor -->

<build>
    <plugins>
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <version>3.11.0</version>
            <configuration>
                <annotationProcessorPaths>
                    <path>
                        <groupId>io.flamingock</groupId>
                        <artifactId>mongock-support</artifactId>
                        <version>${flamingock.version}</version>
                    </path>
                </annotationProcessorPaths>
            </configuration>
        </plugin>
    </plugins>
</build>

```

  </TabItem>
</Tabs>


### 2. Add `@MongockSupport`

Place the annotation in any configuration class (typically your application class):

```java
@MongockSupport(targetSystem = "mongodb-target-system")
public class Application { }
```
:::info
The **`targetSystem` field** refers to the **ID of a target system that you register in Flamingock** as part of your normal application setup.  
If you are not familiar with how target systems are registered, see [Configuring Target Systems](../target-systems/introduction).
:::
The target system you register must point to the same database that Mongock previously used.

Flamingock will use this target system to:

- import Mongock‚Äôs audit log,  
- execute any Mongock change units that were not yet applied, and  
- continue applying any new Flamingock changes that target this system.

A full explanation of why this is required (and how Mongock‚Äôs model differs from Flamingock‚Äôs) is provided in the section [Understanding the target system for Mongock migrations](#understanding-the-target-system-for-mongock-migrations) below.



**That‚Äôs all you need to activate Mongock support.** From there, Flamingock handles the detection of legacy changes, audit import, and stage ordering automatically.

## Understanding the target system for Mongock migrations

Mongock and Flamingock follow different models when interacting with external systems, so it is important to understand how the `targetSystem` defined in `@MongockSupport` fits into a Flamingock application.

### 1. How Mongock handled databases

Mongock used a **single database for everything**. There was no distinction between *audit store* and *target system*.  
A single MongoDB/DynamoDB/DocumentDB instance played both roles, storing its **audit log**, and  applying its **change units**.

### 2. How Flamingock handles external systems

Flamingock separates responsibilities:

- the **audit store** records the execution history.  
- one or more **target systems** are where change units are applied.

These are independent concepts in Flamingock, even though in many practical setups the audit store is instantiated from one of the target systems.  
(See: [Audit Store vs Target System](../get-started/audit-store-vs-target-system))

### 3. Why Mongock migrations reuse a target system

When migrating from Mongock, Flamingock needs to interact with the same system that Mongock previously used for:

1. retrieving its audit log, and  
2. applying its changes.

Since Mongock used one database for both responsibilities, Flamingock reuses **one of your registered target systems** (the one that corresponds to Mongock‚Äôs previous database) to cover both roles during the migration.

This allows Flamingock to:

- **import Mongock‚Äôs audit log** from that system, and  
- **execute any pending Mongock change units** against the correct system.

### 4. What you need to configure

In your Flamingock application:

- you will register one or more target systems depending on your needs,  
- and the `targetSystem` field in `@MongockSupport` must reference the **ID of the target system that represents the database Mongock used**.

Flamingock will then:

- read the legacy Mongock audit log from that system,  
- skip Mongock change units that were already applied,  
- execute any Mongock change units that were pending, and  
- continue applying any new Flamingock change units **that target this specific system**.

### 5. Summary

Using one of your target systems to support Mongock migrations ensures:

- compatibility with Mongock‚Äôs original single-database model,  
- correct import of the legacy audit log,  
- correct execution of pending legacy changes,  
- and a smooth transition into using Flamingock‚Äôs multi‚Äìtarget-system architecture.

For more details about configuring target systems in Flamingock, see [Target Systems](../target-systems/introduction) and [Audit Store vs Target System](../get-started/audit-store-vs-target-system).


## Treat legacy Mongock change units as immutable

Mongock `@ChangeUnit` classes represent historical operations that may already have been executed in production.  
To ensure a safe and predictable migration, Flamingock **treats these legacy change units as immutable artifacts**, following the same best practices we apply to Flamingock changes.

**Immutability implies:**

- not modifying internal logic  
- not renaming classes or packages  
- not changing `id`, `order` or author  
- not relocating, splitting or merging them  
- not altering annotations or structure  

Although Flamingock may technically detect modified classes, the migration logic **assumes** they remain unchanged.  
If they diverge from what Mongock originally executed, Flamingock cannot guarantee correct audit mapping or behaviour.

Preserving immutability ensures:

- consistent audit import  
- correct skip/execute decisions  
- chronological integrity  
- reproducible migrations across environments  

Treat legacy Mongock changes as **immutable historical records**.


## How it works internally (Advanced)

Mongock support activates **when the `@MongockSupport` annotation is present**.

At compilation time, Flamingock‚Äôs annotation processor scans the entire classpath and discovers all legacy Mongock changeUnits(clases annotated with `@ChangeUnit`)

:::info 
if the annotation processor is present in your build but `@MongockSupport` is missing, Flamingock will fail fast to avoid misconfiguration.
:::

### Automatic stage structure

Flamingock creates two additional stages that always run before your Flamingock stages:

#### 1. Mongock Audit Import Stage (system stage)
Imports the Mongock audit log and converts it to Flamingock‚Äôs audit format.  
This always runs first so Flamingock can safely determine which legacy changes were already applied.

#### 2. Mongock Legacy Stage (auto-generated user stage)
Contains all Mongock `@ChangeUnit` classes that were detected during compilation.

At runtime:

- Change units **already applied** ‚Üí *skipped*  
- Change units **pending** ‚Üí *Flamingock executes them*  

After this stage finishes, Flamingock continues with your normal user-defined stages.


## Compatibility notes

- Works with MongoDB, DynamoDB, DocumentDB, CouchBase and other systems supported by Mongock  
- Flamingock restrictions on change IDs, order, etc. do not apply to Mongock change units because they are historical artifacts that must remain unchanged.
- Compatible with Standalone and Spring Boot runners  
- Does not interfere with your normal Flamingock stages  
- Requires no ordering rules or manual wiring ‚Äî Flamingock builds the stage structure automatically  

## Summary

Migrating from Mongock is intentionally simple:

1. Add the `mongock-support` dependency  
2. Add the `@MongockSupport` annotation  

Flamingock then:

- imports the Mongock audit log  
- discovers all Mongock change units  
- skips the executed ones  
- executes the pending ones  
- and continues with your Flamingock stages  

A fast, safe and frictionless transition.

---

// File: safety-and-recovery/introduction

# Safety and Recovery

While Flamingock executions typically complete successfully, the framework provides configurable recovery mechanisms to handle exceptional circumstances with complete control and visibility.

## Safety-first philosophy

In the rare cases where Flamingock cannot guarantee a safe outcome, it stops execution and requires explicit resolution rather than risking data corruption or system inconsistency. This approach ensures you always know the exact state of your systems.

## Recovery strategies

Flamingock provides two recovery strategies to handle execution failures:

### Manual intervention (default)
- **When it activates**: Any failure where the outcome is uncertain
- **What happens**: Execution stops and requires human review before continuing
- **Use case**: When safety is prioritized over automation

### Always retry
- **When it activates**: Any failure, automatically retrying on next execution
- **What happens**: Continues attempting the change until successful
- **Use case**: When changes are idempotent and safe to retry

## How it works

1. **Change execution** - Flamingock attempts to execute a Change
2. **Failure detection** - If execution fails, the recovery strategy determines next steps
3. **Strategy application** - Either automatic retry or manual intervention workflow
4. **Issue resolution** - For manual intervention, use CLI tools to investigate and resolve

## In this section

- **[Recovery strategies](recovery-strategies.md)** - Technical details and configuration
- **[Issue resolution](issue-resolution.md)** - Operational workflows for handling issues

---

// File: safety-and-recovery/issue-resolution

# Issue Resolution

Issue resolution is an iterative process of identifying failures, investigating their cause in target systems, and marking the appropriate resolution. Flamingock provides CLI tools to systematically work through issues until all are resolved.


## Understanding issues

### What creates an issue?
An "issue" is detected when:
1. **Change execution fails** during the `@Apply` method
2. **Change starts but never completes** (process crash, timeout)
3. **Rollback fails** during `@Rollback` method
4. **Change needs to run again** but is in uncertain state


## CLI-driven resolution workflow

### 1. Issue discovery
```bash
flamingock issue list
```

**Example Output**:
```
ISSUES FOUND (3)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Change ID               ‚îÇ State   ‚îÇ Error            ‚îÇ Target       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ user-data-sync-v2       ‚îÇ STARTED ‚îÇ Connection lost  ‚îÇ user-db      ‚îÇ
‚îÇ cache-warming-q4        ‚îÇ FAILED  ‚îÇ Redis timeout    ‚îÇ redis-cache  ‚îÇ
‚îÇ payment-processing      ‚îÇ FAILED  ‚îÇ Validation error ‚îÇ payment-api  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Use 'flamingock issue get' to process issues automatically, or
'flamingock issue get -c <change-id>' for specific issue details.
```

### 2. Automated issue triage
```bash
flamingock issue get
```

**What This Does**:
- Automatically selects the next issue
- Provides detailed context and diagnostic information
- Suggests resolution approaches based on failure type
- No need to copy/paste change IDs

**Example Output**:
```
ISSUE: user-data-sync-v2
Status: STARTED (execution began but never completed)
Target System: user-database
Author: platform-team
Started: 2024-01-15 14:32:15 UTC
Error: Connection lost during execution

DIAGNOSTIC INFORMATION:
- Change was modifying user profiles in MongoDB
- Execution started but connection dropped after 30 seconds
- No rollback was triggered (connection failure before completion)
- Potentially partial state in target system

RESOLUTION GUIDANCE:
1. Check target system state:
   - Query user-database for partially updated records
   - Look for users with incomplete profile updates
   - Check MongoDB logs for connection errors around 14:32:15 UTC

2. Determine actual state:
   - If no changes were applied ‚Üí mark as ROLLED_BACK (safe to retry)
   - If changes were partially applied ‚Üí complete manually, then mark APPLIED
   - If changes were fully applied ‚Üí mark as APPLIED
   - If changes caused corruption ‚Üí rollback manually, then mark ROLLED_BACK

3. Resolve the issue:
   flamingock audit fix -c user-data-sync-v2 --resolution APPLIED
   flamingock audit fix -c user-data-sync-v2 --resolution ROLLED_BACK

Next: flamingock issue get (to process next issue)
```

### 3. Verify target system state

Based on the guidance, investigate the **target system** (not the audit store) to determine the actual state of the change. You will find one of three possible states:

- **Fully applied**: The change completed successfully and all expected modifications are present
- **Not applied at all**: The change failed before making any modifications to the target system
- **Partially applied**: Some but not all changes were made to the target system (**only possible with non-transactional target systems**)

For partially applied changes, you must decide whether to:
- Manually complete the remaining changes, then mark as **APPLIED**
- Manually revert the partial changes, then mark as **ROLLED_BACK**

### 4. Mark audit resolution

Based on your target system verification, mark the audit with the appropriate resolution.

- If the change was successfully applied to the target system (either fully or after manual completion of partial changes), mark it as **APPLIED**:

```bash
flamingock audit fix -c change-id -r APPLIED
```

- If the change was not applied or was manually reverted, mark it as **ROLLED_BACK**:

```bash
flamingock audit fix -c change-id -r ROLLED_BACK
```

## Resolution commands

### APPLIED resolution
Mark the change as successfully applied when the target system contains the expected changes:

```bash
flamingock audit fix -c change-id -r APPLIED
```

**Use when:**
- Changes were successfully applied to target system
- Partial changes were completed manually
- Target system is in the desired end state

### ROLLED_BACK resolution
Mark the change as not applied when the target system was not modified or was reverted:

```bash
flamingock audit fix -c change-id -r ROLLED_BACK
```

**Use when:**
- Changes were not applied to target system
- Changes were reverted due to issues
- Target system should be left unchanged

**Note:** Changes marked as ROLLED_BACK will be attempted again on the next execution.

---

// File: safety-and-recovery/recovery-strategies

# Recovery strategies

Recovery strategies determine how Flamingock handles Change execution failures. They provide configurable behavior to balance safety with automation based on your specific requirements.

## Strategy types

### Manual intervention (default)
- **Behavior**: Stops execution and requires human intervention when any failure occurs
- **Use case**: When safety is prioritized over automation
- **Technical challenge**: Prevents silent failures and ensures human oversight for uncertain outcomes

### Always retry
- **Behavior**: Automatically retries the change on subsequent executions until successful
- **Use case**: When changes are idempotent and safe to retry automatically
- **Technical challenge**: Reduces operational overhead for recoverable failures

## Configuration

### Code-based Changes

Use the `@Recovery` annotation to specify the strategy:

```java
// Default behavior (manual intervention)
@Change(id = "example-change", order = "20250207_01", author = "team")
public class ExampleChange {
    @Apply
    public void apply() {
        // Change logic here
    }
}

// Explicit always retry
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
@Change(id = "retry-change", order = "20250207_02", author = "team")
public class RetryChange {
    @Apply
    public void apply() {
        // Idempotent change logic here
    }
}
```

### Template-based Changes

Use the `recovery` field in your YAML configuration:

```yaml
# File  File `_0001__ExampleChange.yaml`
# Default behavior (manual intervention)
id: example-change
author: team
template: example-template
apply: |
  # Change logic here

---
# File `_0002__RetryChange.yaml`
# Explicit always retry
id: retry-change
author: team
recovery: ALWAYS_RETRY
template: example-template
apply: |
  # Idempotent change logic here
```

## When failures occur

### Manual intervention workflow
1. Execution stops immediately on failure
2. Issue is logged in the audit store
3. Use CLI tools to investigate and resolve
4. Mark change as applied or rolled back manually

### Always retry workflow
1. Execution fails but continues on next run
2. Change attempts retry automatically
3. Process continues until successful or manually intervened

## Best practices

### Choose manual intervention when:
- Changes modify critical system state
- Failures require investigation before proceeding
- Rollback logic is complex or requires validation

### Choose always retry when:
- Operations are truly idempotent
- Failures are typically transient (network, temporary unavailability)
- Automatic recovery is acceptable

For detailed information on Change annotations and configuration, see [Change anatomy](../changes/anatomy-and-structure.md).

For operational workflows when issues occur, see [Issue resolution](issue-resolution.md).

---

// File: target-systems/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Target systems

Target systems are the real-world systems where your business changes are applied.
These include any external service your application interacts with or evolves - message queues, APIs, cloud services, databases, configuration stores, and more. The examples throughout this documentation are illustrative; Flamingock can work with any system your application needs to change.

A Change always declares which target system it belongs to. This ensures Flamingock can:
- Track and audit changes per system
- Guarantee safe execution across heterogeneous environments
- Provide clear visibility into which changes affect which systems

> **Conceptual Overview**: For architectural understanding of target systems vs audit store, see [Target Systems vs Audit Store](../get-started/audit-store-vs-target-system.md).


## Why target systems matter

### Explicit ownership
Every change is tied to a named target system, avoiding ambiguity and enabling clear governance.

### Transactionality awareness
- **Transactional target systems** (like PostgreSQL, MySQL, or MongoDB with transactions) allow Flamingock to use native rollback and guarantees.
- **Non-transactional systems** (like S3, Kafka, or REST APIs) are still safe, but Flamingock relies on rollback methods you provide.

This distinction is built into the target system definition.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

### Dependency isolation

Each target system provides its own dependency context, ensuring **target system isolation**. This means each system has its own set of dependencies that are isolated from other target systems, providing clear boundaries and preventing dependency conflicts between different systems, while still supporting global dependency injection as a fallback.

This isolation enables:
- Clear ownership of dependencies per target system
- Prevention of cross-system dependency conflicts
- Easier testing and debugging of system-specific changes

## Target system implementations

Flamingock provides target system implementations to handle specific behavior when needed. While most external systems work perfectly with the standard `NonTransactionalTargetSystem`, concrete implementations exist primarily to leverage native capabilities like transaction support. As the ecosystem evolves, new implementations may be added by the Flamingock team, community, or even custom-built by users - though custom implementations are rarely necessary.

### Non-transactional target system
The standard choice for systems without native transaction support:

- [Non-transactional target system](../target-systems/non-transactional-target-system.md) - For Kafka, S3, REST APIs, feature flags, file systems, and any other non-transactional system

### Transactional target systems
These implementations leverage native transaction capabilities for automatic rollback:

- [MongoDB target system](../target-systems/mongodb-target-system.md) - For MongoDB with the sync driver
- [MongoDB Spring Data target system](../target-systems/mongodb-springdata-target-system.md) - For MongoDB with Spring Data
- [SQL target system](../target-systems/sql-target-system.md) - For relational databases (PostgreSQL, MySQL, etc.)
- [DynamoDB target system](../target-systems/dynamodb-target-system.md) - For Amazon DynamoDB
- [Couchbase target system](../target-systems/couchbase-target-system.md) - For Couchbase

## Target system configuration

Target systems are configured using a **strict, no-fallback approach** with explicit parameters:

**Mandatory configuration**: Provided through constructor parameters only
- Must be provided at target system creation time
- No fallback to global context
- Example: `MongoClient` and `databaseName` for MongoDB target systems

```java
// Mandatory configuration via constructor
var mongoTarget = new MongoDBSyncTargetSystem("targetsystem-id", mongoClient, "userDatabase");
```

**No global context fallback** - target system configuration must be explicit and complete.


## Registering target systems

Target systems are registered at runtime. You can define and register as many as you need:

<Tabs groupId="registration">
  <TabItem value="builder" label="Flamingock Builder" default>

Use the Flamingock builder for standalone applications:

```java
var mysql = new SqlTargetSystem("mysql-inventory-id", dataSource);

var s3 = new NonTransactionalTargetSystem("aws-s3-id");

var kafka = new NonTransactionalTargetSystem("kafka-stock-id");

Flamingock.builder()
    .setAuditStore(new MongoDBSyncAuditStore(mongoClient, mongoDatabase))
    .addTargetSystems(mysql, s3, kafka)
    .build()
    .run();
```

At startup, Flamingock automatically injects the right dependencies from the corresponding target system into each Change.

  </TabItem>
  <TabItem value="springboot" label="Spring Boot">

For Spring Boot applications, register target systems as beans:

```java
@Bean
public NonTransactionalTargetSystem kafkaTargetSystem() {
    return new NonTransactionalTargetSystem("kafka-stock-id");
}

@Bean
public SqlTargetSystem sqlTargetSystem(DataSource dataSource) {
    return new SqlTargetSystem("mysql-inventory-id", dataSource);
}

@Bean
public MongoDBSyncTargetSystem mongoTargetSystem(MongoClient mongoClient) {
    return new MongoDBSyncTargetSystem("user-database-id", mongoClient, "userDb");
}

```

Spring Boot's auto-configuration will automatically register these target systems with Flamingock.

For more details, see [Spring Boot Integration](../frameworks/springboot-integration/introduction.md).

  </TabItem>
</Tabs>



## Linking Changes to target systems

When defining Changes, you specify which target system they belong to using the `@TargetSystem` annotation:

```java
@TargetSystem("mysql-inventory-id")
@Change(id = "add-category", author = "team")  // order extracted from filename
public class _0001__AddCategory {
    //...
}
```



## Dependency injection

Dependency injection is the mechanism used for **change execution**, providing the dependencies that Changes need to perform their operations. Each target system exposes specific dependencies required by its Changes:

- A MongoDB target system provides a `MongoDatabase`, `ClientSession`
- A Kafka target system provides a `KafkaTemplate`
- A SQL target system provides a `Connection` or `DataSource`

Flamingock uses a **flexible, multi-source approach** with fallback hierarchy for change execution:

1. **Target system context** (highest priority) - includes configuration parameters from constructor
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).


## Cloud Edition visibility

In the Cloud Edition, target systems become a first-class part of the dashboard:
- See all changes grouped by target system
- Filter execution history by system
- Track failures and recoveries per system

This makes it easier to govern and audit distributed environments at scale.


## Best practices

- Use descriptive names (`mysql-inventory`, `aws-s3`, `kafka-stock`)
- Be consistent across related Changes
- Avoid generic names like "database" or "api"
- Provide rollback logic for non-transactional systems
- Keep dependencies scoped to the system they belong to ‚Äî don‚Äôt overload the general context when they are system-specific



**Key Takeaway**: Target systems provide the foundation for safe, auditable changes across your entire technology stack. By explicitly declaring and configuring them, you enable Flamingock to orchestrate complex distributed system evolution with confidence.

---

// File: target-systems/non-transactional-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Non-transactional Target System

The Non-transactional target system (`NonTransactionalTargetSystem`) is Flamingock's generic target system **for any system that doesn't require specialized handling**. It serves as the universal option when no dedicated target system implementation exists or is needed for your specific technology.

## Why use NonTransactionalTargetSystem?

NonTransactionalTargetSystem is the fallback choice when there's no specialized target system implementation available for your technology. While Flamingock provides dedicated target systems for technologies that benefit from specific handling (like transactional systems that leverage native rollback capabilities), many systems don't require such specialization.

**When to use NonTransactionalTargetSystem:**
- No dedicated target system exists for your technology
- Your system doesn't have unique characteristics that warrant specialized handling
- You need a simple, flexible solution without technology-specific optimizations

**Future extensibility:** The Flamingock ecosystem may expand with more specialized target systems as specific needs are identified.


**Common systems using NonTransactionalTargetSystem:** Kafka Schema Registry, message queues, object storage (S3), REST APIs, file systems, cache systems, feature flags, search engines

## Installation

No specific dependencies are required for NonTransactionalTargetSystem. You can add any dependencies needed for your specific use case.

## Basic setup

Configure the target system:

```java
var schemaRegistry = new NonTransactionalTargetSystem("kafka-schema-registry-id");
```

Unlike specialized target systems, NonTransactionalTargetSystem requires no mandatory constructor dependencies. You have complete flexibility to inject whatever dependencies your Changes need.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The Non-transactional target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (none)

Unlike specialized target systems, NonTransactionalTargetSystem requires **no mandatory constructor dependencies**:

```java
// Only requires the target system name
var targetSystem = new NonTransactionalTargetSystem("system-name-id");
```


## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

| Method | Description |
|--------|-------------|
| `.addDependency(object)` | Add a dependency by type for changes |
| `.addDependency(name, object)` | Add a named dependency for changes |
| `.setProperty(key, value)` | Set a configuration property for changes |

1. **Target system context** (highest priority) - any dependencies added via `.addDependency()` or properties via `.setProperty()`
2. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (no mandatory constructor dependencies)
var schemaRegistry = new DefaultTargetSystem("kafka-schema-registry")
    .addDependency(schemaRegistryClient)     // Additional dependency for changes
    .addDependency("registry-url", "http://schema-registry:8081")  // Named dependency
    .setProperty("compatibility.level", "BACKWARD");  // Configuration property

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(metricsService)           // Available to all target systems
    .addDependency(notificationService)      // Available to all target systems
    .addTargetSystems(schemaRegistry)
    .build();
```

**Target system configuration resolution:**
- **No mandatory dependencies**: Target system created with name only
- **Additional dependencies**: Added via `.addDependency()` methods
- **Configuration properties**: Added via `.setProperty()` method

**Change dependency resolution for Changes in "kafka-schema-registry":**
- **SchemaRegistryClient**: From target system additional dependencies
- **Registry URL**: From target system context as named dependency ("registry-url")
- **Compatibility level**: From target system context as property ("compatibility.level")
- **MetricsService**: From global context (fallback)
- **NotificationService**: From global context (fallback)

This architecture provides maximum flexibility while maintaining clear separation between target system setup and change execution.

**How compensation works:**
1. **No transaction boundaries**: Operations execute immediately with no automatic rollback
2. **Rollback execution**: If any failure occurs, Flamingock calls the `@Rollback` method
3. **Manual compensation**: You provide the logic to undo or compensate for the changes made

**Important**: Always provide `@Rollback` methods for NonTransactionalTargetSystem Changes to ensure safe rollback capabilities.

## Available dependencies in Changes

Your Changes can inject any dependencies you add to the target system context via `.addDependency()` or properties via `.setProperty()`, which take precedence over global dependencies. Common examples include system clients, configuration values, custom services, and properties.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: target-systems/sql-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# SQL Target System

The SQL target system (`SqlTargetSystem`) enables Flamingock to apply changes to relational databases including PostgreSQL, MySQL, Oracle, and SQL Server using standard JDBC connections. As a transactional target system, it supports automatic rollback through the database's native transaction capabilities.

## Installation

Add a JDBC driver dependency for your database. For example, for PostgreSQL:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("org.postgresql:postgresql:42.3.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.3.0</version>
</dependency>
```
  </TabItem>
</Tabs>

You can use any JDBC driver for your database. Common examples include:
- **MySQL**: `com.mysql:mysql-connector-j`
- **Oracle**: `com.oracle.database.jdbc:ojdbc8`
- **SQL Server**: `com.microsoft.sqlserver:mssql-jdbc`
- **H2**: `com.h2database:h2`
- **HSQLDB**: `org.hsqldb:hsqldb`
- And any other JDBC-compliant driver

## Basic setup

Configure the target system:

```java
var sqlTarget = new SqlTargetSystem("inventory-database-id", dataSource);
```

The constructor requires the target system name and DataSource. Optional configurations can be added via `.withXXX()` methods.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The SQL target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (mandatory)

These dependencies must be provided at target system creation time with **no global context fallback**:

| Dependency | Constructor Parameter | Description |
|------------|----------------------|-------------|
| `DataSource` | `dataSource` | JDBC DataSource connection pool - **required** for both target system configuration and change execution |

## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

1. **Target system context** (highest priority) - `DataSource`, `Connection`
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (mandatory via constructor)
var sqlTarget = new SqlTargetSystem("inventory-database", inventoryDataSource)
    .addDependency(inventoryService);          // Additional dependency for changes

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(emailService)               // Available to all target systems
    .addDependency(logService)                 // Available to all target systems
    .addTargetSystems(sqlTarget)
    .build();
```

**Target system configuration resolution:**
- **DataSource**: Must be provided via constructor (`inventoryDataSource`)

**Change dependency resolution for Changes in "inventory-database":**
- **DataSource**: From target system context (`inventoryDataSource`)
- **Connection**: From target system context (derived from `inventoryDataSource`)
- **InventoryService**: From target system additional dependencies
- **EmailService**: From global context (fallback)
- **LogService**: From global context (fallback)

This architecture ensures explicit target system configuration while providing flexible dependency access for changes.

## Transactional support

For a Change to leverage SQL's transactional capabilities, it must use either the `DataSource` or `Connection` parameter. Flamingock uses the injected `DataSource` dependency to create connections and manage the transaction lifecycle - starting the transaction before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

```java
@TargetSystem("inventory-database-id")
@Change(id = "update-products", author = "team")  // order extracted from filename
public class _0001__UpdateProducts {

    @Apply
    public void apply(DataSource dataSource) throws SQLException {
        // DataSource automatically participates in transactions
        // Flamingock uses the target system's DataSource for transaction management
        // and handles transaction start, commit, and rollback automatically
        try (Connection conn = dataSource.getConnection()) {
            try (PreparedStatement stmt = conn.prepareStatement(
                "INSERT INTO products (id, name, price) VALUES (?, ?, ?)")) {
                stmt.setString(1, "P001");
                stmt.setString(2, "Updated Product");
                stmt.setBigDecimal(3, new BigDecimal("19.99"));
                stmt.executeUpdate();
            }
        }
    }
}
```

You can also inject a `Connection` directly if you prefer to work with connections instead of DataSource:

```java
@TargetSystem("inventory-database-id")
@Change(id = "create-indexes", author = "team")  // order extracted from filename
public class CreateIndexes {

    @Apply
    public void apply(Connection connection) throws SQLException {
        // Connection automatically participates in transactions
        // Flamingock uses the target system's connection for transaction operations
        // and handles transaction lifecycle automatically
        try (Statement stmt = connection.createStatement()) {
            stmt.execute("CREATE INDEX idx_product_name ON products(name)");
        }
    }
}
```

**How transactions work:**
1. **Connection management**: Flamingock uses the target system's `DataSource` to obtain database connections
2. **Transaction management**: The same `DataSource` or `Connection` handles transaction operations (begin, commit, rollback)
3. **Lifecycle**: Flamingock automatically manages transaction boundaries, committing on success or rolling back on failure

Without the `DataSource` or `Connection` parameter, operations will execute but won't participate in transactions.

## Available dependencies in Changes

Your Changes can inject SQL-specific dependencies like `DataSource` and `Connection`, but are not limited to these. The target system provides these dependencies through its context, and you can add additional dependencies via `.addDependency()` that take precedence over global dependencies.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: target-systems/mongodb-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Sync Target System

The MongoDB Sync target system (`MongoDBSyncTargetSystem`) enables Flamingock to apply changes to MongoDB databases using the official MongoDB Java sync driver. As a transactional target system, it supports automatic rollback through MongoDB's native transaction capabilities.

## Version compatibility

| Component | Version Requirement |
|-----------|-------------------|
| MongoDB Java Driver | 4.0.0+ |

MongoDB 4.0+ is required for transaction support.

## Installation

Add the MongoDB Java sync driver dependency to your project (version 4.0.0+ required):

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("org.mongodb:mongodb-driver-sync:4.0.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>org.mongodb</groupId>
    <artifactId>mongodb-driver-sync</artifactId>
    <version>4.0.0</version> <!-- 4.0.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the target system:

```java
var mongoTarget = new MongoDBSyncTargetSystem("user-database-id", mongoClient, "userDb");
```

The constructor requires the target system name, MongoDB client, and database name. Optional configurations can be added via `.withXXX()` methods.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The MongoDB target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (mandatory)

These dependencies must be provided at target system creation time with **no global context fallback**:

| Dependency | Constructor Parameter | Description |
|------------|----------------------|-------------|
| `MongoClient` | `mongoClient` | MongoDB connection client - **required** for both target system configuration and change execution |
| `String` | `databaseName` | Target database name - **required** to identify which database changes will affect |

## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

1. **Target system context** (highest priority) - `MongoClient`, `MongoDatabase`, `ClientSession`
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (mandatory via constructor)
var mongoTarget = new MongoDBSyncTargetSystem("user-database", productionMongoClient, "userDb")
    .addDependency(auditService);              // Additional dependency for changes

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(emailService)               // Available to all target systems
    .addDependency(logService)                 // Available to all target systems
    .addTargetSystems(mongoTarget)
    .build();
```

**Target system configuration resolution:**
- **MongoClient**: Must be provided via constructor (`productionMongoClient`)
- **Database name**: Must be provided via constructor (`"userDb"`)

**Change dependency resolution for Changes in "user-database":**
- **MongoClient**: From target system context (`productionMongoClient`)
- **MongoDatabase**: From target system context (derived from `productionMongoClient` + `"userDb"`)
- **ClientSession**: From target system context (created by Flamingock)
- **AuditService**: From target system additional dependencies
- **EmailService**: From global context (fallback)
- **LogService**: From global context (fallback)

This architecture ensures explicit target system configuration while providing flexible dependency access for changes.

## Transactional support

For a Change to leverage MongoDB's transactional capabilities, it must use the `ClientSession` parameter. Flamingock uses the injected `MongoClient` and `MongoDatabase` dependencies to create and manage this session's lifecycle - starting the transaction before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

```java
@TargetSystem("user-database-id")
@Change(id = "create-users", author = "team")  // order extracted from filename
public class _0001__CreateUsers {

    @Apply
    public void apply(MongoDatabase db, ClientSession session) {
        // The ClientSession is required for transactional execution
        // Flamingock uses the target system's MongoClient to create this session
        // and handles transaction start, commit, and rollback automatically
        db.getCollection("users")
          .insertOne(session, new Document("name", "John"));
    }
}
```

**How transactions work:**
1. **Session creation**: Flamingock uses the target system's `MongoClient` to create a `ClientSession`
2. **Transaction management**: The same `MongoClient` and `MongoDatabase` handle transaction operations
3. **Lifecycle**: Flamingock automatically starts the transaction, commits on success, or rolls back on failure

Without the `ClientSession` parameter, operations will execute but won't participate in transactions.

## Available dependencies in Changes

Your Changes can inject MongoDB-specific dependencies like `MongoClient`, `MongoDatabase`, and `ClientSession` (for transactions), but are not limited to these. The target system provides these dependencies through its context, and you can add additional dependencies via `.addDependency()` that take precedence over global dependencies.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: target-systems/mongodb-springdata-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Spring Data Target System

The MongoDB Spring Data target system (`MongoDBSpringDataTargetSystem`) enables Flamingock to apply changes to MongoDB databases using Spring Data MongoDB. As a transactional target system, it integrates seamlessly with Spring's transaction management and supports automatic rollback through MongoDB's native transaction capabilities.

## Version compatibility

| Component | Version Requirement |
|-----------|-------------------|
| Spring Data MongoDB | 3.1.x - 4.x |

Spring Data MongoDB versions from 3.1.x through 4.x are supported. Version 3.1.x+ is included in Spring Boot 2.4.3+.

## Installation

Add the Spring Data MongoDB dependency to your project (versions 3.1.x - 4.x supported):

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("org.springframework.data:spring-data-mongodb:3.1.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>org.springframework.data</groupId>
    <artifactId>spring-data-mongodb</artifactId>
    <version>3.1.0</version> <!-- 3.1.x - 4.x supported -->
</dependency>
```
  </TabItem>
</Tabs>


## Basic setup

Configure the target system:

```java
var mongoTarget = new MongoDBSpringDataTargetSystem("user-database-id", mongoTemplate);
```

The constructor requires the target system name and MongoDB template. Optional configurations can be added via `.withXXX()` methods.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The MongoDB Spring Data target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (mandatory)

These dependencies must be provided at target system creation time with **no global context fallback**:

| Dependency | Constructor Parameter | Description |
|------------|----------------------|-------------|
| `MongoTemplate` | `mongoTemplate` | Spring Data MongoDB template - **required** for both target system configuration and change execution |

## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

1. **Target system context** (highest priority) - `MongoTemplate`
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (mandatory via constructor)
var mongoTarget = new MongoDBSpringDataTargetSystem("user-database", userMongoTemplate)
    .addDependency(userAuditService);          // Additional dependency for changes

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(emailService)               // Available to all target systems
    .addDependency(logService)                 // Available to all target systems
    .addTargetSystems(mongoTarget)
    .build();
```

**Target system configuration resolution:**
- **MongoTemplate**: Must be provided via constructor (`userMongoTemplate`)

**Change dependency resolution for Changes in "user-database":**
- **MongoTemplate**: From target system context (`userMongoTemplate`)
- **UserAuditService**: From target system additional dependencies
- **EmailService**: From global context (fallback)
- **LogService**: From global context (fallback)

This architecture ensures explicit target system configuration while providing flexible dependency access for changes.

## Transactional support

Spring Data MongoDB target system integrates with Spring's transaction management. When a Change is marked as transactional (the default), Flamingock uses the injected `MongoTemplate` dependency to handle transaction operations through Spring's infrastructure.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

```java
@TargetSystem("user-database-id")
@Change(id = "create-users", author = "team")  // order extracted from filename
public class _0001__CreateUsers {

    @Apply
    public void apply(MongoTemplate mongoTemplate) {
        // MongoTemplate automatically participates in Spring transactions
        // Flamingock uses the target system's MongoTemplate for transaction management
        // through Spring's @Transactional infrastructure
        mongoTemplate.save(new User("john@example.com", "John Doe"));
    }
}
```

**How transactions work:**
1. **Spring integration**: Flamingock leverages the target system's `MongoTemplate` within Spring's transaction context
2. **Transaction management**: The same `MongoTemplate` handles both Change operations and transaction coordination
3. **Lifecycle**: Spring's transaction infrastructure manages start, commit, and rollback automatically

The transaction lifecycle is managed through Spring's transaction infrastructure, ensuring consistency with your existing Spring Data operations.

## Available dependencies in Changes

Your Changes can inject Spring Data dependencies like `MongoTemplate`, but are not limited to these. The target system provides these dependencies through its context, and you can add additional dependencies via `.addDependency()` that take precedence over global dependencies.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Spring integration

This target system is designed to work seamlessly with Spring Boot applications. When using Spring Boot auto-configuration, your existing `MongoTemplate` beans are automatically available for injection into target systems.

For more information on Spring Boot integration, see [Spring Boot integration](../frameworks/springboot-integration/introduction.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: target-systems/dynamodb-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# DynamoDB Target System

The DynamoDB target system (`DynamoDBTargetSystem`) enables Flamingock to apply changes to Amazon DynamoDB using the AWS SDK for Java. As a transactional target system, it supports automatic rollback through DynamoDB's transaction capabilities with `TransactWriteItems`.

## Version compatibility

| Component | Version Requirement |
|-----------|-------------------|
| AWS SDK DynamoDB Enhanced | 2.25.0+ |

AWS SDK DynamoDB Enhanced 2.25.0+ is required and must be included in your project dependencies.

## Installation

Add the AWS SDK DynamoDB Enhanced dependency to your project (version 2.25.0+ required):

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("software.amazon.awssdk:dynamodb-enhanced:2.25.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>dynamodb-enhanced</artifactId>
    <version>2.25.0</version> <!-- 2.25.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the target system:

```java
var dynamoTarget = new DynamoDBTargetSystem("inventory-database-id", dynamoDbClient);
```

The constructor requires the target system name and DynamoDB client. Optional configurations can be added via `.withXXX()` methods.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The DynamoDB target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (mandatory)

These dependencies must be provided at target system creation time with **no global context fallback**:

| Dependency | Constructor Parameter | Description |
|------------|----------------------|-------------|
| `DynamoDbClient` | `dynamoDbClient` | AWS DynamoDB client - **required** for both target system configuration and change execution |

## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

1. **Target system context** (highest priority) - `DynamoDbClient`, `TransactWriteItemsEnhancedRequest.Builder`
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (mandatory via constructor)
var dynamoTarget = new DynamoDBTargetSystem("inventory-database", inventoryDynamoClient)
    .addDependency(inventoryService);           // Additional dependency for changes

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(emailService)                // Available to all target systems
    .addDependency(logService)                  // Available to all target systems
    .addTargetSystems(dynamoTarget)
    .build();
```

**Target system configuration resolution:**
- **DynamoDbClient**: Must be provided via constructor (`inventoryDynamoClient`)

**Change dependency resolution for Changes in "inventory-database":**
- **DynamoDbClient**: From target system context (`inventoryDynamoClient`)
- **TransactWriteItemsEnhancedRequest.Builder**: From target system context (created by Flamingock)
- **InventoryService**: From target system additional dependencies
- **EmailService**: From global context (fallback)
- **LogService**: From global context (fallback)

This architecture ensures explicit target system configuration while providing flexible dependency access for changes.

## Transactional support

For a Change to leverage DynamoDB's transactional capabilities, it must use the `TransactWriteItemsEnhancedRequest.Builder` parameter. Flamingock uses the injected `DynamoDbClient` dependency to create and manage this builder's lifecycle - creating it before execution and executing the transaction with all operations on success.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

```java
@TargetSystem("inventory-database-id")
@Change(id = "update-inventory", author = "team")  // order extracted from filename
public class _0001__UpdateInventory {

    @Apply
    public void apply(DynamoDbClient client,
                         TransactWriteItemsEnhancedRequest.Builder txBuilder) {
        // The transaction builder is required for transactional execution
        // Flamingock uses the target system's DynamoDbClient to handle transaction operations
        // and manages transaction creation, execution, and rollback automatically

        DynamoDbEnhancedClient enhancedClient = DynamoDbEnhancedClient.builder()
            .dynamoDbClient(client)
            .build();

        DynamoDbTable<Product> table = enhancedClient.table("products",
            TableSchema.fromBean(Product.class));

        // Add operations to the transaction
        txBuilder.addPutItem(table, new Product("123", "Updated Product"));
        txBuilder.addDeleteItem(table, Key.builder().partitionValue("456").build());
    }
}
```

**How transactions work:**
1. **Builder creation**: Flamingock uses the target system's `DynamoDbClient` to create a `TransactWriteItemsEnhancedRequest.Builder`
2. **Transaction management**: The same `DynamoDbClient` executes the transaction with all accumulated operations
3. **Lifecycle**: Flamingock automatically creates the builder, executes the transaction on success, or handles rollback on failure

Without the `TransactWriteItemsEnhancedRequest.Builder` parameter, operations will execute but won't participate in transactions.

## Available dependencies in Changes

Your Changes can inject DynamoDB-specific dependencies like `DynamoDbClient` and `TransactWriteItemsEnhancedRequest.Builder`, but are not limited to these. The target system provides these dependencies through its context, and you can add additional dependencies via `.addDependency()` that take precedence over global dependencies.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: target-systems/couchbase-target-system

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Couchbase Target System

The Couchbase target system (`CouchbaseTargetSystem`) enables Flamingock to apply changes to Couchbase databases using the official Couchbase Java SDK. As a transactional target system, it supports automatic rollback through Couchbase's transaction capabilities.

## Version compatibility

| Component | Version Requirement |
|-----------|-------------------|
| Couchbase Java Client | 3.6.0+ |

Couchbase Java Client 3.6.0+ is required and must be included in your project dependencies.

## Installation

Add the Couchbase Java Client dependency to your project (version 3.6.0+ required):

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>
```kotlin
implementation("com.couchbase.client:java-client:3.6.0")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>com.couchbase.client</groupId>
    <artifactId>java-client</artifactId>
    <version>3.6.0</version> <!-- 3.6.0+ supported -->
</dependency>
```
  </TabItem>
</Tabs>

## Basic setup

Configure the target system:

```java
var couchbaseTarget = new CouchbaseTargetSystem("user-database-id", cluster, "userBucket");
```

The constructor requires the target system name, Couchbase cluster, and bucket name. Optional configurations can be added via `.withXXX()` methods.

:::info Register Target System
Once created, you need to register this target system with Flamingock. See [Registering target systems](introduction.md#registering-target-systems) for details.
:::

## Target System configuration

The Couchbase target system uses Flamingock's [split dependency resolution architecture](introduction.md#dependency-injection) with separate flows for target system configuration and change execution dependencies.

### Constructor dependencies (mandatory)

These dependencies must be provided at target system creation time with **no global context fallback**:

| Dependency | Constructor Parameter | Description |
|------------|----------------------|-------------|
| `Cluster` | `cluster` | Couchbase cluster connection - **required** for both target system configuration and change execution |
| `String` | `bucketName` | Target bucket name - **required** for both target system configuration and change execution |

## Dependencies available to Changes

Changes can access dependencies through [dependency injection with fallback](../changes/anatomy-and-structure.md#method-parameters-and-dependency-injection):

1. **Target system context** (highest priority) - `Cluster`, `Bucket`, `TransactionAttemptContext`
2. **Target system additional dependencies** - added via `.addDependency()` or `.setProperty()`
3. **Global context** (fallback) - shared dependencies available to all target systems

## Configuration example

Here's a comprehensive example showing the new architecture:

```java
// Target system configuration (mandatory via constructor)
var couchbaseTarget = new CouchbaseTargetSystem("user-database", productionCluster, "userBucket")
    .addDependency(auditService);          // Additional dependency for changes

// Global context with shared dependencies
Flamingock.builder()
    .addDependency(emailService)           // Available to all target systems
    .addDependency(logService)             // Available to all target systems
    .addTargetSystems(couchbaseTarget)
    .build();
```

**Target system configuration resolution:**
- **Cluster**: Must be provided via constructor (`productionCluster`)
- **Bucket name**: Must be provided via constructor (`"userBucket"`)

**Change dependency resolution for Changes in "user-database":**
- **Cluster**: From target system context (`productionCluster`)
- **Bucket**: From target system context (derived from `productionCluster` + `"userBucket"`)
- **TransactionAttemptContext**: From target system context (created by Flamingock)
- **AuditService**: From target system additional dependencies
- **EmailService**: From global context (fallback)
- **LogService**: From global context (fallback)

This architecture ensures explicit target system configuration while providing flexible dependency access for changes.

## Transactional support

For a Change to leverage Couchbase's transactional capabilities, it must use the `TransactionAttemptContext` parameter. Flamingock uses the injected `Cluster` and `Bucket` dependencies to create and manage this context's lifecycle - creating the transaction context before execution, committing on success, and rolling back on failure.

> For detailed information on transaction handling, see [Transactions](../changes/transactions.md).

```java
@TargetSystem("user-database-id")
@Change(id = "create-users", author = "team")  // order extracted from filename
public class _0001__CreateUsers {

    @Apply
    public void apply(Cluster cluster, Bucket bucket, TransactionAttemptContext txContext) {
        // TransactionAttemptContext is required for transactional execution
        // Flamingock uses the target system's Cluster and Bucket to handle transaction operations
        // and manages transaction start, commit, and rollback automatically
        Collection collection = bucket.defaultCollection();

        JsonObject user = JsonObject.create()
            .put("name", "John Doe")
            .put("email", "john@example.com");

        txContext.insert(collection, "user::001", user);
    }
}
```

You can also work with the Cluster and Bucket directly without transactions:

```java
@TargetSystem("user-database-id")
@Change(id = "update-configs", author = "team")  // order extracted from filename
public class _0002__UpdateConfigs {

    @Apply
    public void apply(Cluster cluster, Bucket bucket) {
        // Operations without TransactionAttemptContext won't participate in transactions
        Collection collection = bucket.defaultCollection();

        JsonObject config = JsonObject.create()
            .put("version", "2.0")
            .put("updated", Instant.now().toString());

        collection.upsert("config::app", config);
    }
}
```

**How transactions work:**
1. **Context creation**: Flamingock uses the target system's `Cluster` to create an `TransactionAttemptContext` for transaction management
2. **Transaction management**: The same `Cluster` and `Bucket` handle transaction operations and coordinate with the context
3. **Lifecycle**: Flamingock automatically creates the transaction context, commits on success, or rolls back on failure

Without the `TransactionAttemptContext` parameter, operations will execute but won't participate in transactions.

## Available dependencies in Changes

Your Changes can inject Couchbase-specific dependencies like `Cluster`, `Bucket`, and `TransactionAttemptContext` (for transactions), but are not limited to these. The target system provides these dependencies through its context, and you can add additional dependencies via `.addDependency()` that take precedence over global dependencies.

For comprehensive details on change dependency resolution, see [Change Anatomy & Structure](../changes/anatomy-and-structure.md).

## Next steps

- Learn about [Target systems](introduction.md)
- Explore [Changes](../changes/introduction.md)
- See [Flamingock examples](https://github.com/flamingock/flamingock-java-examples)

---

// File: templates/templates-introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Templates

:::caution Beta feature
Templates are available in **beta**.
- You can already create **custom templates** for your own use cases.
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.
- We're building a **comprehensive template catalog** where teams can discover, share, and contribute templates for common integration patterns.
- Expect API and behavior changes before GA.

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of Changes.
:::

## Introduction

Flamingock Templates are experimental modules designed to streamline the integration of common third-party services, databases, and configurations into the **Flamingock change management system**. These templates provide a structured way to define system changes in declarative format (such as **YAML** files), reducing the need for custom code-based Changes while ensuring execution and versioning of changes.

## How it works

Flamingock Templates are designed to simplify change definitions by extracting reusable logic into modular building blocks. While **Flamingock‚Äôs core approach** relies on code-based Changes to manage database and system changes, Flamingock Templates provide a **low-code alternative** that simplifies the process for common integration scenarios. Instead of writing Java classes for each change, users can leverage existing templates by defining changes in a declarative format(**YAML**, etc.).

### Who provides Templates?

Templates can be:
- **Provided by the Flamingock core team** (e.g., SQL, Kafka, Redis)
- **Offered by the community**
- **Created internally by teams** to address common patterns in their own systems

This makes them highly adaptable: whether you're integrating a database, messaging system, or internal service, templates give you a low-code mechanism to structure your system changes cleanly and consistently.

### Why do Templates exist?

Templates exist to solve a common problem in traditional, code-based changes: **duplicated logic across Changes**.

Instead of repeating the same boilerplate code over and over, templates let you **externalize the logic** into a reusable definition and **parameterize** what's different.

Today, Flamingock templates can already be created and used in your own projects. However, the official templates provided by the Flamingock team are experimental, and their APIs may change before GA.

## Key features

- **Reusable modules**: Each template provides a well-defined structure for managing system changes and configurations.
- **Declarative Changes**: Users define changes in YAML, avoiding Java boilerplate.
- **Support for third-party integrations**: Includes databases, messaging systems, and cloud configurations.
- **Automatic execution and versioning**: Templates are applied and tracked as part of Flamingock's change management process.
- **Designed to encourage best practices, though still experimental**.
- **Extensible by the community**: Developers can contribute new templates to expand Flamingock's ecosystem.

## When Template-based Changes shine

Template-based Changes are ideal when you have **reusable patterns** in your system changes. They excel in scenarios where the same type of operation needs to be repeated with different parameters, allowing you to avoid duplicating boilerplate code across multiple Changes.

**Templates shine when:**

- **You have repetitive patterns**: Creating database tables, indexes, Kafka topics, S3 buckets, or API configurations that follow the same structure but with different values
- **Multiple team members need to make similar changes**: Templates provide a consistent, declarative way for developers to define changes without writing boilerplate code
- **You want to enforce best practices**: Templates encapsulate proven logic and prevent implementation inconsistencies across your changes
- **The change type already has a template**: Why reinvent the wheel when S3, Kafka, SQL, MongoDB, or other common templates already exist?

**Stick with code-based Changes when:**

- **You have unique, one-off logic**: Complex business transformations that are specific to your application and unlikely to be repeated
- **You need maximum flexibility**: Custom integrations or complex workflows that require full programmatic control
- **No suitable template exists**: When your use case doesn't match any available templates and creating a custom template isn't justified

**Remember**: Templates can handle any level of complexity - from simple configuration updates to sophisticated multi-step operations. The decision isn't about complexity, but about **reusability** and whether the pattern is worth abstracting into a declarative format.

Flamingock Templates unlock new possibilities for application evolution. Whether you're managing **databases, configurations, or third-party services**, templates simplify the process, though they are still experimental and not yet recommended for production use.

:::tip
Join the [**Flamingock community**](https://github.com/flamingock/flamingock-java/discussions) and start building your own templates today! üöÄ
:::

---

// File: templates/templates-how-to-use

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# How to use Flamingock Templates

:::caution Beta feature
Templates are available in **beta**.
- You can already create **custom templates** for your own use cases.
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.
- Expect API and behavior changes before GA.

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of Changes.
:::

Using a Flamingock Template is straightforward. Here's an example of how you can apply an SQL-based change using the **SQL Template**.

:::danger
This example uses the **SQL Template**, which is experimental. It is intended for testing and feedback, not yet production use.
:::

### Step 1: Add the Template dependency

Ensure your **Flamingock Template** dependency is included in your project. Example of using `SqlTemplate`:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$version"))
implementation("io.flamingock:flamingock-sql-template")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-sql-template</artifactId>
</dependency>
```
  </TabItem>
</Tabs>

### Step 2: define a Template-based change

In Flamingock, a **Change** represents a single unit of work that needs to be applied to your system ‚Äî for example, creating a table, updating a configuration, or setting up a cloud resource.

When using template-based changes, instead of implementing a code-based file to define the logic of the change, you describe the change in a declarative format (e.g., **YAML** file). The structure you use will depend on the template you‚Äôre leveraging.

Create a **YAML file** (e.g., `_0001__CreatePersonsTable.yaml`) inside your application‚Äôs resources directory:

```yaml
id: CreatePersonsTableFromTemplate
targetSystem: "database-system"
template: SqlTemplate
recovery:
  strategy: ALWAYS_RETRY  # Safe to retry - CREATE TABLE IF NOT EXISTS semantics
apply: |
  CREATE TABLE IF NOT EXISTS Persons (
    PersonID int,
    LastName varchar(255),
    FirstName varchar(255),
    Address varchar(255),
    City varchar(255)
  )
rollback: "DROP TABLE IF EXISTS Persons;"
```

#### üîç Understanding the configuration attributes

- **`id`**: Unique identifier for the change, used for tracking (same as in code-based changes).
- **`order`**: Execution order relative to other changes (also shared with code-based).
- **`targetSystem`**: Specifies which target system this change applies to - **required** for all template-based changes, just like code-based Changes.
- **`template`**: Indicates which template should be used to handle the change logic. This is **required** for all template-based changes.
- **`apply`**: Direct apply logic for the change. The format depends on the template type (string for SQL, map for MongoDB, etc.).
- **`rollback`**: Direct rollback logic for the change. The format depends on the template type (string for SQL, map for MongoDB, etc.).
- **`recovery`**: Optional failure handling configuration. Contains:
  - `strategy`: Can be `MANUAL_INTERVENTION` (default if not specified) or `ALWAYS_RETRY`. Use `ALWAYS_RETRY` for idempotent operations that can be safely retried.
- **`configuration`**: Optional configuration parameters accessible within the `apply` and `rollback` sections. The structure and available parameters are defined by the specific template being used.
  ```yaml
  configuration:
    timeout: 30
    retryCount: 3
  ```
- **Other fields**: Templates may define additional configuration fields as needed.

Template-based changes provide both **structure and flexibility**. They share the core concepts of change tracking with code-based Changes, but use a standardized format with `apply` and `rollback` sections that each template interprets according to its specific requirements. Templates can also accept optional `configuration` parameters to customize their behavior.

### Step 3: Configure Flamingock to use the template file

To configure Flamingock to use the YAML template file, you need to define a stage that includes the path to the template file using the `@EnableFlamingock` annotation:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "resources/templates")
    }
)
public class MainApplication {
    // Configuration class
}
```

If you prefer to use a pipeline YAML file for configuration, refer to the [Setup & Stages guide](../flamingock-library-config/setup-and-stages.md) for more details.

### Step 4: Run Flamingock

At application startup, Flamingock will automatically detect the YAML file and process it as a standard change, following the same apply flow as code-based changes.

## Use case: SQL database changes

Let's compare how an SQL change is handled using a **template-based Change** vs. a **traditional code-based Change**.

### Approach 1: Using a traditional code-based Change

```java
@Change(id = "create-persons-table", order = "20250408_01", author = "developer")
public class CreatePersonsTableChange {

    private final DataSource dataSource;

    public CreatePersonsTableChange(DataSource dataSource) {
        this.dataSource = dataSource;
    }

    @Apply
    public void apply() throws SQLException {
        try (Connection connection = dataSource.getConnection();
             Statement statement = connection.createStatement()) {

            statement.executeUpdate("""
                CREATE TABLE Persons (
                    PersonID int PRIMARY KEY,
                    LastName varchar(255),
                    FirstName varchar(255),
                    Address varchar(255),
                    City varchar(255)
                )
            """);
        }
    }
}

```

### Approach 2: Using a Flamingock SQL Template

With the **SQL Template**, users define the same change in **YAML** instead of Java:

```yaml
id: createPersonsTableFromTemplate
targetSystem: "database-system"
template: SqlTemplate
recovery:
  strategy: MANUAL_INTERVENTION  # Critical DDL operation - requires manual review on failure
apply: |
    CREATE TABLE Persons (
        PersonID int PRIMARY KEY,
        LastName varchar(255),
        FirstName varchar(255),
        Address varchar(255),
        City varchar(255)
    )
rollback: "DROP TABLE Persons;"
```

### Key benefits of using a Template instead of code-based Changes:
- **Less code maintenance**: No need to write Java classes, inject DataSource, manage connections, or handle SQL apply manually.
- **Faster onboarding**: YAML is easier for non-Java developers.
- **Standardised changes**: Ensures best practices and avoids custom implementation errors.
- **Improved readability**: Easier to review and version control.
- **Configurable flexibility**: Templates can be customized through configuration parameters without code changes.

---

// File: templates/create-your-own-template

# Create your own Flamingock template


:::caution Beta feature
Templates are available in **beta**.
- You can already create **custom templates** for your own use cases.
- Flamingock is actively developing **official templates** for key technologies (Kafka, SQL, MongoDB, S3, Redis, etc.) that are currently in development and not yet production-ready.
- Expect API and behavior changes before GA.

This feature is a **sneak peek of Flamingock's future**: a low-code, reusable ecosystem on top of Changes.
:::

While official Flamingock templates are experimental, you can already build and use your own custom templates in production if needed. This page explains how.

## Introduction

[Flamingock Templates](./templates-introduction.md) allow you to encapsulate common logic and reduce boilerplate when defining change units. This document explains how to create your own templates for reuse across projects or for contribution to the Flamingock community.

## Overview of the required components

To create a template, you need:

- A Java class extending `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>`
- An `@Apply` method to perform the main change
- (Optionally) A `@Rollback` method for undo support
- A service loader registration file (`META-INF/services`)
- (Optional) Package and distribute your template

## 1. Implement the Template class

Extend `AbstractChangeTemplate<SHARED_CONFIG, APPLY, ROLLBACK>` with three generics:

- **SHARED_CONFIG**: Shared configuration that applies to both apply and rollback (e.g., database connection, common settings). Use `Void` if no shared config is needed.
- **APPLY**: The type representing the apply logic/data
- **ROLLBACK**: The type representing the rollback logic/data

**Example:**

```java
public class MongoChangeTemplate extends AbstractChangeTemplate<Void, MongoOperation, MongoOperation> {

    public MongoChangeTemplate() {
        super(MongoOperation.class);
    }

    @Apply
    public void apply(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional change[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, applyPayload, clientSession);
    }

    @Rollback
    public void rollback(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional change[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, rollbackPayload, clientSession);
    }

    private void executeOp(MongoDatabase db, MongoOperation op, ClientSession clientSession) {
        op.getOperator(db).apply(clientSession);
    }
}
```

#### Important notes
- Access your apply and rollback data directly via `this.applyPayload` and `this.rollbackPayload` fields.
- Access shared configuration via `this.configuration` field (if using a non-Void shared config type).
- If your template references custom types, make sure to register them for reflection‚Äîespecially for **GraalVM** native builds. When extending `AbstractChangeTemplate`, you can pass your custom types to the superclass constructor to ensure proper reflection support.

:::note
See [**2. Define Execution and Rollback methods** ](#2-define-execution-and-rollback-methods) section for how to implement the core logic inside your template class using the apply/rollback data and dependency injection
:::

## 2. Define Execution and Rollback methods
Each template must include an `@Apply` method, and may optionally include a `@Rollback` method.
These methods define the core logic that will be executed when Flamingock runs the corresponding change.

Inside these methods, it‚Äôs expected that you use the data provided by the user in the template-based change unit through the following fields:

- `this.applyPayload` ‚Äî the apply logic/data to apply during apply phase
- `this.rollbackPayload` ‚Äî the rollback logic/data to apply during rollback or undo
- `this.configuration` ‚Äî shared configuration data (if using a non-Void shared config type)

An example of a template for Kafka topic management:

:::info
This is an illustrative example to demonstrate the template structure. Real Kafka templates would use different parameters and configuration structures based on actual requirements.
:::

```java
public class KafkaTopicTemplate extends AbstractChangeTemplate<Void, TopicConfig, String> {

    public KafkaTopicTemplate() {
        super(TopicConfig.class);
    }

    @Apply
    public void apply(AdminClient adminClient) throws Exception {
        // Create topic using the apply configuration
        var newTopic = new NewTopic(
            this.applyPayload.getName(),
            this.applyPayload.getPartitions(),
            this.applyPayload.getReplicationFactor()
        );
        newTopic.configs(this.applyPayload.getConfigs());

        adminClient.createTopics(List.of(newTopic)).all().get();
    }

    @Rollback
    public void rollback(AdminClient adminClient) throws Exception {
        // Delete topic using the rollback topic name
        adminClient.deleteTopics(List.of(this.rollbackPayload)).all().get();
    }
}
```

### Example with shared configuration

When you need to share configuration between apply and rollback (such as connection details, common settings, etc.), you can use a non-Void shared configuration type:

:::info
This is an illustrative example to demonstrate the shared configuration pattern. Real S3 templates would use different parameters and configuration structures based on actual AWS SDK requirements.
:::

```java
public class S3BucketTemplate extends AbstractChangeTemplate<S3ConnectionConfig, BucketCreationRequest, String> {

    public S3BucketTemplate() {
        super(S3ConnectionConfig.class, BucketCreationRequest.class);
    }

    @Apply
    public void apply() {
        // Access shared configuration for AWS connection
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();

        // Create bucket using apply configuration
        var request = new CreateBucketRequest(this.applyPayload.getBucketName())
            .withCannedAcl(this.applyPayload.getAcl());

        if (this.applyPayload.getEncryption() != null) {
            // Apply encryption settings
            request.withObjectLockEnabledForBucket(this.applyPayload.getEncryption().isEnabled());
        }

        s3Client.createBucket(request);
    }

    @Rollback
    public void rollback() {
        // Use the same shared configuration for rollback
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();

        // Delete bucket using rollback bucket name
        s3Client.deleteBucket(this.rollbackPayload);
    }
}
```

This pattern is useful when:
- Both apply and rollback need the same configuration data (AWS credentials, region, etc.)
- You want to avoid duplicating connection details or common settings
- The template needs different data for apply vs rollback operations

### Injecting dependencies into Template methods
Template methods (such as those annotated with `@Apply` and `@Rollback`) support method-level dependency injection using the same mechanism as change units.

Template classes do not support constructor injection.
All dependencies must be injected as parameters in the `@Apply` and `@Rollback` methods.

You can inject any registered dependency as a method parameter:

```java
@Apply
public void apply(MongoDatabase db, ClientService clientService) {
  clientService.doSomething();
}
```
:::info
Flamingock will apply lock-safety guards unless you annotate the parameter with `@NonLockGuarded`.
:::

### Mapping between template-base change file and template methods

Flamingock automatically maps the `apply` and `rollback` sections in your declarative change unit to the corresponding methods in your template class.

## 3. Register the Template with ServiceLoader

Templates are discovered automatically at runtime using Java‚Äôs `ServiceLoader` system.

Steps:
1. Create a file at:

```
src/main/resources/META-INF/services/io.flamingock.core.api.template.ChangeTemplate
```

2. List the fully qualified class names of all templates in the file:

```plaintext
io.flamingock.template.kafka.CreateTopicTemplate
io.flamingock.template.kafka.UpdateTopicConfigTemplate
io.flamingock.template.kafka.DeleteTopicTemplate
```

:::tip
Group templates by domain or technology for better maintainability.
:::

## 4. Package and distribute the Template

Depending on your target:

### Internal Templates (private)
- No special packaging needed.
- Keep your template class inside your application.

### Public Templates (contributing to the Community)
- Package your template as a JAR.
- Notify the Flamingock team via [development@flamingock.io](mailto:development@flamingock.io) or GitHub.
- Submit your template for validation.

#### Validation requirements:
- Clear and justified use case
- Name must align and not conflict with existing templates
- Technically correct and production-grade implementation
- Public classes must be Javadoc-documented
- Submit a Pull Request adding the template's documentation to [flamingock.github.io](https://github.com/flamingock/flamingock.github.io)

## ‚úÖ Best Practices

- Use `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>` with the appropriate generic types for your use case.
- Always provide an `@Rollback` method if rollback or undo is expected.
- Use `Void` for generics when that type is not needed (e.g., `<Void, String, String>` for simple SQL templates).
- Use shared configuration (`<ConfigType, Void, Void>`) when both apply and rollback need the same configuration data.
- Document your template's purpose and generic types clearly for users.
- Ensure all custom types are registered for reflection by passing them to the superclass constructor, especially when targeting native builds.
- Group multiple templates by domain when packaging a library.

---

// File: testing/introduction

## Introduction

This section provides guidance on how to test applications that use **Flamingock**, including strategies for validating your change logic, ensuring proper execution coordination, and maintaining audit and rollback guarantees.

Whether you are running Flamingock in a local development environment, as part of CI pipelines, or through framework integrations like Spring Boot, testing is a key part of ensuring consistency and reliability across deployments.

Flamingock is not limited to database systems ‚Äî it supports a wide range of targets (e.g., message brokers, file systems, APIs). Your testing strategy should reflect the behavior of the underlying systems you integrate with.


## Test support framework

Flamingock provides a **BDD-style test support framework** that simplifies integration testing with a fluent Given-When-Then API. The framework is available in two modules:

| Module | Use case |
|--------|----------|
| `flamingock-test-support` | Standalone/programmatic tests without Spring |
| `flamingock-springboot-test-support` | Spring Boot integration tests |

Both modules share the same BDD API for defining expectations and validating results. See [BDD test API](./flamingock-bdd-api.md) for the complete API reference.


## What to test

There are **three primary levels** at which Flamingock-related functionality can be tested:

### 1. Unit test: Change logic
Isolate and test the logic inside your `@Apply` and `@Rollback` methods without involving Flamingock's runtime or audit mechanism.

- Use mocks for dependencies (e.g., `MongoTemplate`, `DynamoDbClient`, `S3Client`)
- Focus on business correctness and expected side effects
- No audit logs or locking are involved

See [Unit testing your change units](./unit-testing.md)


### 2. Integration test: Flamingock execution
Run Flamingock end-to-end using the test support framework to verify:

- Execution of changes and audit log persistence
- Rollback behavior on failure
- Correct handling of previously applied changes
- Use `FlamingockTestSupport`
- Validate changes using the Flamingock BDD API

See [Integration testing Flamingock](./integration-testing.md)


### 3. Spring Boot integration
For applications using **Spring Boot**, test how Flamingock integrates with your app lifecycle:

- Use `@FlamingockSpringBootTest` to configure test context with deferred execution
- Use autowired `FlamingockSpringBootTestSupport` to control when Flamingock runs
- Validate changes using the Flamingock BDD API

See [Testing with Spring Boot](./springboot-integration-testing.md)

---

// File: testing/flamingock-bdd-api

## Introduction

Flamingock's test support framework provides a fluent BDD-style API for writing integration tests. This API is shared between standalone and Spring Boot tests ‚Äî once you understand these concepts, you can apply them in either context.

The API follows a **Given-When-Then** pattern:

```java
FlamingockTestSupport
    .givenBuilder(builder)                           // Given: configure the builder
    .andExistingAudit(APPLIED(PreviousChange.class)) // Given: set up existing audit state
    .whenRun()                                       // When: trigger execution
    .thenExpectAuditFinalStateSequence(...)          // Then: define expectations
    .verify();                                       // Execute and validate
```

:::info Lazy execution
All methods are **intermediate operations** ‚Äî nothing executes until `verify()` is called. This allows you to build complex test scenarios before running them.
:::


## AuditEntryDefinition

Factory methods to define expected audit entries. Import statically for cleaner tests:

```java
import static io.flamingock.support.domain.AuditEntryDefinition.*;
```

### String-based (manual)

Specify the change ID directly:

```java
APPLIED("change-id")
FAILED("change-id")
ROLLED_BACK("change-id")
ROLLBACK_FAILED("change-id")
```

### Class-based (recommended)

Pass the change class to auto-extract metadata from annotations:

```java
APPLIED(MyChange.class)
FAILED(MyChange.class)
ROLLED_BACK(MyChange.class)
ROLLBACK_FAILED(MyChange.class)
```

This approach automatically extracts:
- `changeId` from `@Change` annotation
- `author` from `@Change` annotation
- `className` and `methodName`
- `targetSystemId` from `@TargetSystem` annotation
- `order` and `transactional`

### Fluent builder

Add or override specific fields:

```java
APPLIED(MyChange.class)
    .withAuthor("custom-author")
    .withTargetSystemId("mongodb-main")
    .withErrorTrace("Expected error message")
    .withTransactional(true)
    .withOrder("001")
```

### Selective field validation

The validator only checks fields that are **set** in the definition:

| Definition | Fields validated |
|------------|------------------|
| `APPLIED("my-change")` | `changeId`, `state` |
| `APPLIED(MyChange.class)` | `changeId`, `state`, `author`, `className`, `methodName`, `order`, `transactional`, `targetSystemId`, `recoveryStrategy` |
| `APPLIED("id").withAuthor("x")` | `changeId`, `state`, `author` |


## WhenStage

The `whenRun()` method marks the transition from setup to expectations:

```java
.givenBuilder(builder)
.andExistingAudit(APPLIED(PreviousChange.class))
.whenRun()  // Transition point
.thenExpect...
```


## Validators

### ExpectAuditFinalStateSequence

Validates the final audit state after execution:

```java
.whenRun()
.thenExpectAuditFinalStateSequence(
    APPLIED(Change1.class),
    APPLIED(Change2.class)
)
.verify();
```

**Behavior:**
- Validates only **final states**: `APPLIED`, `FAILED`, `ROLLED_BACK`, `ROLLBACK_FAILED`
- Filters out intermediate states like `STARTED`
- Requires **exact count match** ‚Äî if 3 changes executed, provide exactly 3 definitions
- Preserves **order** ‚Äî expected[0] must match actual[0], etc.

### ExpectException

Expects an exception to be thrown during execution:

```java
.whenRun()
.thenExpectException(PipelineExecutionException.class, ex -> {
    assertTrue(ex.getMessage().contains("Expected error"));
})
.verify();
```

If you don't need to validate the exception details, use the single-parameter overload:

```java
.thenExpectException(PipelineExecutionException.class)
```

## Final states

The audit log may contain multiple entries per change (e.g., `STARTED` then `APPLIED`). Validators filter out intermediate states and only consider final outcomes:

| State | Meaning |
|-------|---------|
| `APPLIED` | Change successfully applied |
| `FAILED` | Change execution failed |
| `ROLLED_BACK` | Change was rolled back after failure |
| `ROLLBACK_FAILED` | Rollback itself failed |


## Complete example

```java
import static io.flamingock.support.domain.AuditEntryDefinition.*;

@Test
void shouldHandlePartialFailureWithRollback() {
    FlamingockTestSupport
        .givenBuilder(builder)
        .andExistingAudit(
            APPLIED(InitialSetupChange.class)  // Already applied in previous run
        )
        .whenRun()
        .thenExpectException(PipelineExecutionException.class, ex -> {
            assertThat(ex.getMessage()).contains("Intentional failure");
        })
        .andExpectAuditFinalStateSequence(
            APPLIED(InitialSetupChange.class),  // Unchanged from precondition
            APPLIED(SuccessfulChange.class),    // New change succeeded
            FAILED(FailingChange.class),        // This change failed
            ROLLED_BACK(FailingChange.class)    // And was rolled back
        )
        .verify();
}
```

---

// File: testing/unit-testing

## Introduction

Unit tests focus on verifying the internal logic of a **single change unit**, without relying on any external system.  
They are fast, isolated, and ideal for validating:

- That the `@Apply` method performs the correct logic
- That the `@Rollback` method compensates properly on failure
- That injected dependencies are used as expected (using mocks or fakes)

Unit tests are most useful when your change unit contains business logic, computation, validation, or decisions.


## Example: Creating an S3 bucket

Suppose you have a change unit that creates an Amazon S3 bucket:

```java
@Change(id = "create-bucket", author = "dev-team")  // order extracted from filename
public class _0001__CreateS3BucketChange {

  @Apply
  public void apply(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }

  @Rollback
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }
}
```


## Writing a unit test

To unit test this class, we use JUnit and a mocking library (e.g., Mockito).  
We'll mock the `S3Client` and verify the correct calls were made.

```java
class _0001__CreateS3BucketChangeTest {

  private final S3Client s3Client = mock(S3Client.class);
  private final CreateS3BucketChange change = new CreateS3BucketChange();

  @Test
  void shouldCallCreateBucketOnExecution() {
    var s3Client = mock(S3Client.class);
    new _0001__CreateS3BucketChange().apply(s3Client);

    verify(s3Client).createBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }

  @Test
  void shouldCallDeleteBucketOnRollback() {
    var s3Client = mock(S3Client.class);
    new _0001__CreateS3BucketChange().rollback(s3Client);
    
    verify(s3Client).deleteBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }
}
```


## ‚úÖ Best practices

- Use mocks or fakes to isolate the dependencies used in your change unit
- Focus only on the logic inside the `@Apply` and `@Rollback` methods
- Keep assertions specific and minimal ‚Äî check that the right dependencies are called
- Avoid testing Flamingock itself (e.g., locking or audit behavior ‚Äî that‚Äôs handled in integration tests)
- Use descriptive test names like `shouldCallCreateBucketOnExecution()` for readability

---

// File: testing/integration-testing

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

Integration tests verify that Flamingock executes changes correctly against real systems. The `flamingock-test-support` module provides a BDD-style API for writing expressive, maintainable integration tests.

The recommended approach is to use your **production Flamingock builder** with containerized backends (via Testcontainers), ensuring your tests match real-world behavior.

## Setup

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>

```kotlin
testImplementation("io.flamingock:flamingock-test-support:$version")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-test-support</artifactId>
    <version>${flamingock.version}</version>
    <scope>test</scope>
</dependency>
```

  </TabItem>
</Tabs>

## FlamingockTestSupport

The entry point for standalone integration tests. Use `givenBuilder()` to pass your configured Flamingock builder:

```java
FlamingockTestSupport
    .givenBuilder(builder)      // Your production builder
    .andExistingAudit(...)      // Optional: set up existing audit state
    .whenRun()                  // Trigger execution
    .thenExpectAuditFinalStateSequence(...)  // Define expectations
    .verify();                  // Execute and validate
```

See [BDD test API](./flamingock-bdd-api.md) for details on `andExistingAudit()`, validators, and `AuditEntryDefinition`.


## Alternative: in-memory testing

For faster tests where audit store persistence doesn't matter, you can use the in-memory components:

### InMemoryTestBuilder

Creates a pre-configured builder with an in-memory audit store:

```java
import io.flamingock.support.InMemoryTestBuilder;

@Test
void fastTestWithInMemoryAudit() {
    var builder = InMemoryTestBuilder.create()
            .addTargetSystem(new NonTransactionalTargetSystem("kafka").addDependency(kafkaClient))
            .addStage(new Stage("kafka-changes").addCodePackage("com.myapp.changes.kafka"));

    FlamingockTestSupport
            .givenBuilder(builder)
            .whenRun()
            .thenExpectAuditFinalStateSequence(
                    APPLIED(CreateTopicChange.class)
            )
            .verify();
}
```

### InMemoryTestAuditStore

You can also use your production builder configured with all target systems, stages, and dependencies, and just override the audit store. This lets you test with your exact production configuration without needing a real audit store backend:

```java
import io.flamingock.support.InMemoryTestAuditStore;

@Test
void reuseProductionBuilderWithInMemoryAudit() {
    // Retrieve your production builder (already configured with target systems, stages, etc.)
    var builder = MyAppFlamingockConfig.createBuilder();

    // Override only the audit store for testing
    builder.setAuditStore(new InMemoryTestAuditStore());

    FlamingockTestSupport
            .givenBuilder(builder)
            .whenRun()
            .thenExpectAuditFinalStateSequence(
                    APPLIED(MyChange.class)
            )
            .verify();
}
```

:::tip When to use in-memory
Use in-memory components when:
- You want faster test execution
- The audit store behavior is not relevant to the test
- You're testing target system interactions only

Use Testcontainers when:
- You need to verify audit persistence behavior
- You want tests that match production exactly
- You're testing recovery or idempotency scenarios
:::

## Complete example with Testcontainers

This example tests a change that creates an S3 bucket, using MongoDB as the audit store:

```java
//other imports
import io.flamingock.core.Flamingock;
import io.flamingock.support.FlamingockTestSupport;
import io.flamingock.targetsystem.nontransactional.NonTransactionalTargetSystem;
import static io.flamingock.support.domain.AuditEntryDefinition.*;

@Testcontainers
class S3IntegrationTest {

    @Container
    static final MongoDBContainer mongoContainer = new MongoDBContainer("mongo:6.0");

    @Container
    static final LocalStackContainer localstack = new LocalStackContainer(
            DockerImageName.parse("localstack/localstack:latest"))
            .withServices(LocalStackContainer.Service.S3);

    private S3Client s3Client;
    private MongoClient mongoClient;

    @BeforeAll
    void setup() {
        // Configure S3 client (target system)
        s3Client = S3Client.builder()
                .endpointOverride(localstack.getEndpointOverride(LocalStackContainer.Service.S3))
                .credentialsProvider(StaticCredentialsProvider.create(
                        AwsBasicCredentials.create(
                                localstack.getAccessKey(),
                                localstack.getSecretKey())))
                .region(Region.US_EAST_1)
                .build();

        // Configure MongoDB client (audit store)
        mongoClient = MongoClients.create(mongoContainer.getReplicaSetUrl());
    }

    @Test
    void shouldExecuteS3BucketCreation() {
        // Configure target system with S3 client as dependency
        NonTransactionalTargetSystem s3TargetSystem = new NonTransactionalTargetSystem("aws-s3")
                .addDependency(s3Client);

        // Build Flamingock with production configuration
        var builder = Flamingock.builder()
                .setAuditStore(new MongoDBSyncAuditStore(mongoClient, "flamingock-test-db"))
                .addTargetSystem(s3TargetSystem)
                .addStage(new Stage("s3-changes").addCodePackage("com.myapp.changes.s3"));

        // Test using BDD API
        FlamingockTestSupport
                .givenBuilder(builder)
                .whenRun()
                .thenExpectAuditFinalStateSequence(
                        APPLIED(CreateS3BucketChange.class)
                )
                .verify();

        // Optionally verify the actual target system state
        boolean bucketExists = s3Client.listBuckets().buckets().stream()
                .anyMatch(b -> b.name().equals("flamingock-test-bucket"));
        assertTrue(bucketExists, "S3 bucket was not created");
    }

    @Test
    void shouldSkipAlreadyAppliedChanges() {
        var builder = Flamingock.builder()
                .setAuditStore(new MongoDBSyncAuditStore(mongoClient, "flamingock-test-db"))
                .addTargetSystem(new NonTransactionalTargetSystem("aws-s3").addDependency(s3Client))
                .addStage(new Stage("s3-changes").addCodePackage("com.myapp.changes.s3"));

        FlamingockTestSupport
                .givenBuilder(builder)
                .andExistingAudit(
                        APPLIED(CreateS3BucketChange.class)  // Simulate already applied
                )
                .whenRun()
                .thenExpectAuditFinalStateSequence(
                        APPLIED(CreateS3BucketChange.class)  // Should remain unchanged
                )
                .verify();
    }

    @Test
    void shouldHandleFailureWithRollback() {
        var builder = Flamingock.builder()
                .setAuditStore(new MongoDBSyncAuditStore(mongoClient, "flamingock-test-db"))
                .addTargetSystem(new NonTransactionalTargetSystem("aws-s3").addDependency(s3Client))
                .addStage(new Stage("failing-changes").addCodePackage("com.myapp.changes.failing"));

        FlamingockTestSupport
                .givenBuilder(builder)
                .whenRun()
                .thenExpectException(PipelineExecutionException.class, ex -> {
                    assertTrue(ex.getMessage().contains("Intentional failure"));
                })
                .andExpectAuditFinalStateSequence(
                        FAILED(FailingChange.class),
                        ROLLED_BACK(FailingChange.class)
                )
                .verify();
    }
}
```


## Best practices

- **Use your production builder** ‚Äî configure Flamingock the same way you do in production, but point to containerized backends
- **Use Testcontainers** ‚Äî provides realistic, isolated test environments for both target systems and audit stores
- **Test failure scenarios** ‚Äî verify that rollback behavior works correctly
- **Test idempotency** ‚Äî use `andExistingAudit()` to simulate re-runs and verify changes are skipped appropriately
- **Verify target system state** ‚Äî optionally check that the actual target system received the expected changes

---

// File: testing/springboot-integration-testing

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

For Spring Boot applications, Flamingock provides dedicated test support that integrates with the Spring test framework. The `flamingock-springboot-test-support` module uses the same BDD API as the standalone module, but with Spring-specific components for easier integration.

## Setup

Add the Spring Boot test support dependency:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>

```kotlin
testImplementation("io.flamingock:flamingock-test-support:$version")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-test-support</artifactId>
    <version>${flamingock.version}</version>
    <scope>test</scope>
</dependency>
```

  </TabItem>
</Tabs>

## @FlamingockSpringBootTest

This annotation is a composed annotation that includes `@SpringBootTest` with the property `flamingock.management-mode=DEFERRED` pre-configured:

```java
@FlamingockSpringBootTest
class MyFlamingockTest {
    // ...
}
```

This is equivalent to:

```java
@SpringBootTest(properties = "flamingock.management-mode=DEFERRED")
class MyFlamingockTest {
    // ...
}
```

The `DEFERRED` management mode means:
- Flamingock does **not** auto-run on application startup
- Tests control when execution happens via `verify()`
- The builder bean is available for injection, but the runner bean is **not** created

The annotation also exposes common `@SpringBootTest` attributes like `classes` and `webEnvironment`:

```java
@FlamingockSpringBootTest(
    classes = {MyApplication.class, TestConfig.class},
    webEnvironment = SpringBootTest.WebEnvironment.NONE
)
class MyFlamingockTest {
    // ...
}
```

## FlamingockSpringBootTestSupport

An autowirable bean that provides access to the BDD test flow:

```java
@Autowired
private FlamingockSpringBootTestSupport testSupport;
```

### givenBuilderFromContext()

This method retrieves the Flamingock builder that was auto-configured by Spring Boot based on your application properties:

```java
testSupport
    .givenBuilderFromContext()  // Gets the Spring-configured builder
    .andExistingAudit(...)      // Optional: set up existing audit state
    .whenRun()                  // Trigger execution
    .thenExpectAuditFinalStateSequence(...)  // Define expectations
    .verify();                  // Execute and validate
```

See [BDD test API](./flamingock-bdd-api.md) for details on `andExistingAudit()`, validators, and `AuditEntryDefinition`.

:::info Prototype scope
`FlamingockSpringBootTestSupport` has **prototype scope** ‚Äî a new instance is created for each injection. This is necessary because the underlying stages accumulate state and cannot be reused between tests.
:::


## Complete example

```java
//other imports
import io.flamingock.springboot.testsupport.FlamingockSpringBootTest;
import io.flamingock.springboot.testsupport.FlamingockSpringBootTestSupport;

import static io.flamingock.support.domain.AuditEntryDefinition.*;

@ExtendWith(SpringExtension.class)  // Required for Spring Boot 2.0.x. For Spring Boot > 2.1.x, can be omitted
@FlamingockSpringBootTest
class SpringBootFlamingockTest {

    @Autowired
    private FlamingockSpringBootTestSupport testSupport;

    @Test
    void shouldExecuteChanges() {
        testSupport
            .givenBuilderFromContext()
            .whenRun()
            .thenExpectAuditFinalStateSequence(
                APPLIED(CreateUsersTableChange.class),
                APPLIED(SeedInitialDataChange.class)
            )
            .verify();
    }

    @Test
    void shouldSkipAlreadyAppliedChanges() {
        testSupport
            .givenBuilderFromContext()
            .andExistingAudit(
                APPLIED(CreateUsersTableChange.class)  // Simulate already applied
            )
            .whenRun()
            .thenExpectAuditFinalStateSequence(
                APPLIED(CreateUsersTableChange.class)  // Should remain unchanged
            )
            .verify();
    }

    @Test
    void shouldHandleFailureWithRollback() {
        testSupport
            .givenBuilderFromContext()
            .whenRun()
            .thenExpectException(PipelineExecutionException.class, ex -> {
                assertTrue(ex.getMessage().contains("Expected error"));
            })
            .andExpectAuditFinalStateSequence(
                FAILED(FailingChange.class),
                ROLLED_BACK(FailingChange.class)
            )
            .verify();
    }
}
```

:::tip Spring Boot 2.1+
For Spring Boot 2.1.0 and later, `@ExtendWith(SpringExtension.class)` is not required ‚Äî it's automatically included.
:::


## Best practices

- **Use `@FlamingockSpringBootTest`** instead of `@SpringBootTest` to get automatic DEFERRED mode configuration
- **Use class-based `AuditEntryDefinition`** when possible ‚Äî it validates more fields and catches annotation misconfigurations
- **Keep test classes focused** ‚Äî each test class should test a specific aspect of your change execution
- **Use `andExistingAudit()`** to test idempotency and re-run scenarios
- **Test failure scenarios** ‚Äî verify that rollback behavior works correctly in your Spring context
- **Leverage Spring's test slicing** ‚Äî use `@FlamingockSpringBootTest` with specific configuration classes to load only what you need