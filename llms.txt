// File: cli/cli

# Flamingock CLI
*Enterprise-grade operational control for distributed system evolution*

Flamingock's Command-Line Interface (CLI) provides complete operational control over your system changes, enabling maintenance, troubleshooting, and governance tasks outside your application's normal startup cycle.

---

## Enterprise Operational Capabilities

### **Issue Resolution & Recovery**
The CLI is central to Flamingock's recovery strategy workflow, providing enterprise-grade operational excellence:

- **Issue Detection**: Identify failed or incomplete changes across your distributed systems
- **Guided Resolution**: Get specific guidance for resolving each type of failure
- **Audit Management**: Mark changes as resolved after manual verification or correction
- **Compliance Workflow**: Maintain complete audit trails during issue resolution

### **Operational Control**
- **Change Execution**: Run changes on-demand without full application startup
- **Dry-Run Analysis**: Preview pending changes and their execution order
- **Rollback Operations**: Safely revert changes using compensation logic
- **Lock Management**: Clear stale distributed locks from interrupted processes

### **Enterprise Integration**
- **CI/CD Pipeline Integration**: Embed Flamingock operations in deployment workflows
- **Automation Scripts**: Script common operational tasks and maintenance procedures
- **Compliance Reporting**: Generate audit reports and change history analysis

---

## Core CLI Operations

### **Issue Resolution Workflow**
The primary CLI workflow for operational excellence:

```bash
# 1. Discover issues requiring attention
flamingock issue list

# 2. Get the next issue to resolve (automatic prioritization)
flamingock issue get

# 3. Get specific issue with detailed guidance
flamingock issue get -c change-id --guidance

# 4. Resolve the issue after manual verification/correction
flamingock audit fix -c change-id --resolution APPLIED
flamingock audit fix -c change-id --resolution ROLLED_BACK
```

### **Change Execution & Management**
- **Execute Changes**: Run pending changes on-demand
- **Dry-Run Analysis**: Preview execution order and dependencies without applying changes
- **Rollback Operations**: Safely revert changes using `@RollbackExecution` methods
- **Audit Inspection**: Query execution history with filtering by author, date, status

### **Operational Maintenance** 
- **Lock Management**: View and clear distributed locks from interrupted processes
- **Consistency Checks**: Validate change definitions against audit log entries
- **Integrity Verification**: Ensure audit store consistency and detect anomalies

### **Enterprise Reporting**
- **Audit Trails**: Generate compliance reports and change history analysis
- **Issue Analytics**: Track resolution patterns and operational metrics
- **Change Impact**: Analyze cross-system dependencies and execution patterns

---

## Operational Workflows

### **Issue Resolution Workflow**
The most common CLI usage pattern for enterprise operations:

```bash
# Daily operational workflow
flamingock issue list
# Output: Shows all unresolved issues across your distributed systems

flamingock issue get  
# Output: Returns next priority issue with detailed context and guidance

# After manual investigation and correction:
flamingock audit fix -c user-data-update-v2 --resolution APPLIED
# Output: ✅ Issue resolved - change marked as successfully applied

# Alternative resolution:
flamingock audit fix -c problematic-change --resolution ROLLED_BACK
# Output: ✅ Issue resolved - change marked as rolled back
```

### **Change Management Operations**
```bash
# Execute pending changes on-demand
flamingock run --app-jar /path/to/app.jar --config application.yaml

# Preview what would execute (dry-run)
flamingock dry-run --config application.yaml --profile production

# Execute specific change by ID
flamingock run -c user-schema-update --app-jar /path/to/app.jar

# Rollback/undo specific change
flamingock undo -c user-schema-update --app-jar /path/to/app.jar
```

### **Audit and Compliance Operations**
```bash
# List all executed changes with filtering
flamingock audit list --author platform-team --from 2024-01-01

# Generate compliance report
flamingock audit report --format csv --output /reports/compliance-2024.csv

# Verify audit store integrity
flamingock audit verify --config application.yaml
```

### **Maintenance Operations**
```bash
# Clear stale distributed locks
flamingock lock clear --config application.yaml

# Check consistency between code and audit store
flamingock consistency-check --app-jar /path/to/app.jar --config application.yaml
```

---

## Enterprise Integration Patterns

### **CI/CD Pipeline Integration**
```yaml
# Example: Jenkins/GitHub Actions integration
deploy:
  steps:
    - name: Execute Flamingock Changes
      run: |
        flamingock run --app-jar dist/app.jar --config prod.yaml
        
    - name: Verify No Issues
      run: |
        flamingock issue list --fail-if-any
```

### **Operational Runbooks**
```bash
# Daily operations checklist
#!/bin/bash
echo "Checking for Flamingock issues..."
flamingock issue list

if [ $? -ne 0 ]; then
  echo "Issues detected - resolving..."
  while flamingock issue get > /dev/null; do
    echo "Resolve the displayed issue manually, then press Enter"
    read
    flamingock issue get -c $(flamingock issue get --format id) --resolution APPLIED
  done
fi
```

### **Emergency Response**
```bash
# Emergency rollback procedure
flamingock undo -c problematic-change --app-jar emergency-build.jar
flamingock audit fix -c problematic-change --resolution ROLLED_BACK
```

---

## Installation & Setup

### **Download CLI**
```bash
# Linux/macOS
curl -L https://releases.flamingock.io/cli/latest/flamingock-cli-linux -o flamingock
chmod +x flamingock

# Windows
# Download from: https://releases.flamingock.io/cli/latest/flamingock-cli-windows.exe
```

### **Configuration**
The CLI uses your existing Flamingock configuration files:
- `application.yaml` / `application.properties`
- `flamingock.yaml` / `flamingock.properties`

### **JAR Requirements**
Supply `--app-jar` only for commands that execute change logic:
- **Required**: `run`, `undo`, `rollback` commands
- **Not required**: `issue`, `audit`, `lock` commands

---

## Enterprise Support

The Flamingock CLI is production-ready and provides enterprise-grade operational capabilities for managing distributed system evolution at scale.

**Need help?** Contact support@flamingock.io for enterprise support and training.

---

// File: cloud-edition/cloud-edition

# Cloud Edition
:::warning[**Cloud Edition Coming Soon**]
The Cloud Edition is currently under development and not yet publicly available.

**If you'd like to participate in early testing or be notified when Cloud Edition is available, email us at [support@flamingock.io](mailto:support@flamingock.io)**

🔔 Stay tuned — it’s launching very soon!


:::
Flamingock Cloud Edition is a **fully managed SaaS platform** that brings advanced features, collaboration, and visibility to your change management workflow.

While the Community Edition offers core functionality with local storage and self-managed execution, the Cloud Edition extends that with powerful enterprise-grade capabilities.

## What the Cloud Edition will offer

Once released, the Cloud Edition will enable:

- **Centralized dashboards** to track and visualize changes across services and environments
- **Built-in user and team management** with Role-Based Access Control (RBAC)
- **Cross-environment visibility** for staging, production, and everything in between
- **Advanced template and extension support** for faster integration and reuse
- **Governance, auditability, and compliance** built into every change lifecycle
- **Multi-tenant and multi-service support**, ready for real-world deployment complexity

:::note
The Cloud Edition still relies on the Flamingock client library to run within your application.  
:::

## What's coming in this section

This section will guide you through:

- How to set up your **Cloud Edition environment**
- How to configure the Flamingock **client for Cloud Edition**
- How to use the **dashboard**, explore audits, and manage services
- Best practices for working with **multi-environment** and **multi-team** setups

---

// File: community-edition/Introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Community Edition
The **Community Edition** is Flamingock's free, open-source offering where you provide and manage your own database as the **audit store**—the dedicated location where Flamingock records which changes have been executed, when, and by whom.

Unlike the Cloud Edition (which uses Flamingock's managed backend as the audit store and provides advanced features), the Community Edition requires you to set up and maintain your own audit store. This makes it suitable for getting started with Flamingock, experimenting with change-as-code concepts, or for projects that need basic change management capabilities.

The **audit store** is separate from your **target systems** (the resources your ChangeUnits modify). For example, you might use MongoDB as your audit store while your ChangeUnits create S3 buckets, update Kafka topics, or modify database schemas. As the Cloud Edition, the Community edition provides transactional consistency guarantees to ensure changes and audit records remain synchronized.

To learn more about the distinction between audit stores and target systems, see [Audit Store vs. Target System](../overview/audit-store-vs-target-system.md).

The Community Edition supports several database technologies for your audit store: **MongoDB**, **DynamoDB**, **CosmosDB**, and **Couchbase**. Each provides the same core Flamingock functionality while premium features are available in the Cloud and Self-hosted editions.

## Available editions

Below is a summary of the available editions in the Flamingock Community Edition:

| Edition   | Database         | Supported Versions | Transactions | Locking Support | Notes                                                                                                                      |
|-----------|------------------|--------------------|--------------|-----------------|----------------------------------------------------------------------------------------------------------------------------|
| MongoDB   | MongoDB          | >=4.0              | ✅ Yes        | ✅ Yes           | Flamingock provides support for both low-level native drivers and high-level abstractions through Spring Data integration. |
| DynamoDB  | AWS DynamoDB     | >=2.25.29          | ✅ Yes        | ✅ Yes           |                                                                                                                            |
| CosmosDB  | Azure Cosmos DB  | Mongo API 3.6/4.0  | ✅ Yes        | ✅ Yes           |                                                                                                                            |
| Couchbase | Couchbase Server | >=3.6.0            | ❌ No         | ✅ Yes           |                                                                                                                            |

---
## Features
Community editions support the core Flamingock feature set, including:

- Ordered and versioned change execution
- Support for concurrent, distributed deployments
- Optional transactional execution (if supported by the MongoDB server)

:::info
It includes limited access to premium features, which are fully available in the Cloud and Self-Hosted editions.
:::

---

Each edition has its own documentation page with setup instructions, configuration parameters, and usage examples. Use the sidebar or links below to navigate to a specific edition.

---

// File: community-edition/ce-mongodb-java-driver

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

This section explains how to configure and use the **Flamingock Community Edition for MongoDB** in applications that interact directly with MongoDB using the **official Java driver** (`mongodb-driver-sync`).

This edition is designed for use cases where the application provides its own MongoDB connection via `MongoClient`, and Flamingock operates directly over that connection to manage changes. It does not rely on any external framework or abstraction layer.

Flamingock persists a minimal set of metadata in your MongoDB database to support its execution model:

- **Audit logs** – to track which changes have been executed  
- **Distributed locks** – to ensure safe and coordinated execution across multiple application instances

It is particularly suited to teams working in **framework-agnostic** or low-level environments, where integration is done directly at the driver level, and fine-grained control over MongoDB configuration is required.

Flamingock supports `mongodb-driver-sync` versions from **4.0.0 up to 5.x.x**.

---

## Supported versions

| Flamingock Module                 | MongoDB Driver                   | MongoDB Compatibility       |
|----------------------------------|----------------------------------|-----------------------------|
| `flamingock-ce-mongodb-sync`     | `org.mongodb:mongodb-driver-sync` (4.0.0 - 5.x.x) | MongoDB 3.x to 5.x           |

---

## Get started

To get started with the Flamingock Community Edition for MongoDB, follow these basic steps:

### 1. Add the required dependencies

You must include the **Flamingock MongoDB sync edition** and a compatible **MongoDB Java driver** in your project.

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
// MongoDB v4
implementation(platform("io.flamingock:flamingock-ce-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-mongodb-sync")
implementation("org.mongodb:mongodb-driver-sync:4.x.x")
```

</TabItem> <TabItem value="maven" label="Maven">

```xml
<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-ce-mongodb-sync</artifactId>
  <version>${flamingock.version}</version>
</dependency>
<dependency>
  <groupId>org.mongodb</groupId>
  <artifactId>mongodb-driver-sync</artifactId>
  <version>5.5.1</version> <!-- or any version between 4.0.0 and 5.x.x -->
</dependency>
```

</TabItem> </Tabs>

### 2. Enable Flamingock runner

At minimum, you must provide:
- A MongoDatabase (as a **dependency**)
- A MongoClient instance (as a **dependency**)

```java
MongoClient mongoClient = MongoClients.create("mongodb://localhost:27017");
MongoDatabase mongoDatabase = mongoClient.getDatabase("YOUR_DATABASE");

Runner runner = Flamingock.builder()
          .addDependency(mongoDatabase)
          .addDependency(mongoClient)
          // other optional configurations
          .build();
```
For production, we strongly recommend using the default MongoDB configuration values unless you fully understand the implications.
### 3. Execute Flamingock
Once the Flamingock runner is configured and built, you can trigger Flamingock’s execution:
```java
runner.execute();
```

---

## Configuration overview

Flamingock requires both dependencies and configuration properties, set via the builder.

### Dependencies

| Type                               | Required | Description                                   |
|------------------------------------|:--------:|-----------------------------------------------|
| `com.mongodb.client.MongoDatabase` |   Yes    | Required to connect to your MongoDB database. |
| `com.mongodb.client.MongoClient`   |   Yes    | Required for transactional support.           |

### Properties

These must be set using `.setProperty(...)`

| Property                         | Type                   | Default Value                  | Required | Description                                                                                                           |
|----------------------------------|------------------------|--------------------------------|:--------:|-----------------------------------------------------------------------------------------------------------------------|
| `mongodb.autoCreate`             | `boolean`              | `true`                         |    No    | Whether Flamingock should automatically create required collections and indexes.                                      |
| `mongodb.readConcern`            | `String`               | `"MAJORITY"`                   |    No    | Controls the isolation level for read operations.                                                                     |
| `mongodb. writeConcern.w`        | `String or int`        | `"MAJORITY"`                   |    No    | Write acknowledgment level. Specifies how many MongoDB nodes must confirm the write for it to succeed.                |
| `mongodb. writeConcern.journal`  | `boolean`              | `true`                         |    No    | Whether the write must be committed to the journal before acknowledgment.                                             |
| `mongodb. writeConcern.wTimeout` | `Duration`             | `Duration .ofSeconds(1)`       |    No    | Maximum time to wait for the write concern to be fulfilled.                                                           |
| `mongodb. readPreference`        | `ReadPreference Level` | `ReadPreferenceLevel .PRIMARY` |    No    | Defines which MongoDB node to read from.                                                                              |
| `mongodb. auditRepositoryName`   | `String`               | `"flamingockAuditLogs"`        |    No    | Name of the collection for storing the audit log. Overrides the default. Most users should keep the default value.    |
| `mongodb. lockRepositoryName`    | `String`               | `"flamingockLocks"`             |    No    | Name of the collection used for distributed locking. Overrides the default. Most users should keep the default value. |

:::warning
We strongly recommend keeping the default configuration values in production environments. They are optimized for **consistency, durability, and safety**, ensuring Flamingock’s audit and rollback guarantees.
:::
Overriding them is only appropriate in limited cases (e.g., testing or local development). If you choose to modify these settings, you assume full responsibility for maintaining the integrity and consistency of your system.

### Full configuration example
The following example shows how to configure Flamingock with both required and optional properties. It demonstrates how to override  index creation, and read/write behaviour. This level of configuration is useful when you need to customise Flamingock's behaviour to match the consistency and durability requirements of your deployment.

```java
MongoClient mongoClient = MongoClients.create("mongodb://localhost:27017");
MongoDatabase mongoDatabase = mongoClient.getDatabase("YOUR_DATABASE");

FlamingockBuilder builder = Flamingock.builder()
          .addDependency(mongoDatabase)
          .addDependency(mongoClient)
          .setProperty("mongodb.autoCreate", true)
          .setProperty("mongodb.readConcern", "MAJORITY")
          .setProperty("mongodb.writeConcern.w", "MAJORITY")
          .setProperty("mongodb.writeConcern.journal", true)
          .setProperty("mongodb.writeConcern.wTimeout", Duration.ofSeconds(1))
          .setProperty("mongodb.readPreference", ReadPreferenceLevel.PRIMARY");
```

---

## Transaction support

Flamingock supports transactions via `ClientSession` when used with a compatible MongoDB deployment. Simply include it as a parameter in your change unit:

```java
@Execution
public void execute(ClientSession session, MongoDatabase db) {
  db.getCollection("clients")
    .insertOne(session, new Document("name", "test"));
}
```
The session lifecycle is managed automatically by Flamingock.  If you omit the ClientSession parameter, the change will still execute, but it won't participate in a transaction.

> See the [Transactions](../flamingock-library-config/transactions.md) page for guidance on when and how to disable transactions (e.g., `transactional = false`).

---

## Examples

You can find practical examples in the official GitHub repository:  
👉 [Flamingock MongoDB example](https://github.com/flamingock/flamingock-examples/tree/master/mongodb)

---

## ✅ Best practices

- **Use Flamingock’s default consistency settings (`writeConcern`, `readConcern`, `readPreference`) in production**  
  These values guarantee strong consistency, durability, and fault tolerance. Overriding them is discouraged unless absolutely necessary.

- **Use the default collection names (`flamingockAuditLogs`, `flamingockLocks`)**  
  These help avoid collisions and simplify debugging.

- **Enable automatic index creation unless your environment prohibits it**  
  This ensures that Flamingock can enforce audit and locking guarantees. If disabled, manage indexes manually.

- **Ensure your MongoDB Java driver version is between 4.0.0 and 5.x.x**  
  This range is tested and supported by Flamingock.

---

// File: community-edition/ce-mongodb-springdata

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

This section explains how to use the **Flamingock Community Edition for MongoDB** in applications that rely on **Spring Data MongoDB**.

This edition is designed for teams that already use Spring Data to manage their database access and want to include Flamingock as part of their change tracking and execution model. It integrates with **Spring Boot** and **MongoTemplate**, handling auditing, distributed locking, and transactional coordination.

Flamingock persists a minimal set of metadata in your MongoDB database:

- **Audit logs** — track which changes have been applied
- **Distributed locks** — prevent concurrent modifications in distributed deployments

---

## Editions

Flamingock provides two editions for Spring Data.

### Why are there two MongoDB Spring Data Community-Edition artifacts?

The only difference is the Java version they target:

- `flamingock-ce-mongodb-springdata` — built for the current Spring Data MongoDB 4.x line, which itself requires JDK 17 or newer.
- `flamingock-ce-mongodb-springdata-v3-legacy` — kept for teams still on Spring Data 3.x (Spring Boot 2) who must stay on JDK 8 – 11.

Choose the artifact that matches the JDK level of your application today; switching later is as simple as changing the dependency.

| Edition Name                                  | Spring Data Version       |
|-----------------------------------------------|---------------------------|
| `flamingock-ce-mongodb-springdata-v3-legacy`  | [3.1.4, 4.0.0)            |
| `flamingock-ce-mongodb-springdata`            | [4.0.0, 5.0.0)            |


---

## Get Started

If you're using **Spring Boot**, the recommended approach is the **automatic setup** with `@EnableFlamingock`.

By annotating your main class with `@EnableFlamingock`, Flamingock will:

- Automatically detect and inject Spring components (`ApplicationContext`, `ApplicationEventPublisher`, etc.)
- Pick up configuration from the native Spring Boot config file
- Create and register a runner bean (either `ApplicationRunner` or `InitializingBean`)
- Process the setup configuration from the annotation

### 1. Add the required dependencies

<Tabs groupId="build_enable">
<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-ce-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-mongodb-springdata")
```

</TabItem>
<TabItem value="maven" label="Maven">

```xml
<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-ce-mongodb-springdata</artifactId>
  <version>${flamingock.version}</version>
</dependency>
<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>springboot-integration-v3</artifactId>
  <version>${flamingock.version}</version>
</dependency>
```

</TabItem>
</Tabs>

:::info Legacy Support
If your project uses **Spring Data 3.x** and **Spring Boot 2.x**, use the `flamingock-ce-mongodb-springdata-v3-legacy` edition instead.
:::

### 2. Configure setup and enable Flamingock runner
Choose one of the following options based on your preferred integration style:
- **Automatic setup** (recommended): Annotate your main class with `@EnableFlamingock`
- **Manual builder-based setup**: Use `@EnableFlamingock` with `setup = SetupType.BUILDER` and manually register the Flamingock runner bean

<Tabs groupId="automatic_builder">
<TabItem value="automatic" label="Automatic">

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@SpringBootApplication
public class MyApp {
  public static void main(String[] args) {
    SpringApplication.run(MyApp.class, args);
  }
}
```

</TabItem>
<TabItem value="builder" label="Builder">

```java
@EnableFlamingock(
    setup = SetupType.BUILDER,
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@Configuration
public class FlamingockConfig {

    @Bean
    public ApplicationRunner flamingockRunner(ApplicationContext context,
                                               ApplicationEventPublisher publisher,
                                               MongoTemplate template) {
        FlamingockBuilder builder = Flamingock.builder()
            .addDependency(context)
            .addDependency(publisher)
            .addDependency(template)
            .setProperty("mongodb.databaseName", "flamingock-db");
        return SpringbootUtil.toApplicationRunner(builder.build());
    }
}
```

</TabItem>
</Tabs>

---

## Configuration overview

Flamingock’s MongoDB Spring Data edition requires two types of inputs:
- **Dependencies**: These are required runtime components, such as `MongoTemplate`
- **Properties**: These configure Flamingock’s internal behavior and are typically declared in the Spring configuration file or via the builder.

### Dependencies

These must be available in the Spring context (when using automatic setup with `@Flamingock`) or registered via `.addDependency(...)` when using the builder setup.

| Type                                                    | Required | Notes                                                                                                              |
|---------------------------------------------------------|:--------:|--------------------------------------------------------------------------------------------------------------------|
| `org.springframework.data.mongodb.core.MongoTemplate`   |   Yes    | Must be declared as a Spring bean.                                                                                 |
| `org.springframework.context.ApplicationContext`        |   Yes    | Auto-injected by Spring Boot.                                                                                      |
| `org.springframework.context.ApplicationEventPublisher` |   Yes    | Auto-injected by Spring Boot.                                                                                      |

:::info
Spring Boot will typically auto-configure `MongoTemplate` for you.
:::

### Properties

| Property                         | Type                   | Default Value                  | Required | Description                                                                                     |
|----------------------------------|------------------------|--------------------------------|:--------:|-------------------------------------------------------------------------------------------------|
| `mongodb.autoCreate`             | `boolean`              | `true`                         |    No    | Whether Flamingock should automatically create required collections and indexes.                |
| `mongodb.readConcern`            | `String`               | `"MAJORITY"`                   |    No    | Controls the level of isolation for read operations.                                            |
| `mongodb. writeConcern.w`        | `String or int`        | `"MAJORITY"`                   |    No    | Write acknowledgment. Specifies how many MongoDB nodes must confirm the write.                  |
| `mongodb. writeConcern.journal`  | `boolean`              | `true`                         |    No    | Whether the write must be written to the on-disk journal before acknowledgment.                 |
| `mongodb. writeConcern.wTimeout` | `Duration`             | `Duration. ofSeconds(1)`       |    No    | Maximum time to wait for the write concern to be fulfilled.                                     |
| `mongodb. readPreference`        | `ReadPreference Level` | `ReadPreferenceLevel. PRIMARY` |    No    | Specifies which MongoDB node to read from.                                                      |
| `mongodb. auditRepositoryName`   | `String`               | `"flamingockAuditLogs"`        |    No    | Name of the collection used to store applied changes. Most users should keep the default value. |
| `mongodb. lockRepositoryName`    | `String`               | `"flamingockLocks"`             |    No    | Name of the collection used for distributed locking. Most users should keep the default value.  |                                                    |

:::warning
It's **strongly recommended keeping the default MongoDB configuration values provided by Flamingock** — especially in production environments. These defaults are carefully chosen to guarantee **maximum consistency, durability, and safety**, which are fundamental to Flamingock’s audit and rollback guarantees.
:::
Overriding them is only appropriate in limited cases (e.g., testing or local development). If you choose to modify these settings, you assume full responsibility for maintaining the integrity and consistency of your system.

---

### Full configuration example
The following example shows how to configure Flamingock with both required and optional properties. It demonstrates how to override index creation, and read/write behaviour. This level of configuration is useful when you need to customise Flamingock's behaviour to match the consistency and durability requirements of your deployment.

<Tabs groupId="automatic_builder">
<TabItem value="automatic" label="Automatic">

```yaml
flamingock:
  mongodb:
    databaseName: flamingock-db
    autoCreate: true
    readConcern: MAJORITY
    writeConcern:
      w: MAJORITY
      journal: true
      wTimeout: 1s
    readPreference: PRIMARY
```

</TabItem>
<TabItem value="builder" label="Builder">

```java
FlamingockBuilder builder = Flamingock.builder()
    .addDependency(applicationContext)
    .addDependency(applicationEventPublisher)
    .addDependency(mongoTemplate)
    .setProperty("mongodb.databaseName", "flamingock-db")
    .setProperty("mongodb.autoCreate", true)
    .setProperty("mongodb.readConcern", "MAJORITY")
    .setProperty("mongodb.writeConcern.w", "MAJORITY")
    .setProperty("mongodb.writeConcern.journal", true)
    .setProperty("mongodb.writeConcern.wTimeout", Duration.ofSeconds(1))
    .setProperty("mongodb.readPreference", ReadPreferenceLevel.PRIMARY);
```

</TabItem>
</Tabs>

---

## Transaction support

If your MongoDB deployment supports transactions, Flamingock can execute Spring Data operations within a transactional session — **as long as the underlying MongoDB driver and Spring Data version allow it**.

To benefit from transactional execution, simply declare your `@Execution` method to receive a `MongoTemplate`:

```java
@Execution
public void change(MongoTemplate mongoTemplate) {
    // This will run inside a transaction
}
```
Internally, Flamingock will manage the transaction lifecycle and ensure all operations performed through `MongoTemplate` are part of a single, atomic transaction. If anything fails, the changes and the audit log will be rolled back.

There is no need to manually manage a `ClientSession` when using Spring Data.
Flamingock integrates with Spring’s transaction management infrastructure to coordinate the session for you.

> See the [Transactions](../flamingock-library-config/transactions.md) page for general behavior and when to use `transactional = false`.
---

## Examples

You can find practical examples in the official GitHub repository:  
👉 [github.com/flamingock/flamingock-examples/mongodb](https://github.com/flamingock/flamingock-examples/mongodb)

---

## ✅ Best practices

- **Use Flamingock’s default consistency settings (`writeConcern`, `readConcern`, `readPreference`) in production**  
  These defaults are **strictly selected to guarantee strong consistency, durability, and fault-tolerance**, which are fundamental to Flamingock’s execution guarantees.  
  Overriding them is **strongly discouraged in production environments**, as it can compromise the integrity of audit logs and distributed coordination.

- **Use the default repository names (`flamingockAuditLogs`, `flamingockLocks`) unless you have a strong reason to change them**  
  The default names are chosen to avoid collisions and clearly identify Flamingock-managed collections. Overriding them is supported but rarely necessary.

- **Keep `indexCreation` enabled unless your deployment restricts index creation at runtime**  
  This setting ensures that Flamingock creates and maintains the required indexes to enforce audit integrity and locking guarantees.  
  Disable this only if your application does not have the necessary permissions to create indexes — and only if you manage the required indexes manually.
- **Always match the edition to your Spring Data / MongoDB driver version**

---

// File: community-edition/ce-dynamodb

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

This section explains how to configure and use the **Flamingock Community Edition for DynamoDB** in applications that interact with Amazon DynamoDB using the **official AWS SDK for Java**.

This edition is designed for use cases where the application provides its own DynamoDB client via `DynamoDbClient`, and Flamingock operates directly over that connection to manage changes. It does not require any framework-level integration.

Flamingock persists a minimal set of metadata in your DynamoDB tables to support its execution model:

- **Audit records** – to track which changes have been applied  
- **Distributed locks** – to coordinate executions across multiple instances

---

## Edition

This is a single edition for DynamoDB, provided as a standalone artifact.

| Edition Name             | Java Client                       | DynamoDB Compatibility |
|--------------------------|-----------------------------------|:----------------------:|
| `flamingock-ce-dynamodb` | `software.amazon.awssdk:dynamodb` |      >= `2.25.29`      |

---

## Get started

To get started with the Flamingock Community Edition for DynamoDB, follow these steps:

---

### 1. Add the required dependencies

You must include both the **Flamingock DynamoDB edition** and the **AWS SDK v2 for DynamoDB** in your project.

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-ce-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-dynamodb")
implementation("software.amazon.awssdk:dynamodb-enhanced:2.x.x")
implementation("software.amazon.awssdk:url-connection-client:2.x.x")
```

</TabItem> <TabItem value="maven" label="Maven">

```xml
<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-ce-dynamodb</artifactId>
  <version>${flamingock.version}</version>
</dependency>
<dependency>
  <groupId>software.amazon.awssdk</groupId>
  <artifactId>dynamodb-enhanced</artifactId>
  <version>2.x.x</version>
</dependency>
<dependency>
  <groupId>software.amazon.awssdk</groupId>
  <artifactId>url-connection-client</artifactId>
  <version>2.x.x</version>
</dependency>
```

</TabItem> </Tabs>

---

### 2. Enable Flamingock runner

At minimum, you must provide a `DynamoDbClient` instance (as a **dependency**)
```java 
DynamoDbClient dynamoClient = DynamoDbClient.builder()
        .region(Region.US_EAST_1)
        .build();

Runner runner = Flamingock.builder()
        .addDependency(dynamoClient)
        .build();

```

### 3. Execute Flamingock
Once the Flamingock runner is configured and built, you can trigger Flamingock’s execution:

```java
runner.execute();
```


---
## Configuration overview

Flamingock’s DynamoDB Community Edition requires both:
- A `DynamoDbClient` dependency
- A set of configuration properties

### Dependencies

These must be registered using `.addDependency(...)`

| Type                                                      | Required | Description                                    |
|-----------------------------------------------------------|:--------:|------------------------------------------------|
| `software.amazon.awssdk.services.dynamodb.DynamoDbClient` |   Yes    | Required to access and modify DynamoDB tables. |

### Properties

These must be set using `.setProperty(...)`

| Property                        | Type      | Required | Default Value         | Description                                                                  |
|---------------------------------|-----------|:--------:|-----------------------|------------------------------------------------------------------------------|
| `dynamodb. readCapacityUnits`   | `Long`    |    No    | `5L`                  | Read capacity units (for **PROVISIONED** billing mode only).                 |
| `dynamodb. writeCapacityUnits`  | `Long`    |    No    | `5L`                  | Write capacity units (for **PROVISIONED** billing mode only).                |
| `dynamodb.autoCreate`           | `Boolean` |    No    | `true`                | Automatically creates the required tables if they do not exist.              |
| `dynamodb. auditRepositoryName` | `String`  |    No    | `"flamingockAuditLogs"` | Table used to store audit records. Most users should keep the default name.  |
| `dynamodb. lockRepositoryName`  | `String`  |    No    | `"flamingockLocks"`      | Table used for distributed locking. Most users should keep the default name. |

:::warning
In production environments, we strongly recommend keeping the default configuration values unless you fully understand the implications.  
These defaults ensure consistency, safety, and compatibility with Flamingock’s locking and audit mechanisms.
:::




---


## Full configuration example
The following example shows how to configure Flamingock with both required and optional properties. 
It demonstrates how to override index creation, and read/write behaviour. 
This level of configuration is useful when you need to customise Flamingock's behaviour to match the consistency and 
durability requirements of your deployment.
```java
DynamoDbClient dynamoClient = DynamoDbClient.builder()
        .region(Region.US_EAST_1)
        .build();

FlamingockBuilder builder = Flamingock.builder()
        .addDependency(dynamoClient)
        .setProperty("autoCreate", true)
        .setProperty("readCapacityUnits", 5L)
        .setProperty("writeCapacityUnits", 5L);

```


---

## Transaction support


Flamingock supports transactional execution on DynamoDB using the enhanced client’s `TransactWriteItemsEnhancedRequest.Builder`.

If a change unit is marked as transactional (which is the default), Flamingock will:

- Create a **fresh transactional builder** (`TransactWriteItemsEnhancedRequest.Builder`) for that change
- Inject it into the `@Execution` method
- Execute the transaction **only if the change completes successfully** — including Flamingock’s internal audit write as part of the same transaction

This ensures **atomicity**: either all operations defined in the change unit — including the audit log — are applied together, or none are.

:::warning
If you mark a change unit as transactional but do **not** add any operations to the builder, Flamingock will still execute the transaction — but it will contain **only the audit log entry**.

Make sure your change unit populates the `TransactWriteItemsEnhancedRequest.Builder` appropriately.
:::

> See the [Transactions](../flamingock-library-config/transactions.md) page for general guidance and best practices around transactional vs non-transactional change units.



### Example

```java
@Execution
public void execute(@NonLockGuarded DynamoDbClient client,
                    TransactWriteItemsEnhancedRequest.Builder builder) {

  DynamoDbEnhancedClient enhancedClient = DynamoDbEnhancedClient.builder()
      .dynamoDbClient(client)
      .build();

  DynamoDbTable<UserEntity> table = enhancedClient.table("users", TableSchema.fromBean(UserEntity.class));

  builder.addPutItem(table, new UserEntity("Alice", "Anderson"));
  builder.addPutItem(table, new UserEntity("Bob", "Bennett"));
}

```

:::tip
You can add as many operations as needed to the builder: `putItem`, `updateItem`, `deleteItem`, etc.  
These operations will be executed **in a single atomic transaction**, together with Flamingock’s internal audit log update.
:::

You can find more practical examples in the official GitHub repository:  
👉 [Flamingock DynamoDB example](https://github.com/flamingock/flamingock-examples/tree/master/dynamodb)




---

---

// File: community-edition/ce-couchbase

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

This section explains how to configure and use the **Flamingock Community Edition for Couchbase** in applications that interact directly with Couchbase using the **official Couchbase Java SDK**.

This edition is intended for scenarios where your application provides a `Cluster` instance and its associated connection. Flamingock will work directly on this connection to track and execute database changes. It does not rely on any framework abstraction or integration.

Flamingock persists a small set of metadata documents in Couchbase to support its execution model:

- **Audit logs** – to track the execution history of each change
- **Distributed locks** – to coordinate execution across multiple application nodes

---

## Edition

This edition supports Couchbase through a dedicated artifact:

| Edition Name              | Java SDK                           | Couchbase Compatibility |
|---------------------------|------------------------------------|-------------------------|
| `flamingock-ce-couchbase` | `com.couchbase.client:java-client` (>= `3.6.0`) | >= `7.0`              |

---

## Get started

To get started with the Flamingock Community Edition for Couchbase, follow these steps:

### 1. Add the required dependencies

<Tabs groupId="build_tool">

<TabItem value="gradle" label="Gradle">

```kotlin
implementation(platform("io.flamingock:flamingock-ce-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-couchbase")
implementation("com.couchbase.client:java-client:3.x.x")
```

</TabItem> <TabItem value="maven" label="Maven">

```xml
<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-ce-couchbase</artifactId>
  <version>${flamingock.version}</version>
</dependency>
<dependency>
  <groupId>com.couchbase.client</groupId>
  <artifactId>java-client</artifactId>
  <version>3.x.x</version>
</dependency>
```

</TabItem> </Tabs>

---

### 2. Enable Flamingock runner

At minimum, you must provide:
- A Cluster instance (as a **dependency**)
- A Bucket instance (as a **dependency**)

```java
Cluster cluster = Cluster.connect("localhost", "username", "password");
Bucket bucket = cluster.bucket("YOUR_BUCKET");

Runner runner = Flamingock.builder()
    .addDependency(cluster)
    .addDependency(bucket)
    .build();
```

### 3. Execute Flamingock

Once the Flamingock runner is configured and built, you can trigger Flamingock’s execution:

```java
runner.execute();
```

---

## Configuration overview

Flamingock requires both dependencies and configuration properties, set via the builder.

### Dependencies

These must be registered using `.addDependency(...)`

| Type                                | Required | Description                                        |
|-------------------------------------|:--------:|----------------------------------------------------|
| `com.couchbase.client.java.Cluster` |   Yes    | Required to connect and execute against Couchbase cluster. |
| `com.couchbase.client.java.Bucket` |   Yes    | Required to connect and execute against Couchbase bucket. |

### Properties

These must be set using `.setProperty(...)`

| Property      | Type      | Required | Default Value | Description                                                              |
|---------------|-----------|:--------:|---------------|--------------------------------------------------------------------------|
| `couchbase.autoCreate`  | `boolean` |    No    | `true`        | Whether Flamingock should auto-create required collections and indexes.      |
| `couchbase.scopeName`  | `String` |    No    | `"_default"`        | Name of the Couchbase scope where the collections exist or will be created.       |
| `couchbase.auditRepositoryName`   | `String`               |   No    | `"flamingockAuditLogs"`        | Name of the collection for storing the audit log. Overrides the default. Most users should keep the default value.    |
| `couchbase.lockRepositoryName`    | `String`               |    No    | `"flamingockLocks"`             | Name of the collection used for distributed locking. Overrides the default. Most users should keep the default value. |

:::warning
In production environments, we strongly recommend keeping the default configuration values unless you fully understand the implications.  
These defaults ensure consistency, safety, and compatibility with Flamingock’s locking and audit mechanisms.
:::

---

## Full configuration example

The following example shows how to configure Flamingock with both required and optional properties. It demonstrates how to override `autoCreate`, which can be useful in lower environments or when managing schema manually.

```java
Cluster cluster = Cluster.connect("localhost", "username", "password");
Bucket bucket = cluster.bucket("YOUR_BUCKET");

FlamingockBuilder builder = Flamingock.builder()
    // mandatory dependency
    .addDependency(cluster)
    .addDependency(bucket)
    // optional configuration
    .setProperty("autoCreate", true)
    .setProperty("couchbase.scopeName", "YOUR_SCOPE");
```

> You can add additional dependencies and properties based on your custom setup (e.g., metrics, listeners, or cloud-specific settings).

---

## Transaction support

> ⚠️ Couchbase transactions are not currently managed automatically by Flamingock.  
> However, Flamingock guarantees safe, idempotent changes through internal locking, auditing, and execution guarantees.


You can find some practical examples in the official GitHub repository:  
👉 [Flamingock Couchbase example](https://github.com/flamingock/flamingock-examples/tree/master/couchbase)

---

// File: flamingock-library-config/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Flamingock library configuration

Flamingock provides flexible configuration options to support a variety of environments and workflows — from local setups to cloud-native distributed systems.

Configuration is divided into two distinct scopes:

- **Setup configuration** defines how Flamingock discovers and organizes change units. This is configured using the `@Flamingock` annotation.

- **Runtime configuration** includes optional parameters such as locking, metadata, author, etc., and can be provided via builder or (depending on the environment) a file.

---

## What you can configure

| Area                             | Description                                         |
|----------------------------------|-----------------------------------------------------|
| Setup & Stages                   | Organize changes into ordered stages                |
| ChangeUnits dependency injection | Dependency injection to changeUnits and environment |
| Platform component injection     | Platform-level components injection                 |
| Lock                             | Distributed locking and timing options              |
| Extra                            | Metadata, default author, enable/disable            |
| Cloud Edition                    | Cloud-specific setup: token, env, service           |
| Community Edition                | Driver-specific config for MongoDB, DynamoDB...     |


Each of these topics is explained in its own section.

---

## Configuration scopes and layers

Flamingock configuration is organized in two main scopes:
### Core configuration (shared by all editions)
Includes:
- Setup and stages definition
- Lock settings
- Metadata
- Default author
- Enable/disable flag
- Dependency injection via addDependency(...) for ChangeUnits and framework components
- etc.

### Edition-specific configuration
Based on the edition of Flamingock you import:
- **Cloud Edition**: Related settings to configure Flamingock Cloud.
- **Community Edition**: MongoDB, DynamoDB, Couchbase drivers and related settings.

Each of these can be used in two runtime environments:
- **Standalone** (default) — direct usage with builder (file-based config will be supported soon)
- **Spring Boot** — supports both setups; builder and integration with Spring’s lifecycle and properties (covered in a separate section)

---

## Setup and stages configuration

Stages are configured using the `@EnableFlamingock` annotation on any class in your application:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
public class FlamingockConfig {
    // Configuration class
}
```

Alternatively, you can use a dedicated file by specifying `pipelineFile` in the annotation:
```java
@EnableFlamingock(pipelineFile = "config/pipeline.yaml")
public class FlamingockConfig {}
```

The annotation should contain **only** the pipeline and stage definitions — no runtime configuration should be placed here.

:::info
- The `@EnableFlamingock` annotation is required for all runners and all environments.
- The pipeline definition should remain the same across environments.
- To conditionally include or exclude changes, Flamingock supports [profiles](../frameworks/springboot-integration/profiles.md).
- Profile support for stages is planned but not yet available.
:::

See the [Pipeline & stages](setup-and-stages.md) page for full details and examples.


---

## Applying runtime configuration
Runtime configuration (everything except the pipeline) can be applied in the following ways:

| Runtime environment |  Builder  |         File          |
|---------------------|:---------:|:---------------------:|
| Standalone          |     ✅     |    ❌ (coming soon)    |
| Springboot          |     ✅     |  ✅(framework native)  |

:::info
You can combine both approaches. If a property is defined in both, the builder value takes precedence.
:::

---

## Next steps

Explore the rest of the configuration section to tune Flamingock for your system:

### Shared configuration
- [Setup & Stages](./setup-and-stages.md)
- [Lock Configuration](./lock-configuration.md)
- [Extra Configuration](./extra-configuration.md)
- [Dependency wiring](./changeunit-dependency-injection.md)

### Pick an edition
- [☁️ Cloud Edition(Fully-featured)](../cloud-edition/cloud-edition.md)
- 🧪 Community Edition(feature-limited)

---

// File: flamingock-library-config/setup-and-stages

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Setup & Stages

The Flamingock **setup** organizes and executes your changes using **stages**. By default, you'll use a single stage that groups all your changes and executes them sequentially.

Changes within a stage are executed sequentially with order guaranteed. However, execution order between stages is not guaranteed - Flamingock handles system and legacy stages appropriately to ensure correctness.

---

## Setup configuration

Flamingock is configured using the `@EnableFlamingock` annotation on any class in your application. This annotation is required for all environments — whether you're using the standalone runner or Spring Boot integration.

The annotation is **only** used for defining the setup (stages and their sources). No runtime configuration should be placed here.

---

## Defining the setup

Here's the default single-stage configuration:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")
    }
)
public class FlamingockConfig {
    // Configuration class
}
```

Alternatively, using a YAML file:

```java
@EnableFlamingock(pipelineFile = "config/setup.yaml")
public class FlamingockConfig {}
```

Where `config/setup.yaml` contains:
```yaml
pipeline:
  stages:
    - name: main
      location: com.yourcompany.changes
```

:::info Advanced options:
- **Multiple stages**: For complex scenarios requiring independent change sets go to the [stage section below](#multiple-stages-advanced)
- **File-based configuration**: Use `pipelineFile` parameter for YAML configuration
- **Explicit naming**: Use `@Stage(name = "custom", location = "com.yourcompany.changes")`
:::

---

## Stage Types

Flamingock supports two families of stages:

### Standard Stages (default)
The default stage type where users place their changes. This is where you'll put all your application changes (Kafka, MongoDB, SQL, S3, etc.). Standard stages execute changeUnits in order and provide predictable, sequential execution.

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")  // Standard stage (default type)
    }
)
```

### Special Stages
For specific scenarios, Flamingock provides special stage types that require explicitly specifying a `type` parameter. Examples include `SYSTEM` and `LEGACY` stage types, which are used in particular contexts such as the Mongock upgrade process.

```java
@EnableFlamingock(
        stages = {
                @Stage(type = SYSTEM, location = "com.yourapp.system"),
                @Stage(type = LEGACY, location = "com.yourapp.mongock"),
                @Stage(location = "com.yourcompany.changes")  // Standard stage (default type)
        }
)
```

To see these special stages in action, refer to the [Upgrade from Mongock guide](../resources/upgrade-from-mongock) which demonstrates their practical usage.

---

## Multiple Stages (Advanced)

Most applications will naturally fit into a single stage, which keeps things simple and ensures a clear, deterministic execution order. 
However, if you prefer to organize changes into multiple stages—for example, to separate concerns or enforce isolated execution 
flows—Flamingock fully supports that as well. We’ll explain how it works and what to consider when taking that approach.

:::tip Default approach:
Most applications use a single stage: `@Stage(location = "com.yourcompany.changes")`. The name is auto-derived ("changes") and this is the recommended default setup.
:::


### When to Use Multiple Stages

Multiple stages are beneficial in specific scenarios:

#### Multi-module Applications
In monolithic applications with well-defined module boundaries, you can give each module its own stage for full autonomy:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "user-module", location = "com.yourapp.users.changes"),
        @Stage(name = "billing-module", location = "com.yourapp.billing.changes"),
        @Stage(name = "notification-module", location = "com.yourapp.notifications.changes")
    }
)
```

This approach allows:
- Independent change management across modules
- Different release cycles for different modules
- Clear separation of concerns and responsibilities

#### Functional Separation
You might want to separate changes by function or lifecycle:

```java
@EnableFlamingock(
    stages = {
        @Stage(name = "core-setup", location = "com.yourapp.setup.changes"),
        @Stage(name = "business-logic", location = "com.yourapp.business.changes"),
        @Stage(name = "monitoring-setup", location = "com.yourapp.monitoring.changes")
    }
)
```

### Restrictions and Important Considerations

#### No Execution Order Guarantees
**Critical limitation**: Flamingock does not guarantee execution order between stages. This means:

- Stage A might execute before, after, or concurrently with Stage B
- You cannot rely on changes in one stage being applied before another stage starts
- Each stage should be completely independent from others

#### Why This Matters
Consider this problematic scenario:
```java
// ❌ PROBLEMATIC: Relies on execution order
@EnableFlamingock(
    stages = {
        @Stage(name = "create-tables", location = "com.yourapp.schema"),     // Creates tables
        @Stage(name = "seed-data", location = "com.yourapp.data")           // Inserts data - DEPENDS on tables existing!
    }
)
```

The `seed-data` stage might execute before `create-tables`, causing failures.

#### Correct Approach
Instead, group dependent changes in the same stage:
```java
// ✅ CORRECT: All related changes in one stage
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")  // Contains both table creation AND data seeding in order
    }
)
```


### When NOT to Use Multiple Stages

Avoid multiple stages when:
- **You need execution order across different change types** - Use a single stage instead
- **Changes are logically related** - Keep them together for easier maintenance
- **Simple applications** - The complexity isn't worth the overhead
- **Cross-cutting concerns** - Changes that affect multiple areas should be in one stage

:::info Future Enhancements
Conditional stage execution based on dependencies or conditions is planned for future releases, which would allow:
- Running stages based on success/failure of other stages
- Defining explicit dependencies between stages
- More sophisticated stage orchestration patterns
:::
---

## Required fields

Each stage must define:
- `name` (optional): A unique identifier - if not provided, it will be auto-derived from the location
- `location`: The package or directory where changes are located

---

## Stage fields

| Field            | Required            | Description                                                                 |
|------------------|---------------------|-----------------------------------------------------------------------------|
| `location`       | :white_check_mark:  | Package or directory scanned for both code-based and template-based changes |
| `name`           | :x:                 | Unique identifier for the stage (auto-derived from location if not provided) |
| `description`    | :x:                 | Optional text explaining the stage's purpose                                |

---

## Where Changes are located

- **`location`** refers to a source package (e.g., `com.company.changes`), a relative(e.g., `my/path/changes`) or absolute(e.g., `/my/path/changes`) resources directory.  
  - Template-based and code-based changes can co-exist if location is a source package.
  - If location references a resource directory, it only accepts template-based changeUnits.
  - Default source roots: `src/main/java`, `src/main/kotlin`, `src/main/scala`, `src/main/groovy`. 
  - Source root can be customized via the `sources` compiler option.
  - Resource root can be customized via the `resources` compiler option.
  
- Customizing Source and Resource Root Paths
<Tabs groupId="gradle_maven">
    <TabItem value="gradle" label="Gradle" default>
```kotlin
tasks.withType<JavaCompile> {
    options.compilerArgs.addAll(listOf(
        "-Asources=custom/src",
        "-Aresources=custom/resources"
    ))
}
```
    </TabItem>
    <TabItem value="maven" label="Maven">
```xml
<build>
  <plugins>
    <plugin>
      <artifactId>maven-compiler-plugin</artifactId>
      <configuration>
        <compilerArgs>
          <arg>-Asources=custom/src</arg>
          <arg>-Aresources=custom/resources</arg>
        </compilerArgs>
      </configuration>
    </plugin>
  </plugins>
</build>
```
    </TabItem>
</Tabs>


---

## Example Pipeline

```yaml
pipeline:
  stages:
    - name: user-setup
      description: User-related DB setup
      location: com.yourapp.flamingock.users
```

Folder view:

```
src/
  main/
    java/
      com/
        yourapp/
          flamingock/
            users/
              _0001_CREATE_USERS_TABLE.java
              _0002_ADD_INDEX.yaml
```

---

## Best Practices

### Single Stage Execution (default and recommended)

In most applications, **changes that require a specific, deterministic execution order** should be grouped into a **single stage**. This ensures they are applied sequentially and in the exact order they are defined.

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourcompany.changes")
    }
)
```

Grouping related changes into a single stage:
- Ensures **predictable, sequential execution**
- Avoids ambiguity from cross-stage execution timing
- Eliminates the need to manage inter-stage dependencies
- Keeps setup simple and easier to maintain
- Supports mixing all types of changes (Kafka, MongoDB, SQL, S3, etc.) in a well-defined order

:::info Advanced scenarios
If your application benefits from separating changes—for example, by module or lifecycle—you can define [Multiple Stages (Advanced)](#multiple-stages-advanced). Just remember: deterministic execution is guaranteed only within a stage, not across them.
:::

### Placing your changes
We strongly recommend placing all your changes — code-based and template-based — in a **single location** defined by the `@Stage` annotation.
  - Ensures changes are always scanned, regardless of type
  - Avoids needing two locations if one template-based change requires fallback to code
  - Keeps everything in one logical location

---

### Naming Convention for Changes
To ensure clarity and enforce ordering, we recommend naming changes using the following format:

```
_0001_CREATE_CLIENTS_TABLE.java
_0002_ADD_INDEX_TO_EMAIL.yaml
```

- `XXXX`: The execution order of the change
- `CHANGE_NAME`: Descriptive name of what the change does

This convention:
- Works across both code-based and template-based formats
- Makes the execution order obvious at a glance
- Ensures consistent naming and project hygiene

:::tip
While Java typically avoids underscores and leading digits, change units are not traditional classes. Prioritizing **readability and order** is more valuable in this context.
:::



## 🛠 Troubleshooting

### My stage isn't picked up
- Make sure the stage has a `location` field defined
- Check the file path is correct and uses `/` as a separator, not `.` in YAML
- If using resource directory paths, make sure the file is placed under `src/main/resources/your-dir`

### No changes found in stage
- Verify that the class or YAML file is located in the expected package/directory
- For code-based changes, ensure the class is annotated with `@Change` or `@ChangeUnit`
- For template-based changes, check file names and YAML formatting

---

---

// File: flamingock-library-config/changeunits-deep-dive

# ChangeUnits Deep Dive

## 1. Introduction: Understanding ChangeUnits

A **ChangeUnit** is the atomic, versioned, self-contained unit of change in Flamingock.  
It encapsulates logic to evolve [**target systems**](../overview/audit-store-vs-target-system.md) safely, deterministically, and with complete auditability.

**Key characteristics:**
- Executed in sequence based on their `order`
- Recorded in the audit store to prevent duplicate execution
- Safe by default: if Flamingock is uncertain about a change's outcome, it stops and requires manual intervention
- Each ChangeUnit runs exactly once per system

---

## 2. Structure of a ChangeUnit

### Required Properties
- **`id`**: Unique identifier across all ChangeUnits in the application  
- **`order`**: Execution sequence (must use zero-padded format like `0001`, `0002`, `_0001_ChangeName`)  
- **`author`**: Who is responsible for this change  

### Optional Properties
- **`description`**: Brief explanation of what the change does  
- **`transactional`** (default `true`): Only relevant if the target system supports transactions. Has no effect on non-transactional systems like S3 or Kafka.  

### Required Annotations and Methods
- **`@TargetSystem`**: Specifies which system this change affects  
- **`@ChangeUnit`**: Marks the class as a ChangeUnit  
- **`@Execution`**: The method containing your change logic  
- **`@RollbackExecution`**: The method to undo the change (required for safety and governance)  

> **Note:** Rollback is important because in **non-transactional systems**, it's be used to revert changes if execution fails. In **all systems**, rollback is essential for undo operations (via CLI or UI).  

## 3. Types of ChangeUnits

### Code-based ChangeUnits
Written in Java (or Kotlin/Groovy) with annotations. Best for **specific jobs** or when you need a **flexibility window** that isn’t covered by an existing template.  

This approach gives you full programmatic control, making it the fallback option when no reusable template exists for your use case.

```java
@TargetSystem("user-database")
@ChangeUnit(id = "add-user-status", order = "0001", author = "dev-team")
public class _0001_AddUserStatus {
    
    @Execution
    public void execute(MongoDatabase database) {
        database.getCollection("users")
                .updateMany(new Document(), 
                            new Document("$set", new Document("status", "active")));
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        database.getCollection("users")
                .updateMany(new Document(), 
                            new Document("$unset", new Document("status", "")));
    }
}
```

### Template-based ChangeUnits
Template-based ChangeUnits use YAML or JSON definitions. They are especially useful for **repetitive or parameterized operations**, where the same logic can to be applied multiple times with different configurations.

- The execution logic is encapsulated in a **template** (provided by Flamingock, a contributor, or created by you).  
- Each ChangeUnit then supplies its own configuration to apply that logic consistently.  
- This approach ensures **immutability** (the YAML/JSON file itself represents the change) and makes it easier to **reuse proven patterns**.


```yaml
# File: _0002_add_status_column.yml
id: add_status_column
order: "0002"
author: "db-team"
description: "Add status column to orders table"
templateName: sql-template
templateConfiguration:
  executionSql: |
    ALTER TABLE orders ADD COLUMN status VARCHAR(20) DEFAULT 'pending';
  rollbackSql: |
    ALTER TABLE orders DROP COLUMN status;
```

Both types follow the same execution model and provide the same safety guarantees.

## 4. Naming & Discoverability

### Enforced Naming Convention
All ChangeUnit files (both code and templates) **must** follow this pattern:

- **Format**: `_XXXX_DescriptiveName`
- **Order**: Must be at least 4 digits, zero-padded (e.g., `0001`, `0002`, `0100`)
- **Examples**: 
  - Code: `_0001_CreateUserIndexes.java`
  - Template: `_0002_AddStatusColumn.yml`

### Why This Convention?
- **Visibility**: Easy to see execution order at a glance
- **Immutability**: Clear versioning prevents accidental modifications
- **Deterministic ordering**: Ensures consistent execution across environments

### File Locations
- **Code-based**: Place in packages scanned by Flamingock (default: `src/main/java`)
- **Template-based**: Place in `src/main/resources` or preferably alongside code-based ChangeUnits
- **Recommendation**: Keep all ChangeUnits (code and templates) in the same package/directory for better organization

## 5. Transactional Behavior

- **Transactional target systems** (e.g., MongoDB, PostgreSQL): operations run within a transaction **unless you explicitly set `transactional = false`**.  
- **Non-transactional target systems** (e.g., S3, Kafka): the `transactional` flag has no effect — operations are applied without transactional guarantees.

Some operations may require setting `transactional = false` even in databases:
- DDL operations (e.g., CREATE INDEX, ALTER TABLE)
- Large bulk operations that exceed transaction limits
- Cross-system changes spanning multiple databases

➡️ To understand how to define and configure **target systems**, see [Target System Configuration](./target-system-configuration.md)

## 6. Default Safety & Recovery

**Flamingock's core principle**: If a ChangeUnit execution result is uncertain, Flamingock stops and requires manual intervention. This prevents silent data corruption.

**What this means:**
- If a change fails, Flamingock halts execution
- The issue is recorded in the audit store
- Manual investigation and resolution is required via CLI (or Cloud UI in Cloud Edition)

➡️ **For advanced recovery strategies**, see [Recovery Strategies](../recovery-and-safety/recovery-strategies.md)

## 7. Best Practices

### Core Principles
- **Treat ChangeUnits as immutable**: Once deployed, never modify existing ChangeUnits. Create new ones for corrections.
- **Always provide @RollbackExecution**: Important for CLI undo operations and recovery scenarios.
- **Keep scope focused**: One ChangeUnit should address one logical change.

### Technical Guidelines
- **Make operations idempotent when possible**: Try to design changes that can be safely re-run.
- **Test both execution and rollback**: Include ChangeUnit testing in your CI/CD pipeline.
- **Follow naming conventions**: Use the `_XXXX_DescriptiveName` pattern consistently.

### Organizational Best Practices
- **Clear authorship**: Always specify the `author` for accountability.
- **Version control discipline**: Review ChangeUnits in pull requests like any critical code.
- **Document complex changes**: Use the `description` field to explain non-obvious logic.
- **Maintain change logs**: Keep a high-level record of what changes were made when.


---

**Next Steps:**
- Learn about [dependency injection](./changeunit-dependency-injection.md) in ChangeUnits
- Configure [target systems](./target-system-configuration.md) and [audit store](./audit-store-configuration.md)
- Explore [template-based ChangeUnits](../templates/templates-introduction.md) for declarative changes
- Understand [advanced recovery strategies](../recovery-and-safety/recovery-strategies.md) for production scenarios

---

// File: flamingock-library-config/changeunit-dependency-injection

Flamingock allows you to inject dependencies into your change units so they can use services, clients, or utilities during execution. This is especially useful for **standalone applications**, where no dependency injection framework (like Spring) is present.

If you're using **Spring Boot**, Flamingock can integrate with the Spring context to resolve dependencies automatically — Please refer to the [Spring Boot Integration](../frameworks/springboot-integration/introduction.md) section for details.

This injection is handled via the **Flamingock builder** — not via YAML — and supports:

| Feature                                                    |  Supported?  |
|------------------------------------------------------------|:------------:|
| Injection by type                                          |      ✅       |
| Injection by name                                          |      ✅       |
| Constructor-level injection                                |      ✅       |
| Method-level injection(`@Execution`, `@RollbackExecution`) |      ✅       |
| Nullable parameters                                        |      ✅       |
| Lock-safe proxying                                         |      ✅       |
| Opt-out via `@NonLockGuarded` for non-critical components  |      ✅       |

---

## Registering dependencies

Platform changeUnit dependencies  are registered using the method `addDependency(...)` :
```java
builder
  .addDependency(clientService);                         
```
Once registered, Flamingock can inject the requested dependency into your change unit methods or constructors.
```java
@Execution
public void execute(ClientService clientService) {
    // ChangeUnit's logic
}
```
### Using name and explicit type
Let’s say you have a base class `PaymentProcessor`, with two implementations: `StripePaymentProcessor` and `PaypalPaymentProcessor`.

Now imagine you're injecting both implementations like this:
```java
addDependency(new StripePaymentProcessor());
addDependency(new PaypalPaymentProcessor());
```

If a change unit method requests either `StripePaymentProcessor` or `PaypalPaymentProcessor` specifically, Flamingock will inject the correct one.

But if the method requests the general type `PaymentProcessor`, Flamingock cannot guarantee which of the two will be used.

To solve this, Flamingock provides two mechanisms:

#### Named dependency
You can register each implementation with a name:
```java
builder
  .addDependency("stripe", new StripePaymentProcessor())
  .addDependency("paypal", new PaypalPaymentProcessor());
```

Then use the `javax.inject.@Named` annotation in your method:
```java
@Execution
public void execute(@Named("stripe") PaymentProcessor processor) {
  processor.charge(...);
}
```

#### Explicit typing the dependency
Alternatively, you can register a specific instance for the general type, to ensure the right one is used by default:
```java
builder.addDependency(PaymentProcessor.class, new StripePaymentProcessor());
```
Now, any method requesting a `PaymentProcessor` will receive the Stripe implementation — unless a named one is requested instead.


---

## Injection targets

### Method injection

You can declare dependencies as parameters of `@Execution`, `@RollbackExecution`, etc.

```java
@Execution
public void run(ClientService clientService) {
  clientService.doSomething();
}
```

### Constructor injection

You can inject dependencies through constructors:

```java
public class CreateClientsTable {

  private final ClientService clientService;

  @FlamingockConstructor
  public CreateClientsTable(ClientService clientService) {
    this.clientService = clientService;
  }

  @Execution
  public void run() {
    clientService.doSomething();
  }
}
```

:::note 
If the class has only one constructor, the `@FlamingockConstructor` annotation is optional.
:::
---

## What happens if a dependency isn’t found?

By default, Flamingock will throw a clear exception if it cannot resolve a dependency.

You can override this by marking the parameter as `@Nullable`:

```java
import io.flamingock.core.api.annotations.Nullable;

@Execution
public void run(@Nullable OptionalLogger logger) {
  if (logger != null) {
    logger.log("Change started");
  }
}
```

---

## Skipping lock verification

By default, injected dependencies are **proxy-wrapped** to check that the lock is still held before each call — this prevents unsafe execution if the lock expires.

If you're injecting something that doesn't perform critical side effects (like a local list or utility), you can opt out of this check:

```java
@Execution
public void run(@NonLockGuarded SomeHelper helper) {
  helper.doLocalStuff();
}
```
---

## :white_check_mark: Best practices

- Only inject what you need for the current change unit
- Prefer constructor injection when dependencies are shared across multiple methods
- Use `@NonLockGuarded` only when you're certain no side effects are involved
- Document your dependencies to avoid confusion in large pipelines

---

// File: flamingock-library-config/platform-component-injection

# Platform component injection

In addition to injecting dependencies into your change units, Flamingock allows you to register **platform-level components**. These are required for Flamingock's internal operations, such as framework integration, driver setup, or future extensions like observability.

These components are not part of the change unit logic — they help Flamingock integrate and operate effectively within your application's runtime environment.

---

## When is this needed?

You may need to register platform components when:

- **Framework integration** is required  
  For example, when integrating with Spring Boot, you must provide `ApplicationContext` and `ApplicationEventPublisher` so Flamingock can hook into the application lifecycle.

- **Database access in Community Edition drivers**  
  Some drivers (like MongoDB or DynamoDB) require the database client to be explicitly provided.

- **System integrations like logging or observability** *(coming soon)*  
  Future features like OpenTelemetry or event monitoring may rely on externally provided components.

- **Custom modules or platform bridges**  
  If you're building your own Flamingock modules or integrating with external systems, you might need to provide platform services explicitly.

:::info
  Each integration (e.g., Spring Boot, database integration, etc.) will clearly document if and how platform components need to be registered. You don’t need to guess — check the relevant integration section for guidance.
:::

---

## Registering platform dependencies

Platform components are registered using the same `addDependency(...)` API used for change unit dependencies:

```java
builder
  .addDependency(applicationContext)
  .addDependency(applicationEventPublisher);
```
:::tip
If a component is relevant for both Flamingock internal operations and for injection into change units, you only need to register it once.
:::


---

## See also

- [ChangeUnit dependency injection](changeunit-dependency-injection.md) — for injecting services directly into change units  
- [Spring Boot integration](../frameworks/springboot-integration/introduction.md) — for automated platform wiring in Spring apps

---

// File: flamingock-library-config/target-system-configuration

# Target System Configuration

Target systems are the real-world systems where your business changes are applied.  
They can be databases, message queues, storage buckets, APIs, or any external service your application depends on.

A ChangeUnit always declares which target system it belongs to. This ensures Flamingock can:
- Track and audit changes per system
- Guarantee safe execution across heterogeneous environments
- Provide clear visibility (and, in the Cloud Edition, dashboards and filters per target system)

> **Conceptual Overview**: For architectural understanding of target systems vs audit store, see [Target Systems vs Audit Store](../overview/audit-store-vs-target-system.md).

---

## Why target systems matter

### Explicit ownership
Every change is tied to a named target system, avoiding ambiguity and enabling clear governance.

### Transactionality awareness
- **Transactional target systems** (like PostgreSQL, MySQL, or MongoDB with transactions) allow Flamingock to use native rollback and guarantees.
- **Non-transactional systems** (like S3, Kafka, or REST APIs) are still safe, but Flamingock relies on rollback methods you provide.

This distinction is built into the target system definition.

### Dependency injection
Each target system can expose the dependencies required by its ChangeUnits.  
For example:

- A MongoDB target system provides a `MongoDatabase`
- A Kafka target system provides a `KafkaTemplate`  
- A SQL target system provides a `Connection` or `DataSource`

:::info
ChangeUnits are not limited to target system dependencies. They can also request shared or application-level dependencies. Flamingock resolves them automatically, starting from the target system context and falling back to the general context.
:::

---

## Registering target systems

Target systems are registered at runtime with the Flamingock builder.  
You can define and register as many as you need:

```java
public class App {
  public static void main(String[] args) {
    SqlTargetSystem mysql = new SqlTargetSystem("mysql-inventory")
        .withDatasource(ds);

    DefaultTargetSystem s3 = new DefaultTargetSystem("aws-s3");

    DefaultTargetSystem kafka = new DefaultTargetSystem("kafka-stock");

    FlamingockStandalone
      .setAuditStore(new MongoSyncAuditStore(mongoClient, mongoDatabase))
      .addTargetSystems(mysql, s3, kafka)
      .build()
      .run();
  }
}
```

At startup, Flamingock automatically injects the right dependencies from the corresponding target system into each ChangeUnit.

### Spring Boot Integration
For Spring Boot applications, target systems are configured as beans:

```java
@Bean
public SqlTargetSystem sqlTargetSystem(DataSource dataSource) {
    return new SqlTargetSystem("mysql-inventory")
        .withDatasource(dataSource);
}

@Bean  
public DefaultTargetSystem kafkaTargetSystem() {
    return new DefaultTargetSystem("kafka-stock");
}
```

Spring Boot's auto-configuration will automatically register these target systems with Flamingock.

For more details, see [Spring Boot Integration](../frameworks/springboot-integration/introduction.md).


---

## Linking ChangeUnits to target systems

When defining ChangeUnits, you specify which target system they belong to using the `@TargetSystem` annotation:

```java
@TargetSystem("mysql-inventory")
@ChangeUnit(id = "add-category", order = "001", author = "team")
public class _001_AddCategory {
    //...
}
```


---

## Cloud Edition visibility

In the Cloud Edition, target systems become a first-class part of the dashboard:
- See all changes grouped by target system
- Filter execution history by system
- Track failures and recoveries per system

This makes it easier to govern and audit distributed environments at scale.

---

## Best practices

- Use descriptive names (`mysql-inventory`, `aws-s3`, `kafka-stock`)
- Be consistent across related ChangeUnits
- Avoid generic names like "database" or "api"
- Provide rollback logic for non-transactional systems
- Keep dependencies scoped to the system they belong to — don’t overload the general context when they are system-specific

---

**Key Takeaway**: Target systems provide the foundation for safe, auditable changes across your entire technology stack. By explicitly declaring and configuring them, you enable Flamingock to orchestrate complex distributed system evolution with confidence.

---

// File: flamingock-library-config/audit-store-configuration

# Audit Store Configuration
*How to configure Flamingock's audit store for tracking and compliance*

The audit store is Flamingock's dedicated system for tracking execution history, managing distributed locking, and ensuring compliance. This guide covers configuration options for different audit store implementations.

> **Conceptual Overview**: For architectural understanding of audit store vs target systems, see [Target Systems vs Audit Store Architecture](../overview/audit-store-vs-target-system.md).

---

## Audit Store Fundamentals

### What the Audit Store Tracks
- **Execution History**: Which ChangeUnits ran, when, and with what outcome
- **Distributed Locking**: Prevents concurrent executions across multiple instances
- **Issue Tracking**: Failed or uncertain executions requiring resolution
- **Metadata**: Authors, environments, execution context

### Audit Store vs Target Systems
- **Audit Store**: Managed automatically by Flamingock framework (never modified by your code)
- **Target Systems**: Modified by your business logic in `@Execution` methods
- **Independence**: Audit integrity maintained even if target systems fail

---

## Community Edition Audit Store Options

### MongoDB Audit Store

#### Basic Configuration
```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock(MongoTemplate mongoTemplate) {
        return Flamingock.builder()
            .setConnectionRepository(new MongoConnectionRepository(mongoTemplate))
            .addMigrationClass(MyChangeUnits.class)
            .build();
    }
}
```

#### Advanced MongoDB Configuration
```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock() {
        // Create dedicated audit store connection
        MongoClientSettings settings = MongoClientSettings.builder()
            .applyConnectionString(ConnectionString.create("mongodb://audit-db:27017/flamingock-audit"))
            .writeConcern(WriteConcern.MAJORITY)  // Ensure audit durability
            .readConcern(ReadConcern.MAJORITY)    // Consistent audit reads
            .build();
        
        MongoClient auditClient = MongoClients.create(settings);
        MongoTemplate auditTemplate = new MongoTemplate(auditClient, "flamingock-audit");
        
        return Flamingock.builder()
            .setConnectionRepository(new MongoConnectionRepository(auditTemplate))
            .addMigrationClass(MyChangeUnits.class)
            .build();
    }
}
```

#### MongoDB Collections Structure
Flamingock automatically creates these collections in your audit store:

- **`changeLog`**: Execution history and state tracking
- **`locks`**: Distributed locking for concurrent safety
- **`issues`**: Failed executions requiring resolution

### DynamoDB Audit Store

#### Basic DynamoDB Configuration
```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock(DynamoDbClient dynamoDbClient) {
        DynamoConnectionRepository connectionRepository = 
            new DynamoConnectionRepository(dynamoDbClient)
                .withTablePrefix("flamingock-")  // Optional: prefix for table names
                .withRegion(Region.US_EAST_1);   // Optional: specify region
        
        return Flamingock.builder()
            .setConnectionRepository(connectionRepository)
            .addMigrationClass(MyChangeUnits.class)
            .build();
    }
}
```

#### DynamoDB Tables Structure
Flamingock automatically creates these tables:

- **`flamingock-changeLog`**: Execution history
- **`flamingock-locks`**: Distributed locking
- **`flamingock-issues`**: Issue tracking

### Couchbase Audit Store

#### Basic Couchbase Configuration
```java
@Configuration  
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock() {
        Cluster cluster = Cluster.connect("localhost", "username", "password");
        Bucket bucket = cluster.bucket("flamingock-audit");
        
        CouchbaseConnectionRepository connectionRepository = 
            new CouchbaseConnectionRepository(bucket)
                .withScope("audit-scope")        // Optional: custom scope
                .withCollection("change-log");   // Optional: custom collection
        
        return Flamingock.builder()
            .setConnectionRepository(connectionRepository)
            .addMigrationClass(MyChangeUnits.class)
            .build();
    }
}
```

---

## Audit Store Configuration Options

### Write Concern and Durability
Critical for audit integrity - ensure changes are durably persisted:

```java
// MongoDB with strong consistency
MongoClientSettings settings = MongoClientSettings.builder()
    .writeConcern(WriteConcern.MAJORITY)     // Wait for majority acknowledgment
    .readConcern(ReadConcern.MAJORITY)       // Read from majority
    .readPreference(ReadPreference.primary()) // Always read from primary
    .build();

// DynamoDB with consistent reads
DynamoConnectionRepository connectionRepository = 
    new DynamoConnectionRepository(dynamoDbClient)
        .withConsistentRead(true)            // Enable strong consistency
        .withWriteCapacity(25)               // Provision appropriate capacity
        .withReadCapacity(25);
```

### Collection/Table Naming
Customize audit store object names:

```java
// MongoDB custom collection names
MongoConnectionRepository connectionRepository = 
    new MongoConnectionRepository(mongoTemplate)
        .withChangeLogCollectionName("execution_history")
        .withLockCollectionName("distributed_locks")
        .withIssuesCollectionName("failed_executions");

// DynamoDB custom table names  
DynamoConnectionRepository connectionRepository = 
    new DynamoConnectionRepository(dynamoDbClient)
        .withChangeLogTableName("ExecutionHistory")
        .withLockTableName("DistributedLocks")
        .withIssuesTableName("FailedExecutions");
```

### Index Optimization
Flamingock automatically creates necessary indexes, but you can optimize:

```javascript
// MongoDB: Additional indexes for query performance
db.changeLog.createIndex({ "targetSystem": 1, "executionDate": -1 })
db.changeLog.createIndex({ "author": 1, "status": 1 })
db.issues.createIndex({ "createdAt": -1, "status": 1 })
```

---

## Separation Patterns

### Pattern 1: Same Database as Target System
Simplest setup - audit and business data in same database:

```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock(@Qualifier("businessDatabase") MongoTemplate mongoTemplate) {
        // Both audit store and target system use same database
        // Benefits: Single database to manage, reduced infrastructure complexity
        // Important: Even with same database, audit and changes use separate transactions
        // Trade-offs: Mixed concerns, shared resource limits
        return Flamingock.builder()
            .setConnectionRepository(new MongoConnectionRepository(mongoTemplate))
            .addMigrationClass(BusinessChangeUnits.class)
            .build();
    }
}
```

### Pattern 2: Dedicated Audit Database
Best practice - separate audit store from business systems:

```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock(@Qualifier("auditDatabase") MongoTemplate auditTemplate,
                                @Qualifier("businessDatabase") MongoTemplate businessTemplate) {
        // Audit store: dedicated database for compliance and tracking
        // Target systems: business databases
        // Benefits: Clear separation, independent scaling, compliance isolation
        return Flamingock.builder()
            .setConnectionRepository(new MongoConnectionRepository(auditTemplate))
            .addDependency("businessDatabase", businessTemplate)
            .addMigrationClass(BusinessChangeUnits.class)
            .build();
    }
}
```

### Pattern 3: Cloud Edition
Managed audit store with enhanced capabilities:

```java
@Configuration
public class FlamingockConfig {
    
    @Bean
    public Flamingock flamingock(@Value("${flamingock.cloud.api-key}") String apiKey) {
        // Audit store: Fully managed Flamingock Cloud backend
        // Target systems: Your business systems
        // Benefits: Zero ops, advanced features, enterprise governance
        return Flamingock.builder()
            .setConnectionRepository(new CloudConnectionRepository(apiKey))
            .addMigrationClass(BusinessChangeUnits.class)
            .build();
    }
}
```

---

## Security and Access Control

### Audit Store Security
Protect audit integrity with proper access controls:

```java
// MongoDB with authentication and SSL
MongoClientSettings settings = MongoClientSettings.builder()
    .applyConnectionString(ConnectionString.create(
        "mongodb://audit-user:secure-password@audit-cluster:27017/flamingock-audit" +
        "?authSource=admin&ssl=true&replicaSet=audit-rs"))
    .sslSettings(SslSettings.builder()
        .enabled(true)
        .invalidHostNameAllowed(false)
        .build())
    .build();
```

### Role-Based Access
Define appropriate database roles:

```javascript
// MongoDB: Audit store user with minimal required permissions
db.createUser({
    user: "flamingock-audit",
    pwd: "secure-password",
    roles: [
        {
            role: "readWrite",
            db: "flamingock-audit"
        },
        {
            role: "dbAdmin",  // For index creation
            db: "flamingock-audit"
        }
    ]
});
```

### Network Security
Isolate audit store network access:

```yaml
# Docker Compose example with network isolation
services:
  audit-database:
    image: mongo:7
    networks:
      - audit-network
    environment:
      MONGO_INITDB_ROOT_USERNAME: audit-admin
      MONGO_INITDB_ROOT_PASSWORD: secure-password
  
  app:
    networks:
      - audit-network
      - business-network
```

---

## Performance and Scaling

### Connection Pooling
Optimize audit store connections:

```java
// MongoDB connection pool settings
MongoClientSettings settings = MongoClientSettings.builder()
    .applyToConnectionPoolSettings(builder ->
        builder.maxSize(20)                    // Max connections
               .minSize(5)                     // Min connections
               .maxWaitTime(10, TimeUnit.SECONDS)
               .maxConnectionIdleTime(30, TimeUnit.SECONDS))
    .build();
```

### Write Performance Optimization
Balance consistency with performance:

```java
// For high-throughput scenarios
MongoConnectionRepository connectionRepository = 
    new MongoConnectionRepository(mongoTemplate)
        .withBatchSize(100)              // Batch audit writes
        .withAsyncWrites(true)           // Non-blocking audit writes
        .withRetryPolicy(RetryPolicy.exponentialBackoff());
```

### Monitoring and Metrics
Track audit store health:

```java
@Component
public class AuditStoreMonitoring {
    
    @EventListener
    public void onAuditWrite(AuditWriteEvent event) {
        // Track audit store performance metrics
        meterRegistry.timer("flamingock.audit.write.duration")
                    .record(event.getDuration());
        
        if (event.hasFailed()) {
            meterRegistry.counter("flamingock.audit.write.failures")
                        .increment();
        }
    }
}
```

---

## Backup and Recovery

### Audit Store Backup Strategy
Protect your compliance and execution history:

```bash
#!/bin/bash
# MongoDB audit store backup script
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
mongodump --host audit-cluster:27017 \
         --db flamingock-audit \
         --out /backups/flamingock-audit-$TIMESTAMP \
         --gzip

# Retention: Keep 30 days of backups
find /backups -name "flamingock-audit-*" -mtime +30 -exec rm -rf {} \;
```

### Disaster Recovery
Restore audit store from backup:

```bash
#!/bin/bash
# Restore audit store from backup
BACKUP_DATE="20241201_143000"
mongorestore --host audit-cluster:27017 \
            --db flamingock-audit \
            --gzip \
            /backups/flamingock-audit-$BACKUP_DATE/flamingock-audit

# Verify restoration
mongo audit-cluster:27017/flamingock-audit --eval "db.changeLog.count()"
```

---

## Troubleshooting Audit Store Issues

### Common Configuration Problems

#### Connection Issues
```
Error: Unable to connect to audit store
Solution: Verify connection string, network access, and authentication credentials
```

#### Permission Errors
```
Error: Insufficient permissions to create collections/tables
Solution: Grant necessary database permissions to Flamingock user
```

#### Index Creation Failures
```
Error: Failed to create audit store indexes
Solution: Ensure dbAdmin privileges or create indexes manually
```

### Diagnostic Commands
```bash
# Verify audit store connectivity
flamingock test-connection --audit-store

# Check audit store schema
flamingock audit verify-schema

# Monitor audit store performance
flamingock audit stats --since "1 hour ago"

# Repair corrupted audit entries (use with caution)
flamingock audit repair --dry-run
```

### Health Checks
Implement audit store health monitoring:

```java
@Component
public class AuditStoreHealthIndicator implements HealthIndicator {
    
    @Override
    public Health health() {
        try {
            // Test audit store connectivity
            auditStore.testConnection();
            
            // Verify recent write capability
            auditStore.writeHealthCheck();
            
            return Health.up()
                        .withDetail("audit-store", "Available")
                        .build();
        } catch (Exception e) {
            return Health.down()
                        .withDetail("audit-store", "Unavailable")
                        .withException(e)
                        .build();
        }
    }
}
```

---

**Key Takeaway**: Proper audit store configuration is critical for Flamingock's safety guarantees, compliance capabilities, and operational reliability. Choose the configuration pattern that best matches your architecture and operational requirements.

---

// File: flamingock-library-config/lock-configuration

# Distributed lock configuration

Flamingock uses a distributed lock to ensure that changes are only applied **once and only once**, even when multiple instances of your application start simultaneously in a distributed system.

This mechanism is **mandatory** and applies in both Cloud and Community editions:

- In **Cloud Edition**, the lock is managed by Flamingock’s backend
- In **Community Edition**, the lock is stored in your configured database (e.g., MongoDB, DynamoDB)

---

## Configurable properties

| Property                             | Default          | Description                                                                         |
|--------------------------------------|------------------|-------------------------------------------------------------------------------------|
| `lockAcquiredForMillis`              | `60000` (1 min)  | Time the lock remains valid once acquired. Automatically released if not refreshed. |
| `lockQuitTryingAfterMillis`          | `180000` (3 min) | How long to retry acquiring the lock if another instance holds it.                  |
| `lockTryFrequencyMillis`             | `1000` (1 sec)   | Interval between attempts while waiting for the lock.                               |
| `throwExceptionIfCannotObtainLock`   | `true`           | Whether Flamingock should fail if the lock can't be acquired.                       |
| `enableRefreshDaemon`                | `true`           | Whether to run a background thread that periodically extends the lock.              |

---

## Why locking matters

In distributed systems, multiple app instances may start simultaneously — but only **one** should apply pending changes. Flamingock uses locking to:

- Prevent race conditions
- Ensure consistent and safe state transitions
- Guarantee single execution of each change

:::info
If no pending changes exist, the lock is not acquired and startup proceeds normally.
:::
---

## Refresh Daemon (safety net)

The **refresh daemon** is a background thread that extends the lock before it expires.  
It’s critical for **long-running changes** that might exceed the lock duration.

Without the daemon:

- A long-running change (e.g., 90s) could outlive a default lock (e.g., 60s)
- Another instance might acquire the lock prematurely, causing conflict

:::note
By default, Flamingock uses proxy-based injection guards. Before executing any injected dependency, Flamingock verifies that the lock is still valid.
:::

If you're injecting **non-critical components** (e.g., a local list or stateless helper), you can annotate them with `@NonLockGuarded` to avoid the proxy overhead.

---

## Configuration Examples

### Builder
```java
FlamingockStandalone
  .setLockAcquiredForMillis(120000)
  .setLockQuitTryingAfterMillis(300000)
  .setLockTryFrequencyMillis(2000)
  .setThrowExceptionIfCannotObtainLock(true)
  .setEnableRefreshDaemon(true)
  ...
```

---

## When to tweak Lock settings

Most projects can use the default configuration. You may need to adjust values if:

- You expect **long-running changes** (increase `lockAcquiredForMillis`)
- You run **many app instances** and want to reduce startup wait (decrease `lockTryFrequencyMillis`)
- You want Flamingock to **fail fast** if it can't acquire a lock (keep `throwExceptionIfCannotObtainLock` as `true`)

---

## ✅ Best Practices

- Keep the refresh daemon **enabled**, especially for distributed or slow-processing environments
- Avoid setting `lockAcquiredForMillis` too short if any changes might run longer
- Use `@NonLockGuarded` sparingly — only when you're sure no side-effects will occur

[//]: # (TODO: Add "🛠 Troubleshooting" section)

---

// File: flamingock-library-config/events

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Events

This guide provides a comprehensive explanation of how Flamingock events function.

## Introduction

Flamingock utilizes events to notify the main application about the current state of the Flamingock process, as well as the eventual outcome of its execution.

The event-handling approach differs significantly depending on the type of runner being used:

- For Spring-based applications, Flamingock leverages the ```ApplicationEventPublisher```, which is provided during the build process.
- For standalone applications, Flamingock requires an explicit event handler to be defined at build time.

Flamingock offers event handling capabilities for both Pipelines and Stages.

## Type of events

Flamingock emits three types of events:

- **Start Event**: Triggered just before the migration process begins, following successful validation.
- **Success Event**: Emitted upon successful completion of the migration. This indicates that no unhandled exceptions occurred, or that any errors were either properly handled or associated changeLogs were marked with 'Fail' as false.
- **Failure Event**: Emitted when a change log fails and the failure is not handled, as described above.

:::warning
The Success and Failure events are mutually exclusive, only one of them will be raised for a given migration execution.
:::

## Get started

Each runner's documentation page provides the necessary information for using events in accordance with that runner's specific implementation.

## Standalone basic example

In the Flamingock builder, you must configure the events you intend to use and implement the corresponding listeners.

### Builder

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
      FlamingockStandalone.local()
          .setPipelineStartedListener(new PipelineStartedListener())
          .setPipelineCompletedListener(new PipelineCompletedListener())
          .setPipelineFailedListener(new PipelineFailedListener())
          .setStageStartedListener(new StageStartedListener())
          .setStageCompletedListener(new StageCompletedListener())
          .setStageFailedListener(new StageFailedListener())
          .build()
          .run();
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
      FlamingockStandalone.local()
          .setPipelineStartedListener(PipelineStartedListener())
          .setPipelineCompletedListener(PipelineCompletedListener())
          .setPipelineFailedListener(PipelineFailedListener())
          .setStageStartedListener(StageStartedListener())
          .setStageCompletedListener(StageCompletedListener())
          .setStageFailedListener(StageFailedListener())
          .build()
          .run()
  ```
  </TabItem>
</Tabs>
  
### Listener

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
  ```java
    public class StageCompletedListener implements Consumer<IStageCompletedEvent> {

    public static int executed = 0;
    @Override
    public void accept(IStageCompletedEvent iStageCompletedEvent) {
        executed++;
    }
    }
  ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin">
  ```kotlin
class StageCompletedListener : (IStageCompletedEvent) -> Unit {

    companion object {
        var executed = 0
    }

    override fun invoke(iStageCompletedEvent: IStageCompletedEvent) {
        executed++
    }
}
  ```
  </TabItem>
</Tabs>

## Spring-based basic example

### Listeners

<Tabs groupId="languages">
  <TabItem value="java" label="Java" default>
    ```java
      @Bean
      public PipelineStartedListener startFlamingockListener() {
          return new PipelineStartedListener();
      }

      @Bean
      public PipelineCompletedListener successFlamingockListener() {
          return new PipelineCompletedListener();
      }

      @Bean
      public PipelineFailedListener sailedFlamingockListener() {
          return new PipelineFailedListener();
      }

      @Bean
      public StageStartedListener stageStartedListener() {return new StageStartedListener();}

      @Bean
      public StageCompletedListener stageCompletedListener() {return new StageCompletedListener();}

      @Bean
      public StageFailedListener stageFailedListener() {return new StageFailedListener();}
    ```
  </TabItem>
  <TabItem value="kotlin" label="Kotlin" default>
    ```kotlin
        import org.springframework.context.annotation.Bean

        @Bean
        fun startFlamingockListener(): PipelineStartedListener {
            return PipelineStartedListener()
        }

        @Bean
        fun successFlamingockListener(): PipelineCompletedListener {
            return PipelineCompletedListener()
        }

        @Bean
        fun sailedFlamingockListener(): PipelineFailedListener {
            return PipelineFailedListener()
        }

        @Bean
        fun stageStartedListener(): StageStartedListener {
            return StageStartedListener()
        }

        @Bean
        fun stageCompletedListener(): StageCompletedListener {
            return StageCompletedListener()
        }

        @Bean
        fun stageFailedListener(): StageFailedListener {
            return StageFailedListener()
        }
    ```
  </TabItem>
</Tabs>

---

// File: flamingock-library-config/transactions

# Change-Level Transactionality
*Smart defaults with expert control for enterprise safety*

Flamingock provides intelligent transactionality control that balances enterprise safety with operational flexibility. Understanding when and how to use transactional vs non-transactional changes is key to building reliable distributed system evolution.

---

## The Safety-First Approach

### Default Behavior: Transactional = True
Flamingock defaults to `transactional = true` for maximum safety:
- **Change execution** runs within a database transaction
- **Audit logging** happens in a separate transaction for architectural safety
- **Automatic rollback** of the change transaction if execution fails
- **Coordination mechanisms** ensure consistency between change and audit operations

### When You Need Non-Transactional
Some operations cannot or should not run in transactions:
- **DDL operations** (CREATE INDEX, ALTER TABLE) in many databases
- **Large bulk operations** that would exceed transaction limits
- **Cross-system changes** spanning multiple databases
- **Non-transactional targets** (Kafka, S3, REST APIs)

---

## Understanding Target System Types

### Transactional Target Systems
Systems that natively support ACID transactions:

```java
@TargetSystem("user-database")  // PostgreSQL, MySQL, MongoDB 4.0+
@ChangeUnit(id = "update-user-status", order = "001", author = "platform-team")
// transactional = true (default) - leverages database transaction capabilities
public class UpdateUserStatus {
    
    @Execution
    public void execute(MongoDatabase database) {
        // This runs inside a transaction
        // Automatic rollback on failure
        database.getCollection("users")
                .updateMany(eq("status", "pending"), set("status", "active"));
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        // For CLI undo operations - not called on failure (transaction handles it)
        database.getCollection("users")
                .updateMany(eq("status", "active"), set("status", "pending"));
    }
}
```

### Non-Transactional Target Systems  
Systems without native transaction support:

```java
@TargetSystem("event-stream")  // Kafka, S3, REST APIs
@ChangeUnit(id = "publish-user-events", order = "002", author = "platform-team", 
           transactional = false)  // Required for non-transactional systems
public class PublishUserEvents {
    
    @Execution
    public void execute(KafkaTemplate kafka) {
        // No transaction possible - manual safety required
        kafka.send("user-topic", "user-status-changed", eventData);
    }
    
    @RollbackExecution
    public void rollback(KafkaTemplate kafka) {
        // WILL be called on failure - provides manual safety
        // Publish compensating event or cleanup logic
        kafka.send("user-topic", "user-status-rollback", compensationData);
    }
}
```

---

## When to Use Transactional = False

Even in transactional systems, some operations require `transactional = false`:

### DDL Operations Example
```java
@TargetSystem("user-database")  // MongoDB (transactional system)
@ChangeUnit(id = "create-user-indexes", order = "003", author = "dba-team", 
           transactional = false)  // DDL operations can't be in transactions
public class CreateUserIndexes {
    
    @Execution
    public void execute(MongoDatabase database) {
        // Index creation isn't transactional even in MongoDB
        MongoCollection<Document> users = database.getCollection("users");
        users.createIndex(ascending("email"));
        users.createIndex(compound(ascending("status"), descending("createdAt")));
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        // WILL be called on failure - cleanup partial index creation
        MongoCollection<Document> users = database.getCollection("users");
        try {
            users.dropIndex("email_1");
            users.dropIndex("status_1_createdAt_-1");
        } catch (Exception e) {
            // Handle rollback errors appropriately
        }
    }
}
```

### Large Bulk Operations
```java
@TargetSystem("analytics-database")
@ChangeUnit(id = "bulk-user-analysis", order = "004", author = "analytics-team",
           transactional = false)  // Bulk operations for performance
public class BulkUserAnalysis {
    
    @Execution
    public void execute(MongoDatabase database) {
        // Process millions of records - transaction would timeout/lock
        MongoCollection<Document> users = database.getCollection("users");
        MongoCollection<Document> analytics = database.getCollection("user_analytics");
        
        // Batch processing for performance
        users.find().forEach(user -> {
            Document analyticsDoc = generateAnalytics(user);
            analytics.insertOne(analyticsDoc);
        });
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase database) {
        // Clean up partial bulk operation
        database.getCollection("user_analytics").deleteMany(new Document());
    }
}
```

---

## Recovery Strategy Integration

### Transactional Changes + MANUAL_INTERVENTION
```java
@TargetSystem("financial-database")
@ChangeUnit(id = "update-account-balances", order = "005", author = "finance-team")
// transactional = true (default) + MANUAL_INTERVENTION (default)
// = Maximum safety for critical data
public class UpdateAccountBalances {
    
    @Execution
    public void execute(MongoDatabase database) {
        // Critical financial data - automatic transaction rollback on failure
        // Manual intervention required to investigate any issues
    }
}
```

### Non-Transactional Changes + ALWAYS_RETRY
```java
@TargetSystem("cache-service")
@ChangeUnit(id = "warm-user-cache", order = "006", author = "platform-team",
           transactional = false)  // Cache operations aren't transactional
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)  // Safe to retry
public class WarmUserCache {
    
    @Execution
    public void execute(RedisTemplate redis) {
        // Idempotent cache warming - safe to retry automatically
        // No transaction needed, automatic retry on failure
    }
}
```

---

## Configuration Options

### Per-Change Configuration (Recommended)
```java
// Explicit control per change
@ChangeUnit(id = "my-change", transactional = false, /* other params */)
```

### Global Configuration (Less Common)
```java
// Disable transactions globally
Flamingock.builder()
    .disableTransaction()  // All changes become non-transactional
    .build()
```

---

## Decision Matrix

| Change Type | Target System | Operation | Transactional Setting |
|------------|---------------|-----------|---------------------|
| Data updates | MongoDB, PostgreSQL | DML operations | `true` (default) |
| Schema changes | MongoDB, PostgreSQL | DDL operations | `false` |
| Cache updates | Redis, Memcached | Cache operations | `false` |
| Event publishing | Kafka, RabbitMQ | Message sending | `false` |
| API calls | REST services | HTTP requests | `false` |
| File operations | File system, S3 | File manipulation | `false` |
| Bulk processing | Any database | Large datasets | `false` |

---

## Best Practices

### **Always Provide @RollbackExecution**
Regardless of transactionality, always implement rollback methods:

```java
@RollbackExecution
public void rollback(/* dependencies */) {
    // For transactional changes: Used in CLI undo operations
    // For non-transactional changes: Used in automatic failure recovery
}
```

### **Match Recovery Strategy to Operation**
- **Transactional + Critical data** → MANUAL_INTERVENTION (default)
- **Non-transactional + Idempotent** → ALWAYS_RETRY
- **Non-transactional + Critical** → MANUAL_INTERVENTION

### **Keep Changes Focused**
Don't mix transactional and non-transactional operations in one change:

```java
// ❌ Bad - mixing concerns
@ChangeUnit(id = "mixed-operations")
public class MixedOperations {
    @Execution
    public void execute(MongoDatabase db, KafkaTemplate kafka) {
        // Database update (transactional) + Kafka publish (non-transactional)
    }
}

// ✅ Good - separate concerns
@ChangeUnit(id = "database-update", transactional = true)
@ChangeUnit(id = "kafka-publish", transactional = false)
```

### **Use Explicit Annotations**
Be explicit about transactionality for clarity:

```java
// ✅ Clear intent
@ChangeUnit(id = "user-update", transactional = true)   // Explicit
@ChangeUnit(id = "index-creation", transactional = false) // Explicit
```

---

## Troubleshooting

### "Operation Not Supported In Transaction" Errors
```java
// Error: "Cannot create index in transaction"
@ChangeUnit(transactional = true)  // ❌ Wrong
public class CreateIndexes { }

// Fix: Disable transactions for DDL
@ChangeUnit(transactional = false)  // ✅ Correct
public class CreateIndexes { }
```

### Partial Failure Recovery
```java
@ChangeUnit(transactional = false)
public class NonTransactionalChange {
    
    @Execution
    public void execute() {
        // Step 1: succeeds
        // Step 2: fails <- Partial completion
        // @RollbackExecution will be called automatically
    }
    
    @RollbackExecution  
    public void rollback() {
        // Must handle cleanup of Step 1
        // Flamingock calls this automatically on failure
    }
}
```

---

**Key Takeaway**: Flamingock's transactionality control provides enterprise safety through intelligent defaults while giving you expert control when needed. Use transactions when possible, disable them when necessary, and always provide rollback logic for governance and recovery.

---

// File: flamingock-library-config/extra-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

#  Additional Configuration

This section includes additional settings for customizing defaults and adding contextual information to your Flamingock setup. 

| Setting         | Purpose                                      | Default            |
|-----------------|-----------------------------------------------|--------------------|
| `metadata`      | Attach tags and labels for audit tracking     | _empty map_        |
| `defaultAuthor` | Used when no author is specified in a change  | `"default_author"` |
| `enabled`       | Globally enable/disable Flamingock            | `true`             |

:::note
These options can currently be defined using the Flamingock builder. Support for config file (outside Spring Boot) will be added in a future release
:::
---

## Metadata

Flamingock provides a Metadata object - which is a flexible `Map<String, Object>` that allows you to attach custom information to your Flamingock process.

The metadata is stored as part of the **audit log**, and can be used for labeling, traceability, and future reporting.

### Use Cases
You can use metadata to:
- Tag executions by **team**, **service**, or **region**
- Include a **deployment ID**, **build number**, or **triggering user**
- Attach **comments** or **labels** for easier traceability

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
metadata:
  owner: platform-team
  triggeredBy: ci-cd-pipeline
  notes: initial deployment setup
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
Map<String, Object> metadata = new HashMap<>();
metadata.put("owner", "platform-team");
metadata.put("triggeredBy", "ci-cd-pipeline");

FlamingockStandalone
.setMetadata(metadata)
...
```
    </TabItem>
</Tabs>

---

### Default Author

If a change unit does not specify an `author`, Flamingock will use this value as the fallback.

- Applies to both **code-based** and **template-based** changes
- Default value: `"default_author"`
- Ignored if the change itself defines an explicit author

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
defaultAuthor: antonio
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
FlamingockStandalone
        .setDefaultAuthor("antonio")
```
    </TabItem>
</Tabs>

---

## Disable flamingock process

This global toggle allows you to enable or disable Flamingock.

- If set to `false`, Flamingock will **not run**
- A log message will appear in the **application logs**, indicating that Flamingock is disabled
- No changes will be applied and no audit entries will be created

:::note 
Useful in test environments, local runs, or cases where you want to conditionally skip changes.
:::

### Example

<Tabs groupId="config">
    <TabItem value="file" label="YAML" default>
```yaml
enabled: false
```
    </TabItem>
    <TabItem value="builder" label="Builder">
```java
FlamingockStandalone
  .setEnabled(false)
```
    </TabItem>
</Tabs>

---

// File: frameworks/graalvm

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# GraalVM support

Flamingock provides **first-class support for GraalVM native images**, enabling your application to compile into fast, self-contained executables without sacrificing change tracking, rollback, or template support.

This page explains how to generate a GraalVM native image for a Flamingock-enabled application, using the **reflection metadata** produced by the **annotation processor** and Flamingock’s built-in GraalVM **registration feature**.

---

## How it works

When building your application, Flamingock's annotation processor:

- Scans for all annotated code-based changes (`@ChangeUnit`)
- Discovers template-based changes from `sourcesPackage` and `resourcesDir`
- Generates metadata files containing all required classes for reflection

At native image generation time, Flamingock’s **GraalVM feature** picks up these files and registers the required types with GraalVM, so they’re available at runtime.

:::tip
Learn more about the basics of GraalVM native image compilation in the [GraalVM Native Image basics guide](https://www.graalvm.org/latest/reference-manual/native-image/basics/).
:::

---

## Step-by-step setup

### 1. Add Flamingock GraalVM dependency

<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```kotlin
implementation("io.flamingock:flamingock-graalvm:$flamingockVersion")
```

</TabItem>
<TabItem value="maven" label="Maven">

```xml
<dependencies>
  <dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-graalvm</artifactId>
    <version>${flamingock.version}</version>
  </dependency>
</dependencies>
```

</TabItem>
</Tabs>

---

### 2. Add plugin management (only for Gradle)

If using Gradle, ensure your `settings.gradle.kts` includes:

```kotlin
pluginManagement {
    repositories {
        mavenLocal()
        gradlePluginPortal()
        mavenCentral()
    }
}
```

---

### 3. Add GraalVM resource config

Create a file named `resource-config.json` in your project root:

```json
{
  "resources": {
    "includes": [
      { "pattern": "META-INF/flamingock/metadata.json" }
    ]
  }
}
```

:::info
This file declares which resource files should be accessible to your native image. You can add other application-specific resources here as needed.

See the [GraalVM resource configuration documentation](https://www.graalvm.org/latest/reference-manual/native-image/metadata/#resources) for more details.
:::

---

### 4. Build the application

```bash
./gradlew clean build
```

#### Expected build output

During the build process, Flamingock will emit logs similar to the following — indicating successful annotation processing and metadata generation.

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
Note:    [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
[INFO]   [Flamingock] Reading flamingock pipeline from file: 'src/main/resources/flamingock/pipeline.yaml'
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>


---

### 5. Create the native image

```bash
native-image \
  --no-fallback \
  --features=io.flamingock.graalvm.RegistrationFeature \
  -H:ResourceConfigurationFiles=resource-config.json \
  -H:+ReportExceptionStackTraces \
  --initialize-at-build-time=org.slf4j.simple \
  -jar build/libs/your-app.jar
```

#### What these options do:

- `--features=io.flamingock.graalvm.RegistrationFeature`: Registers all Flamingock-related classes for reflection using metadata gathered during build time.
- `-H:ResourceConfigurationFiles=resource-config.json`: Informs GraalVM of required static resource files to include.
- `--initialize-at-build-time`: – **Optional**. Build‑time init for listed classes/packages (freeze static state; faster start; avoids early reflection/I/O). Flamingock does not require specific entries. Use only if a library benefits (e.g., logging). Example: --initialize-at-build-time=org.slf4j.impl,org.slf4j.simple. Omit if unsure.

#### Expected native image output

When creating the native image, you should see log output from Flamingock's GraalVM `RegistrationFeature`, confirming that Flamingock successfully scanned and registered internal classes, templates, system modules, and user-defined change units. 

The actual output may differ slightly depending on the modules you’ve included, but it should look similar to the following:
<details>
<summary>Click to see the expected logs</summary>
```
 - io.flamingock.graalvm.RegistrationFeature
[Flamingock] Starting GraalVM classes registration
[Flamingock] Starting registration of internal classes
    Registering class: io.flamingock.core.task.TaskDescriptor 
    Registering class: io.flamingock.core.task.AbstractTaskDescriptor 
    Registering class: io.flamingock.core.preview.PreviewPipeline 
    Registering class: io.flamingock.core.preview.PreviewStage 
    Registering class: io.flamingock.core.preview.CodePreviewChangeUnit 
    Registering class: io.flamingock.core.preview.CodePreviewLegacyChangeUnit 
    Registering class: io.flamingock.core.preview.PreviewMethod 
    Registering class: io.flamingock.core.api.template.ChangeTemplateConfig 
    Registering class: io.flamingock.core.preview.TemplatePreviewChangeUnit 
    Registering class: io.flamingock.core.pipeline.Pipeline 
    Registering class: io.flamingock.core.pipeline.LoadedStage 
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedTask 
    Registering class: io.flamingock.core.task.loaded.AbstractReflectionLoadedTask 
    Registering class: io.flamingock.core.task.loaded.AbstractLoadedChangeUnit 
    Registering class: io.flamingock.core.task.loaded.CodeLoadedChangeUnit 
    Registering class: io.flamingock.core.task.loaded.TemplateLoadedChangeUnit 
    Registering class: java.nio.charset.CoderResult 
[Flamingock] Completed internal classes
[Flamingock] Starting registration of templates
    Registering class: io.flamingock.core.api.template.TemplateFactory 
    Registering class: io.flamingock.core.api.template.ChangeTemplate 
    Registering class: io.flamingock.core.api.template.AbstractChangeTemplate 
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplate 
    Registering class: io.flamingock.template.mongodb.model.MongoOperation 
    Registering class: io.flamingock.template.mongodb.MongoChangeTemplateConfig 
[Flamingock] Completed templates
[Flamingock] Starting registration of system modules
    Registering class: io.flamingock.core.engine.audit.importer.changeunit.MongockImporterChangeUnit 
    Registering class: io.flamingock.core.engine.audit.importer.ImporterModule 
[Flamingock] Completed system modules
[Flamingock] Starting registration of user classes
    Registering class: io.flamingock.changes._1_create_clients_collection_change 
    Registering class: io.flamingock.changes._2_insertClientFederico_change 
    Registering class: io.flamingock.changes._3_insert_client_jorge 
[Flamingock] Completed user classes
[Flamingock] Completed GraalVM classes registration
```
</details>

:::tip
For more information on image creation and options, refer to the [GraalVM build overview documentation](https://www.graalvm.org/latest/reference-manual/native-image/overview/Build-Overview/).
:::

---

### 6. Run the native image

```bash
./your-app
```

---

## Example project

We have built a [complete example project for GraalVM](https://github.com/flamingock/flamingock-examples/tree/master/graalvm) that demonstrates:
- A working Flamingock configuration with GraalVM
- Sample change units
- Proper resource configuration
- Native image generation process

You can use this example as a reference implementation while following the steps in this guide.

---

// File: frameworks/kubernetes

# How does Flamingock work within a k8s ecosystem? (to-do)

---

// File: frameworks/springboot-integration/introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Spring Boot integration

Flamingock integrates seamlessly with Spring Boot, offering a powerful and flexible setup for managing your change units in Spring-based applications.

This integration leverages Spring Boot’s features—such as dependency injection, profiles, event publishing, and property configuration—to provide a streamlined and production-ready experience.

---

## Why integrate Flamingock with Spring Boot?

Using Flamingock with Spring Boot allows you to:

- Inject Spring-managed beans directly into change units
- Configure Flamingock via Spring Boot's native configuration files
- Use Spring profiles to control when specific change units run
- Receive execution lifecycle events using `ApplicationEventPublisher`
- Choose between Spring Boot lifecycle hooks (`ApplicationRunner` or `InitializingBean`) to run Flamingock.

---

## Two setup approaches

Flamingock offers **two ways to integrate with Spring Boot**, depending on how much control you want over the configuration and lifecycle.

### Builder-based setup (manual)

This approach gives you full control and uses the standard Flamingock builder with `@EnableFlamingock(setup = SetupType.BUILDER)`.  
You manually inject the required Spring Boot components(ApplicationContext and ApplicationEventPublisher) as well as any Flamingock core configuration.

In addition, you can register other dependencies manually — these will take precedence over beans from the Spring context when resolving what to inject into change units.

This is recommended for advanced users or highly customized environments.

> See: [Builder-based setup](./builder-based-setup.md)

---

### Automatic setup

This is the simplest way to enable Flamingock in Spring Boot.  
Just annotate any class with `@EnableFlamingock` (commonly your main application class), and Flamingock will:

- Auto-detect the application context and event publisher
- Read configuration from Spring Boot config files
- Automatically wire the `FlamingockRunner` bean
- Process the setup configuration from the annotation

Ideal for most users who prefer convention over configuration.

> See: [Automatic setup](./enable-flamingock-setup.md)

---

## Runner strategy: ApplicationRunner vs InitializingBean

Flamingock supports two strategies for executing its process during Spring Boot startup. You can control this via the `runnerType` property in your Spring configuration (`flamingock.runnerType`), or programmatically if using the manual builder.

### Comparison

|                                            | `ApplicationRunner`                                                        | `InitializingBean`                                                |
|--------------------------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------------|
| **Phase**                                  | After all beans are initialized — just before the app is marked as started | During bean initialization — before the app is considered started |
| **Context availability**                   | ✅ Full — all Spring beans and profiles available                           | ⚠️ Limited — not all beans may be available                       |
| **Typical use case**                       | Most common — recommended for production environments                      | For lightweight internal logic or strict startup ordering         |
| **Events fully supported?**                | ✅ Yes                                                                      | ⚠️ Risky — context may not be fully ready                         |
| **Spring beans available in change units** | ✅ Yes                                                                      | ⚠️ May fail or be incomplete                                      |

### Startup failure behavior

If Flamingock encounters an error during execution — whether using `ApplicationRunner` or `InitializingBean` — the Spring Boot application **will fail to start**.

This is intentional: Flamingock runs before the application is marked as ready. In deployment platforms such as **Kubernetes**, a failure at this stage will:

- Prevent the container from reaching a *Ready* state
- Trigger restart policies, health checks, or rollbacks as configured
- Ensure that the system is never exposed in a partially initialized or inconsistent state

This behavior ensures your application only starts when all change units have been applied successfully.

---

## Dependency

To use the Spring Boot integration, add the appropriate module for your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Flamingock provides two editions for Spring Boot integration.

### Why are there two Spring Boot integration Community-Edition artifacts?

The only difference is the Java version they target:

- `flamingock-springboot-integration` — requires JDK 17 or newer.
- `flamingock-springboot-integration-v2-legacy` — kept for teams still on Spring Boot 2 who must stay on JDK 8 – 11.

Choose the artifact that matches the JDK level of your application today; switching later is as simple as changing the dependency.

| Package Name                                   | Spring Boot Version  |
|------------------------------------------------|----------------------|
| `flamingock-springboot-integration`            | [3.0.0, 4.0.0)       |
| `flamingock-springboot-integration-v2-legacy`  | [2.0.0, 3.0.0)       |

---

## :white_check_mark: Best practices

Consider the following recommendations to get the most out of Flamingock’s Spring Boot integration:

- **Prefer `ApplicationRunner` as your runner strategy**  
  It ensures Flamingock runs after the application context is fully initialized, giving it access to all beans, profiles, and configuration. It also integrates more safely with event publishing and external monitoring tools like Actuator or Prometheus.

- **Use automatic setup (`@EnableFlamingock`) for simpler setups**  
  Unless you have advanced needs (such as injecting non-Spring-managed dependencies), the automatic setup provides a clean and reliable integration path.

- **Use Spring profiles to scope change units**  
  Profiles let you control when specific change units execute, avoiding the need for environment-specific pipelines.

- **Avoid manual execution unless absolutely necessary**  
  Letting Spring handle the execution via `ApplicationRunner` or `InitializingBean` ensures Flamingock runs at the appropriate time in your application lifecycle.

- **Register custom platform components using `.addDependency(...)` only when required**  
  Most applications using automatic setup will not need to register components manually.

---

// File: frameworks/springboot-integration/enable-flamingock-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Automatic Setup

Flamingock provides a convenient automatic integration with Spring Boot using the `@Flamingock` annotation. This setup is ideal when you want Flamingock to automatically detect and wire required components without writing explicit builder logic.

---

## Import the springboot integration library

Add the appropriate Flamingock Spring Boot integration dependency, depending on your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x (Spring 6.x)
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (Spring 5.x, legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x (Spring 6.x) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (Spring 5.x, legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Check [Version Compatibility](introduction.md#version-compatibility)

## Configure setup and activate integration

To activate the integration, add `@EnableFlamingock` to any class in your application (commonly on your main class or a configuration class):

```java
import io.flamingock.core.api.annotations.EnableFlamingock;
import io.flamingock.core.api.annotations.Stage;

@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@SpringBootApplication
public class MyApplication {
  public static void main(String[] args) {
    SpringApplication.run(MyApplication.class, args);
  }
}
```

The `@EnableFlamingock` annotation enables automatic Spring Boot integration, which:

- Detect and use Spring’s `ApplicationContext` and `ApplicationEventPublisher`
- Loads Flamingock configuration directly from your Spring Boot config file
- Automatically configures the runner (e.g., ApplicationRunner or InitializingBean)
- Processes the setup configuration from the annotation

---

## Providing configuration

Runtime configuration is defined using standard Spring Boot configuration files. Use the `flamingock` section for all core and edition-specific options.

```yaml
flamingock:
  lockAcquiredForMillis: 1200
  runnerType: InitializingBean
  # other configuration...
```

:::info
If the `runnerType` property is not provided, Flamingock defaults to using `ApplicationRunner`.
:::

---

## Next steps

- Want full control over the builder? See [Builder-based setup](builder-based-setup.md)
- Explore [Spring Boot profile support](profiles.md)
- Learn about [Flamingock lifecycle events](../../flamingock-library-config/events.md)

---

// File: frameworks/springboot-integration/builder-based-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Flamingock supports manual integration with Spring Boot using the same builder API shared with standalone setups. 

This unified approach makes it easy to switch between environments without changing your integration logic, while giving you full control over how Flamingock is initialized and executed within your application.

It’s especially useful when integrating Flamingock alongside other frameworks, when you need fine-grained control over the setup process, or when you want to override or prioritize specific dependencies manually.

---

## Import the springboot integration library

Add the appropriate Flamingock Spring Boot integration dependency, depending on your version:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
// For Spring Boot 3.x
implementation("io.flamingock:flamingock-springboot-integration:$flamingockVersion")

// For Spring Boot 2.x (legacy)
implementation("io.flamingock:flamingock-springboot-integration-v2-legacy:$flamingockVersion")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<!-- For Spring Boot 3.x -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration</artifactId>
    <version>${flamingock.version}</version>
</dependency>

<!-- For Spring Boot 2.x (legacy) -->
<dependency>
    <groupId>io.flamingock</groupId>
    <artifactId>flamingock-springboot-integration-v2-legacy</artifactId>
    <version>${flamingock.version}</version>
</dependency>
```
  </TabItem>
</Tabs>

### Version Compatibility

Check [Version Compatibility](introduction.md#version-compatibility)

## Configure setup and build Flamingock manually

With the manual setup, you first need to configure Flamingock using `@EnableFlamingock` annotation with `setup = SetupType.BUILDER`, then manually configure and run Flamingock using the builder API.

### 1. Configure the annotation

```java
@EnableFlamingock(
    setup = SetupType.BUILDER,
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
@Configuration
public class FlamingockConfig {
    // Configuration class
}
```

### 2. Manual builder configuration

With the manual setup, you are responsible for configuring and running Flamingock using the builder API. This includes:

- Providing your configuration (e.g., lock settings, metadata) directly via the builder
- Registering the required **platform components** using `.addDependency(...)`
- `ApplicationContext`
- `ApplicationEventPublisher`

```java
FlamingockBuilder builder = Flamingock
    .setLockAcquiredForMillis(120000) // example config
    .addDependency(applicationContext)
    .addDependency(applicationEventPublisher);
```

:::info
Platform components are registered using the same `.addDependency(...)` method used for change unit dependencies.  
For details, see the [Platform component injection](../../flamingock-library-config/platform-component-injection.md) page.
:::
---
## Overriding Spring-provided dependencies
When using the builder-based setup, Flamingock will attempt to resolve dependencies using the Spring context.

However, if you manually register a dependency via `.addDependency(...)`, that dependency will take precedence over anything resolved from the Spring context. This gives you fine-grained control when you want to:

- Override a Spring-managed bean with a custom instance
- Inject mock or test-specific versions of services
- Provide external or non-Spring-managed components directly

```java
builder
  .addDependency(customClientService) // Overrides Spring's bean of same type
  .addDependency(applicationContext); // Registers Spring context for base dependency injection
```
In a nutshell, Flamingock resolves dependencies using the following order:
- Manually added dependencies via .addDependency(...)
- Beans from the Spring context (if ApplicationContext was registered)

---

## Running Flamingock

Once you've configured the builder, you can choose how to execute Flamingock:

### Option 1: Run manually

You can run Flamingock manually:

```java
builder.build().run();
```

### Option 2: Expose as a Spring Bean

Alternatively, you can integrate Flamingock into the Spring Boot lifecycle by exposing it as an `ApplicationRunner` or `InitializingBean`:

```java
@Bean
public ApplicationRunner flamingockRunner() {
  return SpringbootUtil.toApplicationRunner(builder.build());
}
```

Or:

```java
@Bean
public InitializingBean flamingockRunner() {
  return SpringbootUtil.toInitializingBean(builder.build());
}
```

This ensures Flamingock executes automatically as part of the Spring Boot startup sequence.

---

## Next steps

**Want to avoid manual setup?** Explore the [Automatic Setup](./enable-flamingock-setup.md) for automatic integration with minimal code.

---

// File: frameworks/springboot-integration/profiles

# Spring Boot profiles

Flamingock supports **Spring Boot profiles** out of the box. This allows you to conditionally run specific change units depending on which profile(s) are active in your application.

This is useful for managing environment-specific changes, such as different initialization data for `dev`, `staging`, or `prod` environments.

---

## What is a Spring profile?

Spring profiles provide a way to segregate parts of your application configuration and behavior based on the active environment.

You can define profiles like `dev`, `test`, `staging`, or `prod`, and activate **one or more** of them using any of the following methods:

- Inside `application.yml` or `application.properties`:
  ```yaml
  spring:
    profiles:
      active: dev,staging
  ```

- Using profile-specific configuration files like `application-dev.yml` or `application-prod.yml`

- As command-line arguments:
  ```bash
  --spring.profiles.active=dev,staging
  ```

- Through environment variables:
  ```bash
  SPRING_PROFILES_ACTIVE=dev,staging
  ```

When multiple profiles are active, Flamingock evaluates each change unit against **all active profiles**, and includes it if any match.

---

## How Flamingock uses profiles

Flamingock automatically retrieves the active profiles from Spring’s `ApplicationContext`. You don’t need to manually provide them.

You can then annotate any change unit with Spring’s native `@Profile` annotation to control whether it runs:

```java
@ChangeUnit(id = "add-test-data", order = "001")
@Profile("dev")
public class AddTestDataChangeUnit {
  // will only run if "dev" profile is active
}
```

Flamingock applies the same logic as Spring Boot when evaluating whether a change unit should run.

---

## Multiple profiles

You can declare multiple profiles in a single `@Profile` expression:

```java
@Profile({"dev", "staging"})
```

This change unit will run if **any** of the listed profiles is active.

---

## Excluding profiles

To exclude a change unit from a specific profile, you can use Spring Expression Language (SpEL):

```java
@Profile("!prod")
```

This will run the change unit in **all environments except `prod`**.

---

## ✅ Best practices

- Use profiles to isolate test data, preview features, or tenant-specific migrations
- Avoid mixing profile-specific logic inside a single change unit — split them into separate classes
- Keep profile names consistent across your team and environments (e.g., use `dev` everywhere, not `development`, `dev-env`, etc.)
- Consider grouping related change units under a shared profile for easier activation

---

// File: getting-started/get-started

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Get started

Let's walk through a simple scenario: evolving your inventory service with a few typical changes:

- Add a new column to a MySQL database  
- Provision a new S3 bucket for product images  
- Create a Kafka topic for stock updates  

Even in this basic example, Flamingock ensures all these changes are applied **safely, consistently, and audibly** at your application startup.  
This guide walks you through the process in 5 simple steps.

---

## 1. Set up Flamingock in your project

Add Flamingock to your build:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle" default>

```kotlin
implementation(platform("io.flamingock:flamingock-community-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-community")

annotationProcessor("io.flamingock:flamingock-processor:$flamingockVersion")
```

  </TabItem>
  <TabItem value="maven" label="Maven">

```xml
<dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>io.flamingock</groupId>
      <artifactId>flamingock-community-bom</artifactId>
      <version>${flamingockVersion}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>

<dependency>
  <groupId>io.flamingock</groupId>
  <artifactId>flamingock-community</artifactId>
</dependency>

<!-- Annotation processor -->
<build>
  <plugins>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <version>3.11.0</version>
      <configuration>
        <annotationProcessorPaths>
          <path>
            <groupId>io.flamingock</groupId>
            <artifactId>flamingock-processor</artifactId>
            <version>${flamingockVersion}</version>
          </path>
        </annotationProcessorPaths>
      </configuration>
    </plugin>
  </plugins>
</build>
```

  </TabItem>
</Tabs>

For more about editions, see [Community Edition](../community-edition/introduction.md) and [Cloud Edition](../overview/Editions.md).

---

## 2. Define your first ChangeUnits

Each ChangeUnit represents a single change.  
For our example, we'll define three:

- **MySQL**: Add a column `category` to products
- **S3**: Create a `product-images` bucket  
- **Kafka**: Create a `stock-updates` topic

ChangeUnits can be:
- **Code-based**: Java classes with annotations
- **Template-based**: YAML files using reusable templates

<Tabs groupId="change">
  <TabItem value="template_based" label="Template based" default>

```yaml
id: add-product-category
author: team
order: "001"
targetSystem: mysql-inventory
template: sql-template
templateConfiguration:
  executionSql: |
    ALTER TABLE products ADD COLUMN category VARCHAR(255)
  rollbackSql: |
    ALTER TABLE products DROP COLUMN category
```

  </TabItem>
  <TabItem value="code_based" label="Code based">

```java
@TargetSystem("aws-s3")
@ChangeUnit(id = "create-s3-bucket", order = "002", author = "team")
public class _002_CreateS3Bucket {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("product-images")
        .createBucketConfiguration(
            CreateBucketConfiguration.builder()
                .locationConstraint(BucketLocationConstraint.EU_WEST_1)
                .build())
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("product-images")
        .build());
  }
}
```

  </TabItem>
</Tabs>

For more details, see [Concepts → ChangeUnits](../overview/core-concepts.md).

---

## 3. Create target systems

Target systems represent the external systems Flamingock will apply your changes to.  
They are configured in the builder and shared across ChangeUnits.

For our example:
- A MySQL database (`mysql-inventory`)
- An S3 bucket service (`aws-s3`)  
- A Kafka cluster (`kafka`)

```java
SqlTargetSystem sql = new SqlTargetSystem("mysql-inventory").withDatasource(ds);
DefaultTargetSystem s3 = new DefaultTargetSystem("aws-s3");
DefaultTargetSystem kafka = new DefaultTargetSystem("kafka");
```

See [Target systems](../flamingock-library-config/target-system-configuration.md) for more details.

---

## 4. Configure stages

Flamingock organizes your changes in stages.  
Most applications only need one stage:

```java
@EnableFlamingock(
  stages = {
    @Stage(location = "com.company.inventory.changes")
  }
)
public class App {}
```

- **location**: Where Flamingock should look for changes (package or resources)
- **name**: Optional — defaults to the location name

See [Stages](../flamingock-library-config/setup-and-stages.md) for more details and advanced setups.

---

## 5. Configure Flamingock runtime

Finally, configure Flamingock before running your application.

- **Community Edition**: Set your audit store (MongoDB, DynamoDB, Couchbase, etc.) in the builder

- **Cloud Edition** (coming soon): Provide your API token, service name, and environment

<Tabs groupId="edition">
  <TabItem value="community" label="Community" default>

```java
FlamingockStandalone
  .setAuditStore(new MongoSyncAuditStore(mongoClient, mongoDatabase))
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
  <TabItem value="cloud" label="Cloud (coming soon)">

```java
FlamingockStandalone
  .setApiToken("your-flamingock-api-token") 
  .setEnvironment("dev")
  .setService("inventory-service")
  .addTargetSystems(sql, s3, kafka)
  .build()
  .run();
```

  </TabItem>
</Tabs>

---

## 6. Run your application

When your service starts, Flamingock automatically:

1. Discovers your ChangeUnits
2. Checks pending changes  
3. Executes them safely in order
4. Records everything in the audit store

**If Flamingock cannot guarantee a safe outcome, it stops and alerts you. Safety first.**

### Example output

<details>
<summary>Click to see the expected logs</summary>
<Tabs groupId="gradle_maven">
<TabItem value="gradle" label="Gradle" default>

```bash
> Task :compileJava
Note:    [Flamingock] Starting Flamingock annotation processor initialization.
Note:    [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
Note:    [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Initialization completed. Processed templated-based changes.
Note:    [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
Note:    [Flamingock] Reading flamingock setup from annotation configuration
Note:    [Flamingock] Finished processing annotated classes and generating metadata.
Note:    [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
<TabItem value="maven" label="Maven">

```bash
[INFO]   [Flamingock] Starting Flamingock annotation processor initialization.
[INFO]   [Flamingock] 'resources' parameter NOT passed. Using default 'src/main/resources'
[INFO]   [Flamingock] 'sources' parameter NOT passed. Searching in: '[src/main/java, src/main/kotlin, src/main/scala, src/main/groovy]'
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Initialization completed. Processed templated-based changes.
[INFO]   [Flamingock] Searching for code-based changes (Java classes annotated with @Change or legacy @ChangeUnit annotations)
[INFO]   [Flamingock] Reading flamingock setup from annotation configuration
[INFO]   [Flamingock] Finished processing annotated classes and generating metadata.
[INFO]   [Flamingock] Final processing round detected - skipping execution.
```

</TabItem>
</Tabs>
</details>

---

## Next steps

- [Spring Boot integration](../frameworks/springboot-integration/introduction.md)
- [Configuration options](../flamingock-library-config/setup-and-stages.md)
- [Recovery and safety](../recovery-and-safety/recovery-strategies.md)

---

// File: getting-started/how-it-works

# How it works?

Flamingock provides a structured, auditable, and version-controlled approach to managing changes across your systems, services, and configurations — simplifying the release process and reducing the risk of failure.

At a high level, here’s how Flamingock works:

```mermaid
flowchart LR
    A[1: Define Changes as ChangeUnits] --> B[2: Organize into Workflows]
    B --> C[3: Execute at Startup or On Demand]
    C --> D[4: Acquire Distributed Lock]
    D --> E[5: Apply ChangeUnits Sequentially]
    E --> F[6: Audit Changes]
    F --> G{Success?}
    G -- Yes --> H[Finish Deployment]
    G -- No --> I[Invoke Rollback Logic]
    I --> H
```
:::tip Flamingock helps development teams **release faster**, **with confidence**, and **without surprises**. It provides an auditable traceable system where all Changes are centrally managed.
:::

---

## 1. Define your changes as ChangeUnits

Every change — whether it’s a database migration, a feature flag update, or a third-party API configuration — is encapsulated into a **ChangeUnit**.

- Each ChangeUnit is uniquely identified, versioned, and optionally includes rollback logic.
- Changes can be defined in code (Java/Kotlin) or declaratively (YAML/JSON) via reusable templates [**templates**](../templates/templates-introduction.md).

---

## 2. Organize changes into Workflows

ChangeUnits are grouped into stages and structured into a [**Workflow**](../overview/core-concepts.md?#-workflows) pipeline to represent a coordinated sequence of changes.

- Workflows allow you to define how changes should be applied: sequentially or (in future releases) in parallel or conditionally.
- This logical grouping simplifies the orchestration and order of changes across systems / services / components.

---

## 3. Execute at startup (or on demand)

When your application starts, Flamingock automatically:

- Scans for pending ChangeUnits
- Applies them in the defined workflow order
- Ensures **idempotency** so the same changes aren't applied twice

Flamingock can also run in standalone mode, ideal for setups that don't use an underlying framework (ie. Spring).

---

## 4. Locking for safety in distributed environments

Using **distributed locking**, Flamingock ensures only one instance (or one node) applies changes at a time — preventing race conditions or duplicate executions.

- Works across microservices and distributed system setups
- Supports multiple store types:
  - Flamingock Community Edition, with native driver compatibility with MongoDB, Couchbase, DynamoDB
  - Flamingock SaaS or Flamingock self-hosted options to leverage Flamingock's provisioned storage.

---

## 5. Audit everything, rollback when needed

Every change applied is **fully audited**:

- When, by whom, and what was changed
- Status of execution (success/failure)
- And a provisioned optional rollback strategy for non-transactional integrations.

In case of failure or rollback scenario, Flamingock uses defined compensating logic to revert changes and restore consistency.

---

## Example Use Cases

### Example 1: Versioning made simple

Imagine a developer needs to introduce the following system changes as part of a release:

1. Add a new field to the user collection in MongoDB  
2. Enable a feature flag in a SaaS dashboard via REST API  
3. Update an environment variable in a remote configuration store

![Example 1](../../static/img/Flamingock%20Example%20use%20case%201.png)

Here’s how Flamingock helps:

- The developer defines each change as an individual **ChangeUnit**, with rollback logic included.
- These ChangeUnits are grouped into stages and a embedded into a **workflow**, ensuring they run in the correct order.
- On the next application startup, Flamingock:
  - Detects that these changes haven’t been applied yet
  - Acquires a distributed lock
  - Executes all ChangeUnits safely and atomically
  - Logs every detail in the audit system

Flamingock rolls back automatically in case of failure(if defined), ensuring the system doesn’t end up in a partial state.

The result? Faster deployments, consistent environments, and complete traceability.

---

### Example 2: Synchronizing Changes across domain services

In a Domain-Driven Design (DDD) environment, a change to a domain model often requires updates across several components:

1. Update to the Database and API specification (e.g., OpenAPI/Swagger)
2. Modify the Kafka event schema and topic configuration
3. Adjust the API Gateway routing and validation rules

![Example 2](../../static/img/Flamingock%20Example%20use%20case%202.png)

Here’s how Flamingock makes this seamless:

- The team creates **ChangeUnits** for:
  - Updating the Database and  API specification
  - Reconfiguring Kafka topics and event schema
  - Updating API Gateway specs
- All related *ChangeUnits* are grouped into a single **workflow** to ensure coordinated application.
- During deployment, Flamingock:
  - Applies all changes atomically, respecting dependencies
  - Acquires a distributed lock to avoid concurrent modifications
  - Audits the entire process for traceability and compliance

This ensures that changes in the Database, messaging, and APIs exposed in the gateway are synchronized, reducing integration errors and deployment friction across microservices.

---

---

// File: overview/Introduction

![Flamingock logo](../../static/img/Flamingock-04.png)  
*The safety-first platform for distributed system evolution*

---

## The Flamingock Guarantee
**"Your system will always be left in a known, auditable, and consistent state — no matter what happens."**

Managing change across an application and the distributed systems it interacts with is inherently complex — database schema updates, message broker configuration, API evolution, cloud service provisioning.  
Traditional tools optimize for the *happy path*, but real-world deployments face partial failures, network issues, and uncertain states.

**Flamingock** is built for this reality. It provides safety-first distributed system evolution with **complete auditability** and **configurable recovery strategies**, ensuring that change is never left in doubt.

---

## Why Flamingock?

### Safety and auditability by design
- **Safe by default**: When Flamingock cannot guarantee success, it stops and alerts instead of risking corruption.  
- **Built-in recovery mechanisms**: By default Flamingock retries safely where possible, and users can configure recovery strategies to minimize manual intervention.  
- **Complete audit trail**: Every execution, success, and failure is tracked for compliance and troubleshooting.  
- **Deterministic execution**: ChangeUnits run once and only once, in a controlled order.  

### Designed for distributed reality
- **Non-transactional systems supported**: Kafka, S3, REST APIs, and more get first-class safety treatment.  
- **Network-resilient**: Handles interruptions and partial failures with recovery strategies.  
- **Cluster-safe**: Prevents race conditions in distributed or containerized deployments.  

### Organizational benefits
- **Reduce risk**: Eliminate silent corruption and ensure compliance.  
- **Increase velocity**: Developers can evolve their systems independently, without waiting on infrastructure teams.  
- **Enable governance**: Clear ownership, auditability, and rollback capabilities across all environments.  

---

## Use Cases

Flamingock enables controlled, auditable evolution across your technology stack:

**Data Systems**
- Database schema changes (SQL/NoSQL)  
- Index creation and optimization  
- Data migrations and transformations  

**Infrastructure & APIs**  
- Message broker topic and schema management  
- API gateway and routing rules  
- Cloud service configuration  

**Application Configuration**  
- Feature flag rollouts  
- SaaS integrations and external service setup  
- Security policies and permissions  

**Distributed Coordination**  
- Multi-service configuration synchronization  
- Cross-system dependency management  

**...and other systems requiring safe, auditable evolution**

---

## What Flamingock Is Not
- **Not Infrastructure-as-Code**: We evolve systems already provisioned by your infrastructure.  
- **Not generic batch processing**: Optimized for deterministic, auditable changes — not arbitrary long-running jobs.  
- **Not a CI/CD replacement**: Complements your pipeline but focuses exclusively on safe system evolution.  

---

## How Flamingock Works

### Change-as-code architecture
Developers define **ChangeUnits** in code or templates. Each ChangeUnit is versioned, auditable, and executed once per system.  

### Execution lifecycle
1. **Discovery** – Flamingock scans your app for ChangeUnits  
2. **Validation** – Prevents duplicate execution using the audit store  
3. **Execution** – Runs the change with the configured recovery strategy  
4. **Audit** – Records all outcomes for visibility and compliance  
5. **Recovery** – Provides CLI (and Cloud UI) tools for resolution if needed  

---

## Next Steps
- [Quickstart Guide](../getting-started/get-started.md)  
- [How it Works](../getting-started/how-it-works.md)  
- [Technical Overview](technical-overview.md)

---

// File: overview/Change-as-Code

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

**Automate changes. Version changes. Control changes.**  
Change-as-Code (CaC) means every system change—whether it’s an S3 bucket toggle, a new database schema, or a Kafka topic configuration—is authored, versioned, and audited just like application code.

At Flamingock, we champion CaC as the foundation for truly reliable, auditable, and repeatable deployments. No more one-off shell scripts or manual “clicks” in a console—every change is written in code, tracked in your VCS, and executed in a controlled pipeline.

---

## Why CaC matters today

Modern applications increasingly span dozens of external systems—ranging from relational and NoSQL databases to SaaS feature flags, message buses, and infrastructure APIs. Managing these changes manually or with ad-hoc scripts leads to:

- **Drift and “snowflake” environments**  
  When teams manually tweak production configurations, environments diverge, making rollbacks or audits nearly impossible.

- **Lack of auditability**  
  Regulatory and security teams require a full record of “what changed, when, and who made it.” Spreadsheets and one-off commands don’t cut it.

- **Inefficient collaboration**  
  Developers, operations, and security need a single source of truth: change definitions in code, reviewed and versioned via pull requests.

- **Increased risk of human error**  
  Pasting commands into a console or clicking UI checkboxes invites typos, misconfigurations, and stress during deployment windows.

Flamingock’s CaC approach solves these problems by treating every external-system change as first-class code—complete with version control, automated execution, and a centralized audit trail.

---

## Four Pillars of Change-as-Code

1. **One-Hundred-Percent Versioned**  
   All ChangeUnits live in your Git repository (or other VCS). This means you can review, diff, and roll back changes just like application code.

2. **Automated Execution**  
   Flamingock scans and applies ChangeUnits at application startup or on-demand via the CLI. No manual intervention—just code running code.

3. **Auditable & Traceable**  
   Every ChangeUnit outcome is recorded in an audit store (your database or Flamingock Cloud). Teams can query “who ran what change, and when,” ensuring full compliance.

4. **Cross-Component Support**  
   Whether it’s SQL/NoSQL DDL, S3 buckets, Kafka topics, feature-flag toggles, or REST API calls—Flamingock treats them all as code. Your entire system evolves in lockstep.

---

## “Hello, CaC” Code Snippet

Imagine you need to toggle a feature flag in a downstream service (not a database). In Flamingock, you’d write:

```java
@Change(id = "enable-autosave", order = "0005", author = "ops-team")
public class _0005_EnableAutoSaveFeature {

  @Execution
  public void enableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", true);
  }

  @RollbackExecution
  public void disableAutoSave(FeatureFlagClient client) {
    client.setFlag("autosave_feature", false);
  }
}
```

- **Versioned**: This code-based or template-based ChangeUnit lives in your VCS.
- **Automated**: Flamingock executes it in order (0005) at startup or via CLI.
- **Auditable**: Upon success, an audit entry is written to your audit store.
- **Cross-Component**: The same pattern works for a DynamoDB schema change, a Kafka topic creation, or any REST API call.

---

## Illustration: CaC vs. IaC

![](../../static/img/Change%20as%20code-2.png)

- **Infrastructure as Code (IaC)**: Use Terraform, CloudFormation, Pulumi, etc., to provision VMs, networks, and databases (the “foundation”).
- **Change as Code (CaC)**: Use Flamingock to version and apply everything that lives on that foundation—database schemas, feature flags, SaaS configurations, message topics, and more.

---

## Real-World Use Cases

### Multi-tenant SaaS Onboarding

**Problem**: Over the lifetime of your application, you might need to create and then later modify external resources—such as an S3 bucket, Kafka topics, IAM roles, and initial database state—as part of each new release. Doing this manually or with ad-hoc scripts risks drift, missing audits, and inconsistent environments..

**CaC Solution**: Define a sequence of ChangeUnits that run in order on mutiple deployments, inserting audit entries and ensuring reproducible, versioned updates::
<Tabs groupId="config">
<TabItem value="code-base" label="Code" default>
```java
@ChangeUnit(id = "provision-bucket", order = "0001", author = "team-a", transactional = false)
public class _0001_ProvisionBucketChange {

    @Execution
    public void execute(S3Client s3) {
        s3.createBucket(CreateBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }

    @RollbackExecution
    public void rollback(S3Client s3) {
        s3.deleteBucket(DeleteBucketRequest.builder()
                .bucket("flamingock-app-bucket")
                .build());
    }
}

@ChangeUnit(id = "create-kafka-topics", order = "0002", author = "devops", transactional = false)
public class _0002_CreateKafkaTopicsChange {

    @Execution
    public void exec(KafkaAdminClient admin) {
        NewTopic topic1 = new NewTopic("app-events", 3, (short) 1);
        NewTopic topic2 = new NewTopic("user-notifications", 2, (short) 1);
        admin.createTopics(Arrays.asList(topic1, topic2));
    }

    @RollbackExecution
    public void rollback(KafkaAdminClient admin) {
        admin.deleteTopics(Arrays.asList("app-events", "user-notifications"));
    }
}

@ChangeUnit(id = "setup-iam-roles", order = "0003", author = "devops", transactional = false)
public class _0003_SetupIamRolesChange {

    @Execution
    public void exec(IamClient iam) {
        CreateRoleResponse response = iam.createRole(CreateRoleRequest.builder()
                .roleName("flamingock-app-role")
                .assumeRolePolicyDocument("{...}") // truncated for brevity
                .build());
    }

    @RollbackExecution
    public void rollback(IamClient iam) {
        iam.deleteRole(DeleteRoleRequest.builder()
                .roleName("flamingock-app-role")
                .build());
    }
}

@ChangeUnit(id = "seed-database", order = "0004", author = "devops", transactional = true)
public class _0004_SeedTenantDataChange {

    @Execution
    public void exec(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate(
                    "INSERT INTO tenants (id, name, created_at) " +
                            "VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW())"
            );
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }

    @RollbackExecution
    public void rollback(DataSource ds) {
        try (Connection conn = ds.getConnection();
             Statement stmt = conn.createStatement()) {
            stmt.executeUpdate("DELETE FROM tenants WHERE id IN (1, 2)");
        } catch (SQLException e) {
            throw new RuntimeException(e);
        }
    }
}

@ChangeUnit(id = "update-bucket-settings", order = "0005", author = "team-a", transactional = false)
public class _0005_UpdateBucketSettingsChange {

    @Execution
    public void execute(S3Client s3) {
        // Example: enable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Enabled")
                        .build())
                .build());
    }

    @RollbackExecution
    public void rollback(S3Client s3) {
        // Example: disable versioning on the bucket
        s3.putBucketVersioning(PutBucketVersioningRequest.builder()
                .bucket("flamingock-app-bucket")
                .versioningConfiguration(VersioningConfiguration.builder()
                        .status("Suspended")
                        .build())
                .build());
    }
}

```
</TabItem>
<TabItem value="template-base" label="Template">

```yaml

# File: _0001_provision-bucket.yaml
id: "provision-bucket"
order: 0001
author: "team-a"
transactional: false
templateName: aws-s3-template
templateConfiguration:
  bucketName: "flamingock-app-bucket"
  region: "us-east-1"
  rollbackBucketName: "flamingock-app-bucket"

---

# File: _0002_create-kafka-topics.yaml
id: "create-kafka-topics"
order: 0002
author: "devops"
transactional: false
templateName: kafka-template
templateConfiguration:
  topics:
    - "app-events"
    - "user-notifications"
  configs:
    app-events:
      partitions: 3
      replicationFactor: 1
    user-notifications:
      partitions: 2
      replicationFactor: 1
  rollbackTopics:
    - "app-events"
    - "user-notifications"

---

# File: _0003_setup-iam-roles.yaml
id: "setup-iam-roles"
order: 0003
author: "devops"
transactional: false
templateName: aws-iam-template
templateConfiguration:
  roleName: "flamingock-app-role"
  assumeRolePolicy: |
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": { "Service": "ec2.amazonaws.com" },
          "Action": "sts:AssumeRole"
        }
      ]
    }
  rollbackRoleName: "flamingock-app-role"

---

# File: _0004_seed-database.yaml
id: "seed-database"
order: 0004
author: "devops"
transactional: true
templateName: sql-template
templateConfiguration:
  executionSql: |
    INSERT INTO tenants (id, name, created_at)
    VALUES (1, 'TenantA', NOW()), (2, 'TenantB', NOW());
  rollbackSql: |
    DELETE FROM tenants WHERE id IN (1, 2);

---

# File: _0005_update-bucket-settings.yaml
id: "update-bucket-settings"
order: 0005
author: "team-a"
transactional: false
templateName: aws-s3-template
templateConfiguration:
  # Enable versioning on an existing bucket
  bucketName: "flamingock-app-bucket"
  versioningConfiguration:
    status: "Enabled"
  # Rollback: suspend versioning
  rollbackVersioningConfiguration:
    bucketName: "flamingock-app-bucket"
    versioningConfiguration:
      status: "Suspended"

---

```

</TabItem>
</Tabs>

Flamingock ensures these four steps run in sequence—never twice—and logs them in your audit store for future reference.

---

## Change-as-Code Checklist

- ✅ **Change lives in VCS**: Every ChangeUnit class (or YAML template) is versioned.
- ✅ **Automated pipeline**: Flamingock applies changes automatically at startup or via CLI.
- ✅ **Audit trail**: Query your audit store for a complete history of applied changes.
- ✅ **Rollback logic**: Each ChangeUnit provides `@RollbackExecution` to undo or compensate if needed.
- ✅ **Consistent ordering**: All ChangeUnits follow a strict, declared ordering (via the `order` attribute).
- ✅ **Cross-component**: You can target databases, SaaS APIs, feature flags, message systems—anything with a client API.

---

## Next Steps

- [Quickstart Guide](../getting-started/get-started.md) → Learn how to create your first ChangeUnit and run Flamingock. 
- [Core concepts](./core-concepts.md)   → Dive deeper into auditing, drivers, transactions, and distributed locking.
- [Real use case examples](../resources/examples.md) → Explore real-world code samples: MongoDB, DynamoDB, Couchbase, Kafka, and more.

---

// File: overview/key-features

# Key features

With Flamingock, you can take advantage of the following features:

- 🧱 **Change management of any component**: Manage configuration and data changes with your Application code for any component. NoSQL Databases are a first-class citizen, and we've expanded this capability for any type of component that requires configuration.
  :::info
  Currently supported languages: Java, Kotlin.
  :::
- 🔗 **Extended integrations and custom use case support**: Flamingock enables one-time or repeatable operational processes — such as fetching external data, initializing third-party services, or executing custom logic — ensuring they run safely, just once, and in the right context. It expands on Mongock's support to manage Database changes to all systems, databases, technologies and configurations  (ie. Kafka, Twilio, Auth0, etc) or any user-defined scenario.

- 🧩 **Flexible migration Templates**: New mechanisms for defining changes, offering a no-code option to streamline and simplify change management.

- 🚀 **Seamless deployment**: Deploy your application and systems together, ensuring version compatibility and reducing deployment friction.

- ⚡ **GraalVM support**: Enables the compilation of Java applications into native executables for improved performance.

- 👥 **Multi-Tenant support (coming soon!)**: Designed to handle multiple tenants within the same infrastructure.

- 🔒 **Distributed Locking**: Ensures synchronized deployment of multiple service instances, maintaining consistency and preventing conflicts in distributed environments.

- 🔄 **Auditing & Rollback**: Comprehensive auditing capabilities with support for rollback of changes to ensure consistency and control.

- ☁️ **Cloud offering (coming soon!)**: Offers a fully managed service by hosting Flamingock’s operational data on our servers, removing the need for users to set up and manage their own infrastructure whilst unlocking the full Flamingock suite of features.

- 💻 **Management Operations via a Dashboard and CLI (coming soon!)**: Flamingock offers tools to simplify Operational management tasks. Some of these example are: List history of changes, execute Rollbacks, Undo deployment, Audit, etc. Additionally, offers a Dashboard with metrics and alerts.

- 🛠️ **Advanced Workflow Management**: Enables multiple streams of change units that can be organized to execute sequentially, in parallel, or as a combination, providing flexibility in managing complex processes.

- 🔀 **Parallel Synchronised Execution**: When workflows include parallel streams, they can be executed simultaneously by different service instances, maximizing efficiency in distributed deployments.

---

// File: overview/Editions

# Flamingock Editions
*Progressive investment path for enterprise distributed system evolution*

Flamingock provides a strategic investment path from open-source foundation to enterprise platform, ensuring you can start with essential safety guarantees and scale to full organizational transformation.

![](../../static/img/Diagrams-Editions.drawio.png)

## **🔹 Community Edition (Open Source)**
*Complete safety foundation for distributed system evolution*

**The Foundation**: All core safety guarantees and audit capabilities that make Flamingock unique.

### What You Get:
- **Safety-First Architecture**: MANUAL_INTERVENTION default strategy prevents silent data corruption
- **Complete Audit Trail**: Full execution history, compliance reporting, issue tracking
- **Intelligent Recovery**: Configurable strategies (MANUAL_INTERVENTION, ALWAYS_RETRY)
- **Enterprise-Grade CLI**: Issue resolution, audit management, rollback operations
- **Universal Target Support**: Databases, APIs, message queues, cloud services, SaaS platforms
- **Distributed Coordination**: Safe execution across clustered deployments

### Infrastructure:
- **Your Database**: MongoDB, DynamoDB, CosmosDB, or Couchbase as audit store
- **Self-Managed**: Full control over your audit and execution infrastructure
- **Extensible**: Driver architecture supports additional database integrations

### Ideal For:
- Teams requiring enterprise-grade safety without managed infrastructure
- Organizations with strong operational capabilities
- Development teams seeking autonomous change management
- Projects requiring complete audit trails and governance


## **☁️ Flamingock Cloud Edition**
*Enterprise platform for organizational transformation*

**Launch Timeline**: Early 2025 | **Beta Program**: Now accepting participants

### Three-Tier Value Proposition

#### **Foundation** (All Community Edition capabilities included)
- Complete safety guarantees and audit capabilities
- All recovery strategies and CLI operations
- Universal target system support with distributed coordination

#### **Enhanced Execution** (Same configuration, better outcomes)
- **Intelligent Automation**: Advanced reconciliation and marker mechanisms
- **Enhanced Recovery**: Automatic issue resolution for operations that would require manual intervention in Community Edition
- **Smart Retry Logic**: Sophisticated backoff and circuit breaker patterns
- **Cross-System Coordination**: Advanced transaction protocols for distributed changes

#### **Enterprise Platform Features**
- **Real-Time Dashboards**: Executive visibility, team metrics, compliance reporting
- **Advanced RBAC**: Team-based access control, approval workflows, audit delegation
- **Multi-Environment Management**: Coordinated rollouts, environment promotion, configuration drift detection  
- **Enterprise Integrations**: SSO, LDAP, external audit systems, notification platforms
- **SLA Guarantees**: Committed uptime, support response times, data durability
- **Compliance Automation**: Regulatory reporting, policy enforcement, audit trail management

### **Strategic Investment Path**
**"Same safety foundations → Enhanced automatic outcomes → Enterprise platform capabilities"**

Start with Community Edition's complete safety guarantees, then enhance with Cloud's automatic resolution and enterprise features. Your configurations and change definitions remain unchanged - Cloud Edition amplifies their effectiveness.

### **Join the Beta Program**
:::tip **Early Access Available**
Flamingock Cloud Edition beta program is accepting enterprise participants.

**What you get:**
- Early access to enterprise platform features
- Direct influence on product roadmap and prioritization  
- Dedicated technical support and onboarding assistance
- Grandfathered pricing for early adopters

**Contact**: support@flamingock.io with "Cloud Beta Program" in the subject line
:::


## **💎 Flamingock Self-Hosted Edition**
*Cloud platform capabilities in your infrastructure*

**Status**: Available by request for enterprise customers

### What You Get:
All Flamingock Cloud Edition capabilities deployed and managed within your infrastructure:

- **Full Cloud Platform Features**: Dashboards, RBAC, multi-environment management
- **Your Infrastructure**: Complete data sovereignty and infrastructure control  
- **Enterprise Security**: Meets stringent compliance requirements for regulated industries
- **Custom Integrations**: Tailored integrations with your existing enterprise systems

### Ideal For:
- **Regulated Industries**: Financial services, healthcare, government requiring data sovereignty
- **Enterprise Security**: Organizations with strict infrastructure and data policies
- **Custom Requirements**: Teams needing specialized integrations or compliance features
- **Hybrid Architectures**: Organizations requiring both cloud and on-premises capabilities

:::info **Enterprise Availability**
Flamingock Self-Hosted Edition is available by request for qualifying enterprise customers.

**Requirements**: Enterprise contract, dedicated technical onboarding, infrastructure requirements assessment

**Contact**: support@flamingock.io with "Self-Hosted Edition" in the subject line
:::

---

## **Choosing Your Edition**

| Need | Community Edition | Cloud Edition | Self-Hosted |
|------|------------------|---------------|-------------|
| **Enterprise Safety** | ✅ Complete | ✅ Enhanced | ✅ Enhanced |
| **Audit & Compliance** | ✅ Full capabilities | ✅ Advanced automation | ✅ Advanced + sovereignty |
| **Team Collaboration** | CLI-based | ✅ Platform features | ✅ Platform features |
| **Multi-Environment** | Manual coordination | ✅ Automated | ✅ Automated |
| **Infrastructure Management** | Self-managed | Fully managed | Self-managed |
| **Data Sovereignty** | ✅ Your control | Flamingock managed | ✅ Your control |

**Start your journey**: [Community Edition](../getting-started/get-started.md) → [Cloud Beta Program](#join-the-beta-program) → [Enterprise Self-Hosted](#flamingock-self-hosted-edition)

---

// File: overview/core-concepts

# Core concepts

### ChangeUnits
**ChangeUnits** are the fundamental building blocks of Flamingock's Change-as-Code architecture. They represent atomic, versioned changes applied to target systems with complete safety guarantees and audit capabilities.

Each ChangeUnit includes:
- **Unique identity**: ID, order, and metadata for tracking
- **Target system**: Where the changes is applied to
- **Execution logic**: The actual change implementation
- **Rollback capability**: Compensation logic for governance and undo operations
- **Recovery strategy**: Configurable behavior for handling failures

ChangeUnits can be implemented in two forms:
- **Code-based**: Java classes with annotations that contain the change logic
- **Template-based**: Declarative low-code approach using YAML configurations

For a deeper dive around ChangeUnits, see the [ChangeUnits deep dive](../flamingock-library-config/changeunits-deep-dive.md) section.

---

### Templates
Templates provide a reusable layer on top of ChangeUnits for common change patterns. When you have multiple changes that share similar logic (for example, executing SQL statements), templates allow you to abstract that common logic and reuse it.

With templates, you create multiple ChangeUnits using a declarative, low-code approach. Each ChangeUnit uses a template and passes its specific configuration. For example, an SQL template receives the SQL statement as configuration, executes it, and handles errors consistently.

This approach is particularly useful for:
- Standardizing common operations across your codebase
- Reducing boilerplate code
- Enabling non-developers to define changes through configuration

For more information about templates, see the [Templates](../templates/templates-introduction.md) section.

---

## Recovery strategies

Recovery strategies define how Flamingock responds when a ChangeUnit fails during execution. They determine whether the system should stop and wait for manual intervention or automatically retry the operation.

Flamingock provides two main strategies:
- **Manual intervention** (default): Stops execution and requires human review when failures occur
- **Always retry**: Automatically retries the change on the next execution attempt

The choice of strategy depends on whether your changes are idempotent and how critical they are to your system's integrity.

For detailed configuration and implementation, see the [Recovery configuration](../flamingock-library-config/recovery-configuration.md) section.

---

## Audit store
The **audit store** is where Flamingock records metadata about change executions. Its purpose is to track which ChangeUnits have been executed, when they ran, and their outcomes. This ensures idempotency, enables rollbacks, and provides audit capabilities. The audit store is managed entirely by Flamingock - your code never directly interacts with it.

## Target system  
The **target system** is where your actual business changes are applied. These are the systems your ChangeUnits modify - databases, message queues, APIs, configuration services, etc. Each ChangeUnit declares which target system it operates on.

For more details about how these systems work together, see the [Audit store vs target system](../overview/audit-store-vs-target-system.md) section.

---

## Transaction handling
Flamingock adapts its behavior based on the transactional capabilities of your target systems:

### Transactional target systems
Systems like PostgreSQL, MySQL, or MongoDB 4.0+ that support ACID transactions. When working with these systems, Flamingock can leverage native transaction support to ensure atomicity of changes. If a failure occurs mid-execution, the native rollback mechanism ensures no partial changes are left in the system.

### Non-transactional target systems
Systems like Kafka, S3, REST APIs, or file systems that don't support transactions. For these systems, Flamingock relies on explicit rollback methods and careful change design to maintain consistency. Recovery strategies become particularly important for handling failures in non-transactional contexts.

For implementation details, see the [Transactions](../flamingock-library-config/transactions.md) section.

---

## Stages
Stages organize your changes into logical groups within Flamingock's execution pipeline. By default, you work with a single stage that contains all your changes, ensuring they execute sequentially in a deterministic order.

Key characteristics:
- Changes within a stage execute sequentially with guaranteed order
- Most applications only need a single stage
- Multiple stages can be used for modular architectures, but execution order between stages is not guaranteed
- Each stage defines where to find its changes (package or directory location)

For detailed information about stages and advanced configurations, see the [Setup and stages](../flamingock-library-config/setup-and-stages.md) section.

---

## Events
Flamingock can notify your application about the execution status of changes through events. This enables integration with monitoring systems, custom logging, or triggering downstream processes based on change completion.

For more information about events, see the [Events](../flamingock-library-config/events.md) section.

---

// File: overview/technical-overview

# Flamingock Technical Overview

Welcome to the **Technical Overview** of Flamingock — a flexible framework designed to help you manage and audit changes of any kind across your systems and services.

Building on the foundations of Mongock, Flamingock goes beyond traditional database migrations to support a wide range of change types, including data updates, configuration adjustments, API evolutions, and system integrations — all with a consistent, traceable, and repeatable approach.

This document introduces Flamingock’s core concepts and outlines its architecture to help you understand how it simplifies the orchestration of system changes.

---

## Architectural Overview

In a nutshell, the Flamingock process takes all the pending changes and executes them in order during your Application startup process.

1. **Application Startup**  → Initializes the **Runner**.
2. **Runner** scans and loads all registered **ChangeUnits**.
3. **Drivers** communicate with an underlying component that varies by edition.
   - In Flamingock CE, this component is a simple storage layer (e.g., MongoDB, DynamoDB).
   - In the Cloud and Self-Hosted editions, the driver connects to a more sophisticated Flamingock backend that includes orchestration, auditing, and support for advanced operational features.
4. **ChangeUnits** execute in a coordinated **workflow**, optionally using templates.
5. **Distributed Locking** ensures safe execution in distributed environments.
6. All executions are **audited** and can be **rolled backed**.

Flamingock is designed to either apply all defined changes successfully or fail early. On the next run, it will resume from the last failed change.

![Flamingock Architecture Diagram](../../static/img/Flamingock%20Arch%20HLD.png)

### A more detailed process steps
Flamingock process follows the next steps:

1. The runner/builder loads the pipeline of execution of changes.
2. The runner loads the files storing the changes desired (changeUnits).
3. The runner checks if there is pending change to execute.
4. The runner acquires the distributed lock through the driver.
5. The runner loops over the ChangeUnits (change files) in order.
6. Takes the next ChangeUnit and executes it.
- If the ChangeUnit is successfully executed, Flamingock persists an entry in the Flamingock change history with the state SUCCESS and start the step 5 again.
- If the ChangeUnit fails, the runner rolls back the change. If the driver supports transactions and transactions are enabled, the rollback is done natively. When the driver does not support transactions or transactions are disabled, the method @RollbackExecution is executed. In both cases the ChangeUnit failed, whereas in the latter option, and entry is added in the changelog that a change has been rolled back.
- If the runner acomplished to execute the entire migration with no failures, it's considered successful. It releases the lock and finishes the migration.
On the other hand, if any ChangeUnit fails, the runner stops the migration at that point and throws an exception. When Flamingock is executed again, it will continue from the failure ChangeUnit(included).

---

// File: overview/audit-store-vs-target-system

# Target Systems vs Audit Store
*Understanding Flamingock's dual-system design for enterprise safety*

Flamingock's architecture separates business changes from execution tracking through two distinct system types. This separation is fundamental to Flamingock's safety guarantees and competitive advantages.

---

## The Dual-System Architecture

### Target Systems: Where Changes Are Applied
**Target Systems** are your business systems where actual changes happen:

- **Examples**: User database, Product catalog, Order management system, Kafka topics, S3 buckets, REST APIs
- **Purpose**: Store and process your business data and configurations
- **Modified by**: Your business logic through ChangeUnits
- **Configuration**: See [Target System Configuration](../flamingock-library-config/target-system-configuration.md) for technical setup

### Audit Store: Where Execution Is Tracked  
**Audit Store** is Flamingock's dedicated system for tracking what happened:

- **Examples**: Flamingock Cloud backend or dedicated audit table/collection in the user's database. 
- **Purpose**: Record execution history, compliance data, issue tracking
- **Modified by**: Flamingock framework automatically (never your code)
- **Configuration**: See [Audit Store Configuration](../flamingock-library-config/audit-store-configuration.md) for technical setup

---

## Why This Separation Matters

### Enterprise Safety Benefits
1. **Complete Audit Trail**: Every change attempt is recorded regardless of business system failures
2. **Governance Separation**: Business data and compliance data have different access patterns
3. **Recovery Capabilities**: Operations team can resolve issues by reading audit state, not business data
4. **Compliance Independence**: Audit integrity is maintained even during business system issues

---

## Target System Types

### Transactional Target Systems
Systems with native ACID transaction support (PostgreSQL, MySQL, MongoDB 4.0+):

**Safety and Coordination:**
- **Community Edition**: Reliable execution tracking and recovery capabilities
- **Cloud Edition**: Advanced coordination protocols ensure complete recoverability

### Non-Transactional Target Systems
Systems without native transaction support (Kafka, S3, REST APIs, File Systems):

**Safety and Coordination:**
- **Community Edition**: Reliable execution tracking and rollback-based recovery
- **Cloud Edition**: Enhanced recoverability with custom validation options

---

## How It Works

```
     Your ChangeUnits:
     ┌──────────────────────────────────────────────────────────────────────────┐
     │ 1. Change[UpdateKafkaSchema] → Target System[Kafka Schema Registry]      │
     │ 2. Change[SeedKafkaEvents]   → Target System[Kafka Topics]               │
     │ 3. Change[AddUserStatus]     → Target System[User Database]              │
     └──────────────────────────────────────────────────────────────────────────┘
                                │
                                ▼
                    ┌───────────────────────┐
                    │      Flamingock       │
                    │    (Orchestrator)     │
                    └───────────────────────┘
                                │
                                │ Executes sequentially
                                │
                 ChangeUnit #1  │───────────────────────────┐
            (UpdateKafkaSchema) │                           │
                                │                           │
                                │             ┌─────────────┴────────────┐
                                │             ▼                          ▼
                                │     ┌─────────────────────┐      ┌──────────────┐
                                │     │   Target System:    │      │ Audit Store  │
                                │     │ ┌─────────────────┐ │      │              │
                                │     │ │ Schema Registry │ │      │   Records:   │
                                │     │ └─────────────────┘ │      │ #1 applied   │
                                │     │  (applies change)   │      │              │
                                │     └─────────────────────┘      └──────────────┘
                                │
                                │
                  ChangeUnit #2 │───────────────────────────┐
              (SeedKafkaEvents) │                           │
                                │                           │
                                │             ┌─────────────┴────────────┐
                                │             ▼                          ▼
                                │     ┌─────────────────────┐      ┌──────────────┐
                                │     │   Target System:    │      │ Audit Store  │
                                │     │ ┌─────────────────┐ │      │              │
                                │     │ │  Kafka Topics   │ │      │   Records:   │
                                │     │ └─────────────────┘ │      │ #2 applied   │
                                │     │  (applies change)   │      │              │
                                │     └─────────────────────┘      └──────────────┘
                                │
                                │
                  ChangeUnit #3 └───────────────────────────┐
                (AddUserStatus)                             │
                                                            │
                                              ┌─────────────┴────────────┐
                                              ▼                          ▼
                                      ┌─────────────────────┐      ┌──────────────┐
                                      │   Target System:    │      │ Audit Store  │
                                      │ ┌─────────────────┐ │      │              │
                                      │ │  User Database  │ │      │   Records:   │
                                      │ └─────────────────┘ │      │ #3 applied   │
                                      │  (applies change)   │      │              │
                                      └─────────────────────┘      └──────────────┘
                                
```

**The Flow:**
1. **You create ChangeUnits** - Define what changes need to happen
2. **Flamingock orchestrates** - Safely applies changes across all your systems  
3. **Target systems evolve** - Your business systems get updated
4. **Audit store tracks everything** - Complete history for compliance and recovery

---

## Key Takeaways

### For Developers
- **Target Systems**: Where your business logic runs and makes changes
- **Audit Store**: Automatically managed by Flamingock for tracking and compliance
- **Implementation**: See [Target System Configuration](../flamingock-library-config/target-system-configuration.md) and [Audit Store Configuration](../flamingock-library-config/audit-store-configuration.md)

### For Architects  
- **Clean Separation**: Business logic separated from execution tracking
- **Enterprise Scalability**: Architecture supports compliance, governance, multi-environment
- **Flexibility**: Works with any target system type (transactional, non-transactional, hybrid)

### For Operations
- **Issue Resolution**: Tools operate on audit store, you fix target systems
- **Compliance**: Complete audit trail independent of business system availability  
- **Recovery**: Always know the state, even during complex failure scenarios

**Bottom Line**: This dual-system architecture is what enables Flamingock to provide enterprise-grade safety and governance capabilities that traditional tools cannot match.

---

// File: recovery-and-safety/recovery-strategies

# Recovery Strategies
*Intelligent failure handling for enterprise distributed systems*

Flamingock's recovery strategies are a key differentiator from traditional tools. While others retry blindly or fail silently, Flamingock provides intelligent, configurable recovery based on operation characteristics.

---

## The Safety-First Philosophy

**Core Principle**: "When in doubt, stop and alert rather than corrupt data."

Traditional tools assume the "happy path" - they retry operations blindly or fail without context. This approach leads to:
- Silent data corruption
- Inconsistent system states  
- Difficult troubleshooting
- Compliance gaps

**Flamingock's Approach**: Configurable recovery strategies that match your operation's risk profile.

---

## Recovery Strategy Types

### MANUAL_INTERVENTION (Default)
**Philosophy**: "Safety first - human judgment for uncertain situations."

```java
@TargetSystem("financial-database")
@ChangeUnit(id = "process-payments", order = "001", author = "finance-team")
// No @Recovery annotation = MANUAL_INTERVENTION default
public class ProcessPayments {
    
    @Execution
    public void execute(MongoDatabase financialDb) {
        // Critical financial operations
        // Any failure requires manual review to ensure data integrity
        financialDb.getCollection("payments")
                  .updateMany(eq("status", "pending"), 
                             combine(set("status", "processed"),
                                   set("processedAt", new Date())));
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase financialDb) {
        // Financial rollback requires careful manual oversight
        financialDb.getCollection("payments")
                  .updateMany(eq("status", "processed"),
                             combine(set("status", "pending"),
                                   unset("processedAt")));
    }
}
```

**When It Activates**: Any failure where system state is uncertain
**What Happens**:
1. Execution stops immediately
2. Issue logged with detailed context
3. Human review required via CLI
4. Complete audit trail maintained

**Best For**:
- Financial transactions
- User data modifications
- Critical business logic
- Non-idempotent operations
- Compliance-sensitive changes

### ALWAYS_RETRY  
**Philosophy**: "Keep trying until successful - for operations we know are safe."

```java
@TargetSystem("user-cache")
@ChangeUnit(id = "warm-user-cache", order = "002", author = "platform-team")
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
public class WarmUserCache {
    
    @Execution
    public void execute(RedisTemplate redis, UserService userService) {
        // Idempotent cache warming - safe to repeat
        List<User> activeUsers = userService.findActiveUsers();
        for (User user : activeUsers) {
            String cacheKey = "user:" + user.getId();
            UserProfile profile = userService.getUserProfile(user.getId());
            redis.opsForValue().set(cacheKey, profile, Duration.ofHours(24));
        }
    }
    
    @RollbackExecution
    public void rollback(RedisTemplate redis) {
        // Clear cache - used for CLI undo operations
        redis.delete("user:*");
    }
}
```

**When It Activates**: Any failure, regardless of cause
**What Happens**:
1. Failure is logged
2. Automatic retry on next execution
3. Continues until successful
4. No manual intervention required

**Best For**:
- Cache warming operations
- Idempotent API calls  
- Event publishing (with consistent keys)
- Configuration updates
- Index creation
- File operations with overwrite

---

## Decision Framework

### Is Your Operation Idempotent?
**Idempotent**: Running multiple times produces same result as running once
- ✅ Cache SET operations
- ✅ Database UPSERT operations
- ✅ File overwrites
- ✅ CREATE IF NOT EXISTS operations
- ❌ Increment/decrement operations
- ❌ Append operations
- ❌ Time-sensitive operations

### Risk Assessment Matrix

| Operation Risk | Data Criticality | Recovery Strategy |
|---------------|------------------|-------------------|
| **High** | **High** | MANUAL_INTERVENTION |
| **High** | **Low** | MANUAL_INTERVENTION |
| **Low** | **High** | MANUAL_INTERVENTION |
| **Low** | **Low** | ALWAYS_RETRY (if idempotent) |

**Examples**:
- **High Risk + High Criticality**: Financial transactions, user authentication data
- **High Risk + Low Criticality**: Complex multi-step processes, dependency changes
- **Low Risk + High Criticality**: Simple user data updates, critical configuration
- **Low Risk + Low Criticality**: Cache operations, metrics collection

---

## Practical Implementation Patterns

### Pattern 1: Financial Operations
```java
@TargetSystem("payment-system")
@ChangeUnit(id = "process-refunds", order = "010", author = "finance-team")
// MANUAL_INTERVENTION default - no annotation needed
public class ProcessRefunds {
    
    @Execution
    public void execute(PaymentService paymentService) {
        // Critical financial operation - requires human oversight on failure
        List<RefundRequest> pendingRefunds = paymentService.getPendingRefunds();
        for (RefundRequest refund : pendingRefunds) {
            paymentService.processRefund(refund);
            auditService.logRefund(refund);
        }
    }
    
    @RollbackExecution
    public void rollback(PaymentService paymentService) {
        // Financial rollbacks require manual verification
        // This method used for CLI undo operations
    }
}
```

### Pattern 2: Infrastructure Setup
```java
@TargetSystem("messaging-infrastructure")
@ChangeUnit(id = "create-kafka-topics", order = "020", author = "platform-team",
           transactional = false)
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
public class CreateKafkaTopics {
    
    @Execution
    public void execute(KafkaAdminClient kafkaAdmin) {
        // Topic creation is idempotent - safe to retry
        List<NewTopic> topics = Arrays.asList(
            new NewTopic("user-events", 10, (short) 3),
            new NewTopic("order-events", 10, (short) 3)
        );
        kafkaAdmin.createTopics(topics);
    }
    
    @RollbackExecution
    public void rollback(KafkaAdminClient kafkaAdmin) {
        // Delete topics - used for CLI undo operations
        kafkaAdmin.deleteTopics(Arrays.asList("user-events", "order-events"));
    }
}
```

### Pattern 3: Conditional Logic Based on Environment
```java
@TargetSystem("user-database")
@ChangeUnit(id = "user-data-cleanup", order = "030", author = "data-team")
@Recovery(strategy = RecoveryStrategy.MANUAL_INTERVENTION)  // Explicit for clarity
public class UserDataCleanup {
    
    @Execution
    public void execute(MongoDatabase userDb, @Value("${environment}") String env) {
        if ("production".equals(env)) {
            // Production data cleanup requires manual oversight
            cleanupInactiveUsers(userDb);
        } else {
            // Non-production can be more aggressive
            cleanupAllTestData(userDb);
        }
    }
}
```

---

## Cloud Edition Enhanced Recovery

Cloud Edition uses the same recovery strategies but provides enhanced outcomes:

### Enhanced MANUAL_INTERVENTION
- **Automatic issue detection** with real-time alerts
- **Detailed diagnostic information** for faster resolution
- **Workflow automation** for common resolution patterns  
- **Team collaboration** features for complex issues

### Enhanced ALWAYS_RETRY
- **Intelligent retry backoff** prevents system overload
- **Circuit breaker patterns** prevent cascading failures
- **Automatic reconciliation** detects and resolves inconsistencies
- **Advanced monitoring** provides visibility into retry patterns

### Marker Mechanism (Cloud Edition)
For transactional systems, Cloud Edition uses sophisticated coordination:
1. **Intent markers** placed before execution
2. **State tracking** during execution
3. **Resolution markers** after completion
4. **Automatic recovery** based on marker state

This enables Cloud Edition to automatically resolve many issues that require manual intervention in Community Edition.

---

## Operational Workflows

### Issue Resolution Process
```bash
# 1. Detect issues
flamingock issue list
# Shows all changes requiring attention

# 2. Get next priority issue
flamingock issue get
# Returns detailed context and guidance

# 3. Investigate and resolve
# Review target system state
# Make necessary corrections
# Document resolution

# 4. Mark as resolved
flamingock audit fix -c change-id --resolution APPLIED
# or
flamingock audit fix -c change-id --resolution ROLLED_BACK
```

### Monitoring and Alerting
- **Issue detection**: Automated monitoring of failure states
- **Alert integration**: Connect to PagerDuty, Slack, email systems
- **Metrics tracking**: Success rates, failure patterns, resolution times
- **Dashboard visibility**: Real-time status across environments

---

## Best Practices

### **Start Conservative, Optimize Gradually**
1. Begin with MANUAL_INTERVENTION (default)
2. Monitor failure patterns and resolution outcomes
3. Identify truly idempotent operations
4. Gradually move appropriate changes to ALWAYS_RETRY

### **Design for Idempotency When Possible**
```java
// ✅ Idempotent design
users.updateMany(
    eq("status", "pending"),
    set("status", "processed")  // Same result regardless of repetition
);

// ❌ Non-idempotent design  
users.updateMany(
    eq("status", "pending"),
    inc("processCount", 1)  // Different result each time
);
```

### **Document Recovery Strategy Decisions**
```java
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)
// Document why: "Cache SET operations are idempotent and safe to retry"
@ChangeUnit(description = "Warm user profile cache - idempotent operation safe for automatic retry")
```

### **Test Both Strategies in Development**
- Simulate failures in lower environments
- Verify MANUAL_INTERVENTION workflow
- Validate ALWAYS_RETRY behavior
- Test rollback logic for both strategies

### **Enterprise Governance**
- **Policy definition**: Establish organization-wide guidelines
- **Code review**: Include recovery strategy in review process
- **Compliance documentation**: Maintain records of strategy decisions
- **Regular assessment**: Review and update strategies based on operational experience

---

**Key Takeaway**: Recovery strategies are not just error handling - they're a core architectural decision that affects operational safety, team productivity, and business risk. Choose wisely, document thoroughly, and evolve based on operational experience.

---

// File: recovery-and-safety/issue-resolution

# Issue Resolution
*Enterprise operational workflows for handling failures*

Flamingock's issue resolution system transforms how organizations handle distributed system evolution failures. Instead of guesswork and manual database queries, you get structured workflows, detailed guidance, and complete audit trails.

---

## Understanding Issues

### What Creates an Issue?
An "issue" is detected when:
1. **Change execution fails** during the `@Execution` method
2. **Change starts but never completes** (process crash, timeout)
3. **Rollback fails** during `@RollbackExecution` method
4. **Change needs to run again** but is in uncertain state

### Issue States
| State | Description | Action Required |
|-------|-------------|----------------|
| **STARTED** | Execution began but never completed | Manual investigation |
| **EXECUTION_FAILED** | `@Execution` method failed | Review and resolve |
| **ROLLBACK_FAILED** | `@RollbackExecution` method failed | Manual cleanup |

---

## CLI-Driven Resolution Workflow

### 1. Issue Discovery
```bash
flamingock issue list
```

**Example Output**:
```
ISSUES FOUND (3)
┌─────────────────────────┬─────────┬──────────────────┬──────────────┐
│ Change ID               │ State   │ Error            │ Target       │
├─────────────────────────┼─────────┼──────────────────┼──────────────┤
│ user-data-sync-v2       │ STARTED │ Connection lost  │ user-db      │
│ cache-warming-q4        │ FAILED  │ Redis timeout    │ redis-cache  │
│ payment-processing      │ FAILED  │ Validation error │ payment-api  │
└─────────────────────────┴─────────┴──────────────────┴──────────────┘

Use 'flamingock issue get' to process issues automatically, or
'flamingock issue get -c <change-id>' for specific issue details.
```

### 2. Automated Issue Triage
```bash
flamingock issue get
```

**What This Does**:
- Automatically selects the next priority issue
- Provides detailed context and diagnostic information
- Suggests resolution approaches based on failure type
- No need to copy/paste change IDs

**Example Output**:
```
ISSUE: user-data-sync-v2
Status: STARTED (execution began but never completed)
Target System: user-database
Author: platform-team
Started: 2024-01-15 14:32:15 UTC
Error: Connection lost during execution

DIAGNOSTIC INFORMATION:
- Change was modifying user profiles in MongoDB
- Execution started but connection dropped after 30 seconds
- No rollback was triggered (connection failure before completion)
- Potentially partial state in target system

RESOLUTION GUIDANCE:
1. Check target system state:
   - Query user-database for partially updated records
   - Look for users with incomplete profile updates
   - Check MongoDB logs for connection errors around 14:32:15 UTC

2. Determine actual state:
   - If no changes were applied → mark as APPLIED (safe to continue)
   - If changes were partially applied → complete manually, then mark APPLIED
   - If changes were fully applied → mark as APPLIED
   - If changes caused corruption → rollback manually, then mark ROLLED_BACK

3. Resolve the issue:
   flamingock audit fix -c user-data-sync-v2 --resolution APPLIED
   flamingock audit fix -c user-data-sync-v2 --resolution ROLLED_BACK

Next: flamingock issue get (to process next issue)
```

### 3. Manual Investigation

Based on the guidance, investigate the **target system** (not the audit store):

```bash
# Example: Check MongoDB for partial updates
mongo user-database --eval "
  db.users.find({
    profileUpdatedAt: { \$gte: ISODate('2024-01-15T14:30:00Z') },
    profileComplete: { \$ne: true }
  }).count()
"
```

### 4. Issue Resolution

After investigation, mark the issue as resolved:

```bash
# If changes were successfully applied (or completed manually)
flamingock audit fix -c user-data-sync-v2 --resolution APPLIED

# If changes were rolled back (or need to be skipped)
flamingock audit fix -c user-data-sync-v2 --resolution ROLLED_BACK
```

**Success Output**:
```
✅ Issue resolved successfully
   Change: user-data-sync-v2
   Resolution: APPLIED
   Audit State: MANUAL_MARKED_AS_EXECUTED
   Next Execution: Will skip this change (marked as completed)
```

---

## Resolution Types

### APPLIED Resolution
**When to use**:
- Changes were successfully applied to target system
- Partial changes were completed manually
- Change should be marked as "done"

**Effect**:
- Updates audit store to `MANUAL_MARKED_AS_EXECUTED`
- Future executions will skip this change
- Maintains audit trail of manual resolution

```bash
flamingock audit fix -c change-id --resolution APPLIED
```

### ROLLED_BACK Resolution  
**When to use**:
- Changes were rolled back from target system
- Changes caused issues and were reverted
- Change should be marked as "undone"

**Effect**:
- Updates audit store to `MANUAL_MARKED_AS_ROLLED_BACK`
- Future executions will attempt to run this change again
- Enables retry after fixing underlying issues

```bash
flamingock audit fix -c change-id --resolution ROLLED_BACK
```

---

## Advanced Resolution Scenarios

### Scenario 1: Partial Multi-System Update
```
Issue: user-profile-sync failed
Target Systems: user-database, elasticsearch, redis-cache
Failure: Elasticsearch connection timeout after DB and cache updates
```

**Investigation**:
1. **Database**: Check if user profiles were updated
2. **Cache**: Verify cache entries were created  
3. **Elasticsearch**: Confirm no documents were indexed

**Resolution**:
```bash
# Manually sync remaining Elasticsearch documents
curl -X POST "elasticsearch:9200/users/_bulk" -H 'Content-Type: application/json' -d @user_updates.json

# Mark as successfully applied
flamingock audit fix -c user-profile-sync --resolution APPLIED
```

### Scenario 2: Failed DDL Operation
```
Issue: create-user-indexes failed
Target System: user-database  
Failure: Index creation failed due to duplicate key constraint
```

**Investigation**:
```bash
# Check which indexes were created before failure
mongo user-database --eval "db.users.getIndexes()"
```

**Resolution Options**:
```bash
# Option 1: Complete the index creation manually
mongo user-database --eval "db.users.createIndex({email: 1}, {unique: true, sparse: true})"
flamingock audit fix -c create-user-indexes --resolution APPLIED

# Option 2: Clean up partial indexes and retry later
mongo user-database --eval "db.users.dropIndex('partial_index_name')"
flamingock audit fix -c create-user-indexes --resolution ROLLED_BACK
```

### Scenario 3: External API Failure
```
Issue: notify-users-via-email failed
Target System: email-service-api
Failure: Email service returned 503 Service Unavailable
```

**Investigation**:
```bash
# Check email service logs
curl -X GET "https://email-service/api/v1/status"

# Check which emails were actually sent
curl -X GET "https://email-service/api/v1/notifications?batch=user-migration-2024"
```

**Resolution**:
```bash
# If emails were sent despite the error
flamingock audit fix -c notify-users-via-email --resolution APPLIED

# If no emails were sent and service is now available
flamingock audit fix -c notify-users-via-email --resolution ROLLED_BACK
# This allows automatic retry on next execution
```

---

## Enterprise Operational Patterns

### Daily Operations Checklist
```bash
#!/bin/bash
# Daily Flamingock health check script

echo "=== Flamingock Issues Check ==="
ISSUE_COUNT=$(flamingock issue list --format count 2>/dev/null || echo "0")

if [ "$ISSUE_COUNT" -gt 0 ]; then
    echo "⚠️  Found $ISSUE_COUNT issues requiring attention"
    echo "Run: flamingock issue get"
    
    # Optional: Send alert to ops team
    slack-notify "#ops-alerts" "Flamingock: $ISSUE_COUNT issues need resolution"
else
    echo "✅ No issues detected"
fi

echo "=== Recent Changes ==="
flamingock audit list --since yesterday --format summary
```

### Bulk Issue Resolution
```bash
#!/bin/bash
# Process all issues interactively

while flamingock issue get --exists; do
    echo "=== Processing Next Issue ==="
    flamingock issue get
    
    echo ""
    echo "Actions:"
    echo "1. Mark as APPLIED (changes were successful)"  
    echo "2. Mark as ROLLED_BACK (changes were reverted)"
    echo "3. Skip (investigate manually later)"
    echo ""
    
    read -p "Choose action (1/2/3): " choice
    
    case $choice in
        1)
            CHANGE_ID=$(flamingock issue get --format id)
            flamingock audit fix -c "$CHANGE_ID" --resolution APPLIED
            echo "✅ Marked as APPLIED"
            ;;
        2)
            CHANGE_ID=$(flamingock issue get --format id)
            flamingock audit fix -c "$CHANGE_ID" --resolution ROLLED_BACK
            echo "✅ Marked as ROLLED_BACK"
            ;;
        3)
            echo "⏭️  Skipped - investigate manually"
            break
            ;;
        *)
            echo "Invalid choice"
            ;;
    esac
    
    echo ""
done

echo "✅ All issues processed"
```

### Integration with Monitoring Systems
```yaml
# Example: Prometheus alerting rule
groups:
- name: flamingock
  rules:
  - alert: FlamingockIssuesDetected
    expr: flamingock_unresolved_issues > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Flamingock issues require attention"
      description: "{{ $value }} unresolved issues in Flamingock"
      runbook_url: "https://wiki.company.com/flamingock-issue-resolution"
```

```bash
# Custom metrics collection script
#!/bin/bash
ISSUE_COUNT=$(flamingock issue list --format count 2>/dev/null || echo "0")
echo "flamingock_unresolved_issues $ISSUE_COUNT" | curl -X POST --data-binary @- http://pushgateway:9091/metrics/job/flamingock
```

---

## Best Practices

### **Investigate Target Systems, Not Audit Store**
- ❌ `SELECT * FROM changeLog WHERE id = 'change-id'`
- ✅ Check actual business data in target systems
- ✅ Use application logs and system metrics
- ✅ Verify intended business outcomes

### **Document Resolution Decisions**
```bash
# Add documentation when resolving
flamingock audit fix -c user-migration --resolution APPLIED \
  --notes "Verified all users updated successfully. Connection timeout was transient."

# Or maintain a resolution log
echo "$(date): user-migration APPLIED - connection timeout, data verified complete" >> /var/log/flamingock-resolutions.log
```

### **Establish Resolution SLAs**
- **Critical issues**: Resolve within 4 hours
- **Standard issues**: Resolve within 24 hours
- **Non-critical issues**: Resolve within 72 hours

### **Team Responsibilities**
- **Development team**: Create runbooks for their changes
- **Operations team**: Daily issue monitoring and basic resolution
- **Subject matter experts**: Complex issue investigation and resolution
- **Management**: Escalation procedures for critical failures

### **Automation Where Appropriate**
```bash
# Example: Auto-resolve known transient failures
#!/bin/bash
for issue in $(flamingock issue list --format id --filter "error:ConnectionTimeout"); do
    # Check if target system is healthy now
    if ping -c 1 target-database >/dev/null 2>&1; then
        echo "Auto-resolving transient connection issue: $issue"
        flamingock audit fix -c "$issue" --resolution ROLLED_BACK --notes "Auto-resolved: transient connection issue"
    fi
done
```

### **Compliance and Audit Requirements**
- Maintain records of all manual resolutions
- Document investigation process and findings
- Establish approval workflows for critical system changes
- Regular review of resolution patterns for process improvement

---

## Troubleshooting Common Issues

### "No issues found" but changes are stuck
```bash
# Check if changes are actually failing or just slow
flamingock audit list --status STARTED --since "1 hour ago"

# Check application logs for execution context
tail -f /var/log/app/flamingock.log | grep "EXECUTION"
```

### CLI returns "connection error"
```bash
# Verify CLI configuration
flamingock config verify

# Check network connectivity to audit store
telnet audit-database-host 27017
```

### Resolution doesn't take effect
```bash
# Verify resolution was recorded
flamingock audit list -c change-id --format detailed

# Check for configuration issues
flamingock consistency-check
```

---

**Key Takeaway**: Issue resolution is not just error handling - it's a structured operational discipline that ensures your distributed systems evolve safely and your team can respond confidently to any failure scenario.

---

// File: recovery-and-safety/safety-patterns

# Safety Patterns
*Proven approaches for enterprise-grade distributed system evolution*

This guide presents battle-tested patterns that ensure safe, reliable system evolution in production environments. These patterns have been refined through real-world enterprise deployments and operational experience.

---

## Core Safety Principles

### 1. **Explicit is Better Than Implicit**
Always be explicit about your intentions and system boundaries.

```java
// ✅ Explicit and clear
@TargetSystem("user-database")  // Clear target
@ChangeUnit(id = "user-status-update", transactional = true)  // Explicit transaction control
@Recovery(strategy = RecoveryStrategy.MANUAL_INTERVENTION)  // Explicit strategy
public class UserStatusUpdate { }

// ❌ Implicit and unclear  
@ChangeUnit(id = "update")  // Unclear intent
public class Update { }  // No target, relies on defaults
```

### 2. **Design for Failure**
Every change should anticipate and handle failure scenarios.

```java
@TargetSystem("payment-system")
@ChangeUnit(id = "process-payment-batch", order = "001", author = "finance-team")
public class ProcessPaymentBatch {
    
    @Execution
    public void execute(PaymentService paymentService) {
        List<Payment> pendingPayments = paymentService.getPendingPayments();
        
        for (Payment payment : pendingPayments) {
            try {
                paymentService.processPayment(payment);
                // Mark individual payment as processed for granular tracking
                paymentService.markAsProcessed(payment.getId());
            } catch (PaymentException e) {
                // Log failure but continue with other payments
                logger.error("Failed to process payment {}: {}", payment.getId(), e.getMessage());
                paymentService.markAsFailed(payment.getId(), e.getMessage());
            }
        }
    }
    
    @RollbackExecution
    public void rollback(PaymentService paymentService) {
        // Rollback only successfully processed payments
        List<Payment> processedPayments = paymentService.getProcessedPayments();
        for (Payment payment : processedPayments) {
            paymentService.revertPayment(payment);
        }
    }
}
```

### 3. **Idempotency by Design**
When possible, design operations to be naturally idempotent.

```java
// ✅ Idempotent by design
@TargetSystem("user-database")
@ChangeUnit(id = "set-user-preferences", author = "product-team")
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)  // Safe because idempotent
public class SetUserPreferences {
    
    @Execution
    public void execute(MongoDatabase userDb) {
        // SET operations are naturally idempotent
        userDb.getCollection("users")
              .updateMany(
                  new Document(), // All users
                  new Document("$set", new Document("preferences", defaultPreferences()))
              );
    }
}

// ❌ Non-idempotent design
public class IncrementUserScores {
    @Execution
    public void execute(MongoDatabase userDb) {
        // INCREMENT is not idempotent - each run changes the result
        userDb.getCollection("users")
              .updateMany(new Document(), new Document("$inc", new Document("score", 10)));
    }
}
```

---

## Enterprise Safety Patterns

### Pattern 1: Critical Path Protection
**Use Case**: Financial operations, user authentication, compliance-sensitive changes

```java
@TargetSystem("financial-database")
@ChangeUnit(id = "update-account-balances", order = "001", author = "finance-team",
           transactional = true)  // Leverage database transactions
// MANUAL_INTERVENTION default - explicit safety
public class UpdateAccountBalances {
    
    @Execution
    public void execute(MongoDatabase financialDb, AuditLogger auditLogger) {
        MongoCollection<Document> accounts = financialDb.getCollection("accounts");
        
        // Pre-execution validation
        long totalBefore = calculateTotalBalance(accounts);
        auditLogger.logBalanceSnapshot("before", totalBefore);
        
        // Critical financial operation
        accounts.updateMany(
            eq("status", "pending_interest"), 
            combine(
                set("status", "interest_applied"),
                inc("balance", calculateInterest()),
                set("lastInterestDate", new Date())
            )
        );
        
        // Post-execution validation
        long totalAfter = calculateTotalBalance(accounts);
        auditLogger.logBalanceSnapshot("after", totalAfter);
        
        // Invariant check
        if (Math.abs(totalAfter - totalBefore - expectedInterestTotal()) > 0.01) {
            throw new BalanceInconsistencyException("Total balance invariant violated");
        }
    }
    
    @RollbackExecution  
    public void rollback(MongoDatabase financialDb, AuditLogger auditLogger) {
        auditLogger.logRollbackStart("update-account-balances");
        
        MongoCollection<Document> accounts = financialDb.getCollection("accounts");
        accounts.updateMany(
            eq("status", "interest_applied"),
            combine(
                set("status", "pending_interest"),
                inc("balance", -calculateInterest()),
                unset("lastInterestDate")
            )
        );
        
        auditLogger.logRollbackComplete("update-account-balances");
    }
}
```

### Pattern 2: Idempotent Operations with Retry
**Use Case**: Cache warming, event publishing, infrastructure setup

```java
@TargetSystem("messaging-infrastructure")
@ChangeUnit(id = "setup-kafka-topics", order = "002", author = "platform-team",
           transactional = false)  // External system calls
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)  // Safe to retry
public class SetupKafkaTopics {
    
    @Execution
    public void execute(KafkaAdminClient kafkaAdmin) {
        List<NewTopic> requiredTopics = Arrays.asList(
            new NewTopic("user-events", 10, (short) 3),
            new NewTopic("order-events", 15, (short) 3),
            new NewTopic("notification-events", 5, (short) 3)
        );
        
        // Get existing topics to avoid creating duplicates
        Set<String> existingTopics = kafkaAdmin.listTopics().names().get();
        
        List<NewTopic> topicsToCreate = requiredTopics.stream()
            .filter(topic -> !existingTopics.contains(topic.name()))
            .collect(Collectors.toList());
        
        if (!topicsToCreate.isEmpty()) {
            // Topic creation is idempotent - safe to retry
            kafkaAdmin.createTopics(topicsToCreate).all().get();
            logger.info("Created {} new topics: {}", 
                       topicsToCreate.size(), 
                       topicsToCreate.stream().map(NewTopic::name).collect(Collectors.toList()));
        } else {
            logger.info("All required topics already exist");
        }
    }
    
    @RollbackExecution
    public void rollback(KafkaAdminClient kafkaAdmin) {
        // For infrastructure setup, rollback usually means cleanup
        List<String> topicNames = Arrays.asList("user-events", "order-events", "notification-events");
        kafkaAdmin.deleteTopics(topicNames);
    }
}
```

### Pattern 3: Progressive Migration  
**Use Case**: Large-scale data transformations, phased rollouts

```java
@TargetSystem("user-database")
@ChangeUnit(id = "migrate-user-profiles-batch-1", order = "003", author = "data-team",
           transactional = false)  // Large operation, process in batches
public class MigrateUserProfilesBatch1 {
    
    private static final int BATCH_SIZE = 1000;
    private static final String MIGRATION_MARKER = "profile_v2_migration";
    
    @Execution
    public void execute(MongoDatabase userDb) {
        MongoCollection<Document> users = userDb.getCollection("users");
        
        // Process only users without migration marker (idempotent)
        FindIterable<Document> unmigrated = users.find(
            and(
                exists("profileVersion", false),  // Old schema
                exists(MIGRATION_MARKER, false)   // Not yet processed
            )
        ).limit(BATCH_SIZE);
        
        int processed = 0;
        for (Document user : unmigrated) {
            try {
                // Transform user profile to new schema
                Document newProfile = transformProfile(user);
                
                users.updateOne(
                    eq("_id", user.getObjectId("_id")),
                    combine(
                        set("profile", newProfile),
                        set("profileVersion", 2),
                        set(MIGRATION_MARKER, new Date())  // Mark as processed
                    )
                );
                processed++;
                
            } catch (Exception e) {
                logger.error("Failed to migrate user {}: {}", user.getObjectId("_id"), e.getMessage());
                // Mark this user as failed for separate handling
                users.updateOne(
                    eq("_id", user.getObjectId("_id")),
                    set("migrationError", e.getMessage())
                );
            }
        }
        
        logger.info("Migrated {} user profiles in this batch", processed);
        
        // Check if more batches are needed
        long remaining = users.countDocuments(
            and(
                exists("profileVersion", false),
                exists(MIGRATION_MARKER, false),
                exists("migrationError", false)  // Exclude failed ones
            )
        );
        
        if (remaining > 0) {
            logger.info("{} users remaining for migration", remaining);
        } else {
            logger.info("User profile migration completed successfully");
        }
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase userDb) {
        MongoCollection<Document> users = userDb.getCollection("users");
        
        // Rollback users that were migrated in this execution
        users.updateMany(
            exists(MIGRATION_MARKER),
            combine(
                unset("profile"),
                unset("profileVersion"), 
                unset(MIGRATION_MARKER),
                unset("migrationError")
            )
        );
    }
}
```

### Pattern 4: Multi-System Coordination
**Use Case**: Distributed system synchronization, event sourcing, complex workflows

```java
@TargetSystem("user-database")  // Primary system
@ChangeUnit(id = "sync-user-data-across-systems", order = "004", author = "integration-team",
           transactional = false)  // Multi-system can't be transactional
public class SyncUserDataAcrossSystems {
    
    @Execution
    public void execute(MongoDatabase userDb, 
                       ElasticsearchOperations searchOps,
                       KafkaTemplate<String, Object> eventPublisher,
                       RedisTemplate<String, Object> cacheOps) {
        
        // Get users that need synchronization
        List<User> usersToSync = findUsersNeedingSync(userDb);
        List<String> processedUsers = new ArrayList<>();
        
        try {
            for (User user : usersToSync) {
                // Step 1: Update primary database
                updateUserInDatabase(userDb, user);
                
                // Step 2: Update search index  
                indexUserInElasticsearch(searchOps, user);
                
                // Step 3: Update cache
                updateUserInCache(cacheOps, user);
                
                // Step 4: Publish change event
                publishUserChangeEvent(eventPublisher, user);
                
                // Track successful processing
                processedUsers.add(user.getId());
                
                // Mark user as synchronized
                markUserAsSynced(userDb, user.getId());
            }
            
        } catch (Exception e) {
            logger.error("Multi-system sync failed for user batch. Processed: {}. Error: {}", 
                        processedUsers.size(), e.getMessage());
            
            // Store progress information for rollback
            storeProcessingProgress(userDb, processedUsers);
            throw e;  // Re-throw to trigger rollback
        }
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase userDb,
                        ElasticsearchOperations searchOps,
                        KafkaTemplate<String, Object> eventPublisher, 
                        RedisTemplate<String, Object> cacheOps) {
        
        // Get list of users that were processed before failure
        List<String> processedUsers = getProcessingProgress(userDb);
        
        for (String userId : processedUsers) {
            try {
                // Reverse each step in opposite order
                publishUserRollbackEvent(eventPublisher, userId);
                removeUserFromCache(cacheOps, userId);
                removeUserFromElasticsearch(searchOps, userId);
                rollbackUserInDatabase(userDb, userId);
                
            } catch (Exception e) {
                logger.error("Failed to rollback user {}: {}", userId, e.getMessage());
                // Continue with other users - partial rollback is better than none
            }
        }
        
        // Clean up progress tracking
        clearProcessingProgress(userDb);
    }
}
```

---

## Operational Safety Patterns

### Pattern 5: Environment-Aware Changes
**Use Case**: Different behavior across environments, gradual rollouts

```java
@TargetSystem("feature-flags")
@ChangeUnit(id = "enable-new-checkout", order = "005", author = "product-team")
@Recovery(strategy = RecoveryStrategy.ALWAYS_RETRY)  // Feature flags are idempotent
public class EnableNewCheckout {
    
    @Execution
    public void execute(FeatureFlagService flagService, 
                       @Value("${spring.profiles.active}") String environment) {
        
        FeatureFlagConfig config = buildConfigForEnvironment(environment);
        
        switch (environment) {
            case "development":
                // Full rollout in dev
                flagService.enableFlag("new-checkout", config.withRollout(100));
                break;
                
            case "staging":  
                // Full rollout in staging
                flagService.enableFlag("new-checkout", config.withRollout(100));
                break;
                
            case "production":
                // Gradual rollout in production
                flagService.enableFlag("new-checkout", config.withRollout(5));  // Start with 5%
                break;
                
            default:
                logger.warn("Unknown environment: {}. Skipping feature flag change.", environment);
        }
    }
    
    @RollbackExecution
    public void rollback(FeatureFlagService flagService) {
        flagService.disableFlag("new-checkout");
    }
}
```

### Pattern 6: Validation and Verification
**Use Case**: Critical changes requiring validation, compliance requirements

```java
@TargetSystem("compliance-database")
@ChangeUnit(id = "update-gdpr-consent", order = "006", author = "legal-team")
public class UpdateGdprConsent {
    
    @Execution
    public void execute(MongoDatabase complianceDb, GdprService gdprService) {
        MongoCollection<Document> userConsents = complianceDb.getCollection("user_consents");
        
        // Pre-execution validation
        long totalUsers = userConsents.countDocuments();
        long usersWithoutConsent = userConsents.countDocuments(exists("gdprConsent", false));
        
        logger.info("Starting GDPR consent update. Total users: {}, Without consent: {}", 
                   totalUsers, usersWithoutConsent);
        
        if (usersWithoutConsent == 0) {
            logger.info("All users already have GDPR consent recorded. No action needed.");
            return;
        }
        
        // Execute the change
        UpdateResult result = userConsents.updateMany(
            exists("gdprConsent", false),
            combine(
                set("gdprConsent", buildDefaultConsent()),
                set("consentUpdatedDate", new Date()),
                set("consentSource", "system-migration")
            )
        );
        
        // Post-execution validation
        long updatedCount = result.getModifiedCount();
        long stillWithoutConsent = userConsents.countDocuments(exists("gdprConsent", false));
        
        logger.info("GDPR consent update completed. Updated: {}, Remaining without consent: {}", 
                   updatedCount, stillWithoutConsent);
        
        // Validation checks
        if (updatedCount != usersWithoutConsent) {
            throw new ValidationException(
                String.format("Expected to update %d users but actually updated %d", 
                             usersWithoutConsent, updatedCount));
        }
        
        if (stillWithoutConsent > 0) {
            logger.warn("Some users still without consent after migration: {}", stillWithoutConsent);
        }
        
        // Compliance reporting
        gdprService.reportConsentUpdate(updatedCount, "system-migration");
    }
    
    @RollbackExecution
    public void rollback(MongoDatabase complianceDb, GdprService gdprService) {
        MongoCollection<Document> userConsents = complianceDb.getCollection("user_consents");
        
        // Rollback only system-generated consent entries
        UpdateResult result = userConsents.updateMany(
            eq("consentSource", "system-migration"),
            combine(
                unset("gdprConsent"),
                unset("consentUpdatedDate"),
                unset("consentSource")
            )
        );
        
        logger.info("Rolled back GDPR consent for {} users", result.getModifiedCount());
        gdprService.reportConsentRollback(result.getModifiedCount(), "system-migration");
    }
}
```

---

## Anti-Patterns to Avoid

### ❌ Anti-Pattern 1: Silent Failures
```java
// DON'T DO THIS
@Execution
public void execute(ExternalService service) {
    try {
        service.updateData(data);
    } catch (Exception e) {
        // Silent failure - no one knows this failed!
        logger.debug("Update failed: {}", e.getMessage());
    }
}
```

### ✅ Better Approach:
```java
@Execution  
public void execute(ExternalService service) {
    try {
        service.updateData(data);
    } catch (ServiceUnavailableException e) {
        logger.error("Service temporarily unavailable: {}", e.getMessage());
        throw new RetryableException("External service unavailable", e);
    } catch (ValidationException e) {
        logger.error("Data validation failed: {}", e.getMessage());
        throw new PermanentException("Invalid data provided", e);
    }
}
```

### ❌ Anti-Pattern 2: Mixing Transactional and Non-Transactional
```java
// DON'T DO THIS
@ChangeUnit(transactional = true)  // This won't work for Kafka!
public class MixedOperations {
    @Execution
    public void execute(MongoDatabase db, KafkaTemplate kafka) {
        db.getCollection("users").updateMany(...);  // Transactional
        kafka.send("user-topic", event);            // Non-transactional
    }
}
```

### ✅ Better Approach:
```java
// Separate concerns
@TargetSystem("user-database")
@ChangeUnit(id = "update-users", transactional = true)
public class UpdateUsers { }

@TargetSystem("event-stream")  
@ChangeUnit(id = "publish-events", transactional = false)
public class PublishEvents { }
```

### ❌ Anti-Pattern 3: Assuming Success
```java
// DON'T DO THIS
@Execution
public void execute(List<ExternalService> services) {
    for (ExternalService service : services) {
        service.update();  // What if some succeed and others fail?
    }
}
```

### ✅ Better Approach:
```java
@Execution
public void execute(List<ExternalService> services) {
    List<String> successfulServices = new ArrayList<>();
    
    try {
        for (ExternalService service : services) {
            service.update();
            successfulServices.add(service.getId());
        }
    } catch (Exception e) {
        // Store partial progress for rollback
        storeProgress(successfulServices);
        throw e;
    }
}
```

---

## Best Practices Summary

### **Design for Production**
1. **Assume failures will happen** - design changes to handle partial completion
2. **Make operations idempotent** when possible to enable safe retry
3. **Validate inputs and outputs** to catch issues early
4. **Log extensively** for troubleshooting and audit purposes

### **Choose the Right Strategy**
1. **MANUAL_INTERVENTION** for critical, non-idempotent operations
2. **ALWAYS_RETRY** for idempotent, low-risk operations
3. **Document your reasoning** for recovery strategy decisions

### **Implement Proper Rollback**
1. **Always provide @RollbackExecution** methods
2. **Test rollback logic** as thoroughly as execution logic
3. **Handle partial failures** in rollback scenarios
4. **Log rollback operations** for audit trails

### **Monitor and Alert**
1. **Set up monitoring** for change execution patterns
2. **Create alerts** for failure conditions
3. **Establish SLAs** for issue resolution
4. **Review patterns** regularly to improve safety

**Remember**: Safety patterns are not just about preventing failures - they're about building confidence in your system evolution process and enabling your team to move fast while maintaining enterprise-grade reliability.

---

// File: resources/examples

## Introduction

The **Flamingock Examples** repository showcases a growing collection of real-world use cases demonstrating how to use Flamingock in different environments, integrations, and technologies. Each top-level folder represents a target technology and contains one or more self-contained example projects. Each project is designed to be cloned, explored, and run as a reference or foundation for your own implementation.

👉 **GitHub Repository**: [github.com/flamingock/flamingock-examples](https://github.com/flamingock/flamingock-examples)

---

## What you’ll find

Within each technology folder, you’ll find one or more example ​projects that demonstrate how to configure Flamingock and apply change units in various scenarios. Each folder contains its own `README.md` with setup instructions, and each project inside has its own documentation.

| Technology Folder                                                                 | Description                                                                                                                                                               |
|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [mongodb](https://github.com/flamingock/flamingock-examples/tree/master/mongodb)     | Folder containing Flamingock CE projects using MongoDB as the audit‐log backend. Each project shows different integration scenarios (standalone Java, Spring Boot, etc.). |
| [dynamodb](https://github.com/flamingock/flamingock-examples/tree/master/dynamodb)   | Folder containing Flamingock CE projects using Amazon DynamoDB for audit logging. Includes both standalone and Spring Boot examples.                                      |
| [couchbase](https://github.com/flamingock/flamingock-examples/tree/master/couchbase) | Folder containing Flamingock CE projects using Couchbase as the audit‐log backend.                                                                                        |

More examples are planned — including PostgreSQL, Redis, LocalStack, Kafka, Spring Native, multi‐module projects, and custom runners.

---

## How to use the examples

Each example folder and project includes its own `README.md` with detailed setup and run instructions. In general:

1. **Clone the examples repository**
   ```bash
   git clone https://github.com/flamingock/flamingock-examples.git
   ```  
   This repository contains all the example folders for various technologies.

2. **Navigate to the technology folder of interest**
   ```bash
   cd flamingock-examples/s3
   ```  
   Replace `s3` with the folder name for the technology you are interested in (e.g., `kafka`, `mongodb`, `dynamodb`, etc.).

3. **Navigate to a specific example project**
   ```bash
   cd s3
   ```  
   Each folder contains one or more projects. Move into the project folder that matches your use case or environment.

4. **Run the example**
   - For standalone Java applications:
     ```bash
     ./gradlew run
     ```  
   - For Spring Boot projects:
     ```bash
     ./gradlew bootRun
     ```  
   - Follow any additional instructions in the project’s `README.md`. Some examples may use Testcontainers or LocalStack; if so, ensure Docker is running on your machine.

---

## Who this is for

- **New users**: Learn by example. Pick an example that matches your tech stack and explore how Flamingock integrates with your environment.
- **Advanced users**: Discover integration patterns with external systems like Kafka, AWS, or NoSQL databases.
- **Contributors**: Want to improve or submit a new example? Fork the repo, add your example folder, and create a pull request!

---

## Contributing

We welcome community contributions to expand this repository! Please consider:

- Adding new example projects or folders (e.g., Wiremock, Kafka, PostgreSQL, Redis)
- Fixing or modernizing existing examples
- Improving documentation and setup instructions

See the [CONTRIBUTING.md](https://github.com/flamingock/flamingock-examples/blob/master/CONTRIBUTING.md) for detailed guidelines.

---

// File: resources/faq

## Introduction

This FAQ addresses frequent questions about Flamingock's enterprise-grade distributed system evolution platform, from basic usage to advanced recovery strategies and operational concerns.

---

### Getting started

**Should I use a template-based or code-based ChangeUnit?**  
Choose template-based ChangeUnits to eliminate boilerplate for common tools and integrations (SQL DDL, SaaS/API, etc) and for your custom ChangeUnits by defining changes declaratively in YAML or JSON.
Use code-based ChangeUnits when you need custom or conditional logic in Java.
See: [Template introduction](templates/templates-introduction.md)

**Can I integrate Flamingock into a Spring Boot application?**  
Yes, you can. You just need to import the Spring Boot integration module and annotate you main application with [`@EnableFlamingock`](../frameworks/springboot-integration/introduction#automatic-setup).
See: [Spring Boot integration](../frameworks/springboot-integration/introduction.md)

**Can I use Flamingock without Spring Boot?**  
Yes. You can use Flamingock in any Java application by configuring it manually using the [`FlamingockBuilder`](../getting-started/get-started#5-configure-flamingock). This approach is ideal for applications that do not rely on Spring Boot or that require finer control.

**What Java version is required?**  
Flamingock’s core engine runs on Java 8 and above. However, some optional integration modules (such as the Spring Boot support) target more recent ecosystems and require Java 17+. For those cases we publish two artifacts:

- A modern module (e.g., flamingock-springboot-integration) built for Java 17+ and Spring Boot 3.x
- A legacy counterpart (e.g., flamingock-springboot-integration-v2-legacy) compatible with Java 8 and Spring Boot 2.x

Most users on Java 8 can stick with the core and legacy integrations; if you’re on Java 17 or newer, simply use the up-to-date modules.

**Is it possible to use Flamingock in GraalVM native images?**  
Yes, Flamingock provides a dedicated [GraalVM integration guide](../frameworks/graalvm.md). Ensure your dependencies and reflection requirements are correctly configured.

---

### Editions and compatibility

**What edition of Flamingock should I use?**  
Flamingock is available in three flavors—pick the one that best fits your needs and operational model:

1. [**Cloud Edition (SaaS)**](../overview/Editions#%EF%B8%8F-flamingock-cloud-edition-coming-soon)

    A fully managed, enterprise-grade service hosted by Flamingock:

    - Zero ops: no infrastructure to manage, no database to configure
    - Enterprise features: cross-service dashboards, RBAC, team & environment management, fully support for templates, batching, etc.
    - 24×7 support & SLAs and seamless upgrades

    Perfect for teams that need scalability, governance, and out-of-the-box observability.

2. [**Self-hosted Edition**](../overview/Editions#-flamingock-self-hosted-edition-coming-soon)

    All the same features as our Cloud Edition—dashboards, governance, transaction protocols—but deployed into your own infrastructure (on-premises or in your VPC):

    - Full feature parity with SaaS Cloud
    - Data residency & compliance: you control where audit records live

    Ideal for organizations that require enterprise capabilities but cannot—or prefer not to—consume a hosted SaaS.

3. [**Community Edition**](../overview/Editions#-community-edition-open-source)

    Open-source, self-hosted library you run alongside your application:

    - Lightweight & free: you supply your own audit store (MongoDB, DynamoDB, Couchbase, etc.)
    - Core capabilities: ChangeUnits, audit logging, distributed locking, and transactional consistency where supported

    Perfect for smaller teams or projects that need a robust, code-centric change framework.


**Can I switch between editions?**  
Yes. Flamingock provides an importer that allows you to migrate seamlessly from a **Community Edition to the Cloud Edition**, making it easy to adopt a fully managed backend for storing internal data.

If you are working with different Community Editions that use the **same underlying store** (such as MongoDB), and they share the same structure and collection for storing metadata, it is possible to switch between them with minimal adjustments. This enables flexible integration depending on your preferred access layer, such as switching from the MongoDB Java Driver edition to the Spring Data edition.

---

### Behaviour and execution

**Does Flamingock guarantee idempotent execution?**  
Yes. Each `ChangeUnit` has a unique ID and Flamingock ensures it runs only once per system, even across multiple instances.

**What happens if a ChangeUnit execution fails midway?**  
Flamingock's behavior depends on your recovery strategy configuration:

**With MANUAL_INTERVENTION (default)**:
1. **Transactional changes**: Database automatically rolls back, issue logged for manual review
2. **Non-transactional changes**: `@RollbackExecution` method called, issue logged for manual review
3. **Resolution required**: Use CLI (`flamingock issue get`, then `flamingock audit fix`) to resolve after investigation

**With ALWAYS_RETRY**:
1. **Transactional changes**: Database automatically rolls back, automatic retry on next execution
2. **Non-transactional changes**: `@RollbackExecution` method called, automatic retry on next execution
3. **No manual intervention**: Continues until successful

This intelligent failure handling prevents silent data corruption and provides operational control.

**How can I ensure changes are transactional?**  
If your database supports transactions (e.g. MongoDB ≥ 4.0 in replica set), you can enable them using [Flamingock’s transaction config](../flamingock-library-config/transactions.md).

**Should I implement the @RollbackExecution method in transactional environments?**

Yes, we highly recommend to implement the `@RollbackExecution` method. The main reason for this is that some other operations like undo, rely on this method to work. However it's a very good practice as it provides a robust system that is less affected when moving to non-transactional environments.

**Can I react to the execution of Flamingock from my application?**  
Yes. Flamingock provides an event system that allows your application to listen to key lifecycle moments, such as when a `ChangeUnit` starts or finishes execution. These events can be used to trigger logging, monitoring, or other side effects external to the change execution logic itself.

This enables loose coupling between Flamingock’s core execution and your application-level behaviour, without modifying the `ChangeUnit` directly.

For more details, see the [Events](../flamingock-library-config/events.md) guide.

**Is Flamingock compatible with Spring Boot profiles?**  
Yes. You can conditionally run ChangeUnits using [`@Profile`](../frameworks/springboot-integration/profiles.md), allowing changes to vary by environment.

---

### Configuration

**Where do I set MongoDB connection options like write concern or read preference?**  
You can define these directly in the config using dedicated properties (e.g. `mongodb.writeConcern.w`, `readPreference`, etc.). Refer to the [extra configuration](../flamingock-library-config/extra-configuration.md) section for detailed examples.

**Can I inject Spring beans or other services into my ChangeUnits?**  
Yes. Flamingock supports full [dependency injection](../flamingock-library-config/changeunit-dependency-injection.md) in both Spring and non-Spring environments.

**Can I define ChangeUnit dependencies and execution order?**  
Yes. ChangeUnits can declare dependencies via annotations or configuration metadata. See [ChangeUnit deep dive](../flamingock-library-config/changeunits-deep-dive.md) for more.

---

### Testing and development

**How do I test Flamingock ChangeUnits?**  
You can perform [unit](../testing/unit-testing.md), [integration](../testing/integration-testing.md), and [Spring Boot integration](../testing/springboot-integration-testing.md) tests using test runners and mocking utilities.

**Can I use templates to generate ChangeUnits?**  
Yes. Flamingock offers a templating mechanism for [creating new ChangeUnits](../templates/templates-how-to-use.md) and defining reusable components.

---

### Migrating from Mongock

**What’s the relationship between Flamingock and Mongock?**  
Flamingock is the direct evolution of Mongock. While it inherits the core idea of tracking and executing changes reliably, Flamingock is a complete architectural and conceptual redesign aimed at overcoming the limitations of Mongock.

Some of the key advancements introduced by Flamingock include:

- **Cloud-native capabilities**: Support for cloud-managed storage and execution, enabling Flamingock to run in distributed, serverless, or ephemeral environments without additional setup.
- **Execution stages and pipelines**: A structured way to group and orchestrate ChangeUnits by context, environment, or lifecycle stage.
- **Modular architecture**: Clean separation of core, editions, templates, and integrations, enabling better extensibility and maintainability.
- **Template-based ChangeUnits**: An additional declarative mechanism to define reusable changes without writing Java code, accelerating development and standardisation.

While Flamingock retains conceptual compatibility with Mongock, it represents a significant leap forward in flexibility, scalability, and developer experience.

If you are currently using Mongock, we encourage you to [review the migration guide](upgrade-from-mongock.md) and explore what Flamingock can offer in modern change management.

---

### Recovery Strategies & Safety

**What are recovery strategies and why do I need them?**  
Recovery strategies determine how Flamingock handles failures - the key differentiator from traditional tools that retry blindly or fail silently. You choose between:
- **MANUAL_INTERVENTION** (default): Stop and alert for human review when uncertain
- **ALWAYS_RETRY**: Continue automatically until successful for idempotent operations

This prevents silent data corruption and gives you operational control based on your risk tolerance.

**When should I use MANUAL_INTERVENTION vs ALWAYS_RETRY?**  
**Use MANUAL_INTERVENTION for**:
- Financial transactions
- User data modifications  
- Critical business logic
- Non-idempotent operations
- Compliance-sensitive changes

**Use ALWAYS_RETRY for**:
- Cache warming operations
- Idempotent API calls
- Event publishing (with consistent keys)
- Configuration updates
- Index creation
- File operations with overwrite

**How do I know if my operation is idempotent?**  
An operation is idempotent if running it multiple times produces the same result as running it once. Examples:
- ✅ `SET user.status = 'active'` (same result every time)
- ✅ `CREATE INDEX IF NOT EXISTS` (safe to repeat)  
- ✅ File overwrite with same content
- ❌ `INCREMENT user.score` (different result each time)
- ❌ Append operations
- ❌ Time-sensitive calculations

**What is the issue resolution workflow?**  
1. **Detection**: `flamingock issue list` shows all unresolved issues
2. **Triage**: `flamingock issue get` provides next priority issue with guidance
3. **Investigation**: Check target system state (not audit store)
4. **Resolution**: `flamingock audit fix -c change-id --resolution APPLIED|ROLLED_BACK`

This structured workflow eliminates guesswork and provides complete audit trails.

**Can I change recovery strategies after deployment?**  
Yes, you can update the `@Recovery` annotation in your code and redeploy. Existing audit entries maintain their state, but new executions use the updated strategy.

**How does Cloud Edition improve recovery without changing my code?**  
Cloud Edition uses the same recovery strategies but provides enhanced outcomes through:
- **Intelligent automation**: Advanced reconciliation and marker mechanisms
- **Enhanced retry logic**: Sophisticated backoff and circuit breaker patterns  
- **Automatic issue resolution**: Many failures requiring manual intervention in Community Edition are resolved automatically

Your change definitions remain identical - Cloud Edition just delivers better results.

---

### Enterprise & Operational Concerns

**How does Flamingock ensure data integrity in distributed systems?**  
Flamingock uses a dual-architecture separating target systems (where changes are applied) from audit store (execution tracking):
- **Complete audit trail**: Every change attempt recorded regardless of business system failures
- **Recovery capabilities**: CLI operates on audit state, you fix business systems
- **Compliance independence**: Audit integrity maintained during business system issues
- **Governance separation**: Business and compliance data have different access patterns

**What compliance and audit capabilities does Flamingock provide?**  
- **Complete execution history** with timestamp, author, system, and outcome
- **Issue tracking and resolution** workflows for failed changes
- **CLI-based audit management** for governance and compliance
- **Integration ready** for external observability platforms (ELK, Prometheus, Datadog)
- **Regulatory reporting** capabilities in Cloud Edition

**How does Flamingock compare to traditional migration tools?**  
| Aspect | Flyway/Liquibase | Mongock | Flamingock |
|--------|-----------------|---------|------------|
| **Focus** | SQL databases | MongoDB only | All systems |
| **Distributed Systems** | ❌ Not designed for | ❌ Limited | ✅ First-class support |
| **Non-transactional** | ❌ No support | ❌ Assumes transactions | ✅ Full support |
| **Failure Handling** | Retry blindly | Retry blindly | Configurable strategies |
| **Issue Resolution** | Manual SQL | None | CLI + Cloud automation |
| **Safety Default** | None | None | MANUAL_INTERVENTION |

**Can Flamingock handle multi-system coordination?**  
Yes, Flamingock is designed for distributed systems. A single ChangeUnit can coordinate changes across multiple target systems (databases, APIs, message queues) while maintaining a unified audit trail and recovery strategy.

**How do I ensure my team adopts Flamingock safely?**  
1. **Start conservative**: Use MANUAL_INTERVENTION (default) initially
2. **Establish governance**: Define organization-wide recovery strategy guidelines
3. **Create runbooks**: Document investigation procedures for your changes
4. **Train on CLI**: Ensure team knows issue resolution workflow
5. **Monitor patterns**: Review failure patterns to optimize strategies over time

**What happens if the audit store goes down?**  
Flamingock's safety guarantee: **No business changes applied without proper audit tracking**. If the audit store is unavailable:
- Flamingock stops execution safely
- No changes are applied to target systems
- System remains in safe, known state
- Resume automatically once audit store connectivity is restored

**Can I use Flamingock in microservices architectures?**  
Absolutely. Flamingock is designed for distributed systems:
- Each microservice can have its own ChangeUnits for its domain
- Shared audit store provides cross-service visibility (especially in Cloud Edition)  
- CLI provides centralized operational control across all services
- Recovery strategies can be tailored per service's risk profile

**What are the organizational benefits of adopting Flamingock?**  
- **Risk reduction**: Prevent silent data corruption through safety-first defaults
- **Team velocity**: Eliminate deployment bottlenecks with autonomous change management
- **Operational excellence**: Centralized governance with distributed execution
- **Compliance automation**: Complete audit trails and governance workflows
- **Reduced dependencies**: Teams control their domain without infrastructure dependencies

**How does Flamingock support regulatory compliance requirements?**  
- **Complete audit trails** with immutable execution history
- **Governance workflows** for change approval and review
- **Issue resolution documentation** for regulatory reporting
- **CLI integration** for compliance automation
- **Separation of concerns** between business and compliance data
- **Cloud Edition features**: Advanced reporting, RBAC, multi-environment governance

---

### Other

**Is Flamingock open-source?**  
Yes. The Flamingock client library — used across all editions, including Community, Self-managed, and Cloud — is fully open-source.

For the Cloud and Self-managed editions, additional enterprise components such as the server runtime, dashboards, and governance tools are provided under a commercial licence. These components build on top of the open-source core to deliver advanced features like observability, orchestration, and centralised management.

**Is there a CLI available?**  
Yes! The [Flamingock CLI](../cli/cli.md) provides enterprise-grade operational control for issue resolution, audit management, and maintenance tasks.

---

If your question is not listed here, please check the corresponding edition’s guide or open an issue on our GitHub repository.

---

// File: resources/upgrade-from-mongock

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Upgrade from Mongock to Flamingock

Flamingock is the next evolution of Mongock. **Upgrading** from Mongock to Flamingock involves two main pillars:

1. **Audit-store import** – Flamingock automatically copies Mongock’s _changeLog_ collection/table into its own audit store so historical executions are preserved.
2. **Library swap** – Your application stops calling the Mongock API and starts calling Flamingock. Existing ChangeUnits stay in place; only their annotation imports change.

Because the codebase remains the same and ChangeUnits are kept intact, we call this an _upgrade_, not a migration.

---

## Upgrade steps (at a glance)

1. **Update ChangeUnit imports** – Replace Mongock annotations with Flamingock equivalents.
2. **Upgrade application code** – Replace Mongock API usage with the Flamingock builder(or Spring annotation).
3. **Create system stage** – Add a template-based ChangeUnit that imports legacy audit records.
4. **Configure pipeline** – Point Flamingock to your legacy and new ChangeUnit packages.

That’s it! Once complete, Flamingock runs with your full history intact.


## Step1: Update artefacts

Replace the Mongock artefacts with Flamingock ones.

- Mongock
```groovy
implementation(platform("io.mongock:mongock-bom:5.5.0"))
implementation("io.mongock:mongock-standalone")
implementation("io.mongock:mongodb-sync-v4-driver")
```

- Flamingock
```groovy
implementation(platform("io.flamingock:flamingock-cloud-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-mongodb-sync")
annotationProcessor("io.flamingock:flamingock-processor:$flamingockVersion")
```

## Step 1: Update ChangeUnit imports

Update these imports in your existing ChangeUnits (keep them in their current packages):

| Mongock import                                 | Flamingock import                                 |
|------------------------------------------------|---------------------------------------------------|
| `io.mongock.api.annotations.ChangeUnit`        | `io.flamingock.api.annotations.ChangeUnit`        |
| `io.mongock.api.annotations.Execution`         | `io.flamingock.api.annotations.Execution`         |
| `io.mongock.api.annotations.RollbackExecution` | `io.flamingock.api.annotations.RollbackExecution` |

:::info Legacy Support
- **For existing change units**: Keep them **exactly as they are** in their current packages - only update imports to maintain immutability.
- **For new change units**: Avoid using `@BeforeExecution` and `@RollbackBeforeExecution`. Instead, use dedicated `@Execution` and `@RollbackExecution` methods for better separation of concerns
- `@BeforeExecution` and `@RollbackBeforeExecution` from `io.mongock.api` are supported for backward compatibility
:::
## Step 2: Upgrade application code

<Tabs groupId="upgrade">
  <TabItem value="flamingock" label="Flamingock(new)" default>
```java
Flamingock.builder()
    .addDependency(mongoClient)
    .addDependency(mongoDatabase)
    .build()
    .run();
```
  </TabItem>
  <TabItem value="mongock" label="Mongock(legacy)">
```java
MongockStandalone.builder()
    .setDriver(MongoSync4Driver.withDefaultLock(mongoClient, "test"))
    .addMigrationScanPackage("legacy.mongock.changes")
    .buildRunner()
    .execute();
```
  </TabItem>
</Tabs>


### Key changes:
- Replace `MongockStandalone` with `Flamingock.builder()`
- Remove explicit driver setup (Flamingock auto-configures it)
- Remove package scanning in favor of pipeline config
- Inject dependencies via `.addDependency()`

For Spring Boot integration, see the [Spring Boot guide](../frameworks/springboot-integration/introduction.md).

## Step 3: Create system stage

The system stage is a special stage handled by Flamingock for system-level operations. In this upgrade context, you'll create a template-based change unit in the system stage package to handle audit records migration. 

Create a YAML file (e.g., `_0001_upgrade_from_mongock.yaml`) with the following structure:

```yaml
id: upgrade-from-mongock
order: 0001
template: MongoDbImporterChangeTemplate
configuration:
  origin: mongockChangeLog
  failOnEmptyOrigin: true
```

**Configuration parameters:**
- **id**: Choose how you want to identify this change unit
- **order**: Should be the first one (0001) as this is typically the first system stage change unit
- **template**: Available templates: `MongoDbImporterChangeTemplate`, `DynamoDbImporterChangeTemplate`, `CouchbaseImporterChangeTemplate`
- **origin**: The collection/table where Mongock's audit log is stored (typically `mongockChangeLog`)
- **failOnEmptyOrigin**: (Optional) Set to `false` to disable the security check that ensures the origin contains data. By default, Flamingock verifies the origin collection/table has content to prevent importing from the wrong source

## Step 4: Configure setup

Configure Flamingock using the `@EnableFlamingock` annotation. Add this annotation to any class in your application:

```java
@EnableFlamingock(
    stages = {
        @Stage(type = SYSTEM, location = "com.yourapp.flamingock.system"),
        @Stage(type = LEGACY, location = "com.yourapp.mongock"),
        @Stage(location = "com.yourapp.flamingock.changes")
    }
)
public class FlamingockConfig {
    // Configuration class
}
```

### Configuration explained:

**Stage types and usage:**

1. **System stage** - A special stage for framework-level changeUnits handled by Flamingock itself. In this context, it contains the changeUnit(provided by flamingock team) that copies Mongock’s audit data into Flamingock’s store
2. **Legacy stage** - Designed specifically for the changeUnits that originally came from the legacy tool (here, Mongock). Flamingock treats it as read-only: it runs only the units that never executed under Mongock and skips those already recorded in the imported audit history. Do **not** add new ChangeUnits to this stage.
3. **Standard stage** (default): For new Flamingock-native change units. This is where all your new application changes should be added going forward

- For advanced stage configurations and multi-stage scenarios, see the [setup & stages guide](../flamingock-library-config/setup-and-stages)

## Run and validate

### Running the upgrade

```shell
./gradlew run
```

### Expected output

After running Flamingock, you should see output similar to:
```
Stage: flamingock-system-stage
	0001) id: upgrade-from-mongock 
		Started				✅ - OK
		Executed			✅ - OK
		Audited[execution]	        ✅ - OK
	
Stage: Application Changes
	0001) id: create-users-collection-with-index 
		Started				✅ - OK
		Executed			✅ - OK
		Audited[execution]	        ✅ - OK
	0002) id: seed-users 
		Started				✅ - OK
		Executed			✅ - OK
		Audited[execution]	        ✅ - OK
```

### Validation checklist

- ✅ System stage executes the upgrade changeUnit successfully
- ✅ Already-applied existing changeUnits from Mongock are not reapplied
- ✅ Previously unapplied existing changeUnits from Mongock execute without errors
- ✅ New Flamingock changeUnits execute as expected
- ✅ All audit logs are properly created in Flamingock format
- ✅ Database changes match the expected results

---

## Why upgrade instead of removing or starting fresh?

- **Preserve your audit trail** – Every historical ChangeUnit and its execution log remains intact for compliance and debugging.
- **Avoid unintended re-runs** – Flamingock imports Mongock’s history, so previously-executed ChangeUnits are never applied twice.
- **Keep change-as-code semantics** – The act of migrating the audit store itself is handled as a versioned change, reinforcing the idea that history is part of your application.
- **Future continuity** – Teams and tools that rely on Mongock’s records can transition seamlessly; dashboards and reports will show an unbroken timeline.



---

Ready to upgrade? See the [pipeline & stages guide](../flamingock-library-config/setup-and-stages.md) and [ChangeUnit reference](../flamingock-library-config/changeunits-deep-dive.md).  

**Complete example project**: https://github.com/flamingock/flamingock-examples/tree/master/import-from-mongock

---

// File: templates/templates-introduction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Templates

## Introduction

Flamingock Templates are pre-built modules designed to streamline the integration of common third-party services, databases, and configurations into the **Flamingock change management system**. These templates provide a structured way to define configuration changes in declarative format (such as **YAML** files), reducing the need for custom code-based ChangeUnits while ensuring seamless execution and versioning of changes.

## How It Works

Flamingock Templates are designed to simplify change definitions by extracting reusable logic into modular building blocks. While **Flamingock’s core approach** relies on code-based ChangeUnits to manage database and system changes, Flamingock Templates provide a **low-code alternative** that simplifies the process for common integration scenarios. Instead of writing Java classes for each migration, users can leverage existing templates by defining changes in a declarative format(**YAML**, etc.).

### Who Provides Templates?

Templates can be:
- **Provided by the Flamingock core team** (e.g., SQL, Kafka, Redis)
- **Offered by the community**
- **Created internally by teams** to address common patterns in their own systems

This makes them highly adaptable: whether you're integrating a database, messaging system, or internal service, templates give you a low-code mechanism to structure your changes cleanly and consistently.

### Why Do Templates Exist?

Templates exist to solve a common problem in traditional, code-based migrations: **duplicated logic across ChangeUnits**.

Instead of repeating the same boilerplate code over and over, templates let you **externalize the logic** into a reusable definition and **parameterize** what’s different.



## Key Features

- **Pre-built, reusable modules**: Each template provides a well-defined structure for managing migrations and configurations.
- **Declarative ChangeUnits**: Users define changes in YAML, avoiding Java boilerplate.
- **Support for third-party integrations**: Includes databases, messaging systems, and cloud configurations.
- **Automatic execution and versioning**: Templates are applied and tracked as part of Flamingock’s change management process.
- **Built-in best practices**: Ensures correctness and reliability for each integration.
- **Extensible by the community**: Developers can contribute new templates to expand Flamingock’s ecosystem.

## When to use Template-based ChangeUnits vs. code-based ChangeUnits

| **Use Case** | **Template-Based ChangeUnit** | **Code-Based ChangeUnit** |
|-------------|-----------------------------|-------------------------|
| Integration with third-party services (e.g., Kafka, Twilio) | ✅ | ✅ |
| Simple database migrations (e.g., SQL schema updates) | ✅ | ✅ |
| Custom logic and advanced migrations | ☑️* | ✅ |
| Complex, dynamic change sequences | ☑️** | ✅ |
| Low-code, configuration-driven changes | ✅ | ❌ |

☑️* Templates can handle custom logic if it can be abstracted and reused. Users can create custom templates to manage these scenarios.

☑️** While templates may support complex change sequences, full control and dynamic logic might be easier to implement in code when the scenario is highly specific or non-repetitive.


## List of current Flamingock templates

| Template Name | Description |
|--------------|-------------|
| **SQL Template** | Enables SQL-based migrations using YAML-defined ChangeUnits. |
| **Kafka Template** (Upcoming) | Manages Kafka topics and configurations using YAML definitions. |
| **Twilio Template** (Upcoming) | Simplifies Twilio messaging configurations via YAML. |
| **Redis Template** (Upcoming) | Allows structured updates to Redis configurations. |

---

Flamingock Templates unlock new possibilities for seamless application evolution. Whether you’re managing **databases, configurations, or third-party services**, templates simplify the process, ensuring **faster, safer, and more standardised migrations**. 

:::tip 
Join the [**Flamingock community**](https://github.com/flamingock/flamingock-project/discussions) and start building your own templates today! 🚀
:::

---

// File: templates/templates-how-to-use

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# How to use Flamingock Templates

Using a Flamingock Template is straightforward. Here’s an example of how you can apply an SQL-based migration using the **SQL Template**.

### Step 1: Add the Template dependency

Ensure your **Flamingock Template** dependency is included in your project. Example of using `sql-template`:

<Tabs groupId="gradle_maven">
  <TabItem value="gradle" label="Gradle">
```kotlin
implementation(platform("io.flamingock:flamingock-ce-bom:$flamingockVersion"))
implementation("io.flamingock:flamingock-ce-sql-template")
```
  </TabItem>
  <TabItem value="maven" label="Maven">
```xml
<dependency>
    <groupId>io.flamingock.template</groupId>
    <artifactId>sql-template</artifactId>
    <version>1.0.0</version>
</dependency>
```
  </TabItem>
</Tabs>

### Step 2: define a Template-based change

In Flamingock, a **ChangeUnit** represents a single unit of work that needs to be applied to your system — for example, creating a table, updating a configuration, or setting up a cloud resource.

When using template-based changes, instead of implementing a code-based file to define the logic of the change, you describe the change in a declarative format (e.g., **YAML** file). The structure you use will depend on the template you’re leveraging.

Create a **YAML file** (e.g., `_0001_create_persons_table.yaml`) inside your application’s resources directory:

```yaml
id: create-persons-table-from-template
order: 1
templateName: sql-template
templateConfiguration:
  executionSql: |
    CREATE TABLE Persons (
      PersonID int,
      LastName varchar(255),
      FirstName varchar(255),
      Address varchar(255),
      City varchar(255)
    )
```

:::info
Note that your application must provide a `java.sql.Connection` instance as a dependency to Flamingock.
:::

#### 🔍 Understanding the configuration attributes

- **`id`**: Unique identifier for the change, used for tracking (same as in code-based changes).
- **`order`**: Execution order relative to other changes (also shared with code-based).
- **`templateName`**: Indicates which template should be used to handle the change logic. This is **required** for all template-based changes.
- **`templateConfiguration`**: Section where you define the input parameters for the selected template. These parameters vary depending on the template.
  - In this example, the template expects an `executionSql` field.
- **Other fields**: Some templates may define additional, custom configuration fields (e.g., `rollbackSql` for SQL template).

Template-based changes provide both **structure and flexibility**. They share the core concepts of change tracking with code-based ChangeUnits, but introduce a flexible configuration model where each template defines its own behavior through external parameters.

### Step 3: Configure Flamingock to use the template file

To configure Flamingock to use the YAML template file, you need to define a stage that includes the path to the template file using the `@EnableFlamingock` annotation:

```java
@EnableFlamingock(
    stages = {
        @Stage(location = "src/main/resources/templates")
    }
)
public class MainApplication {
    // Configuration class
}
```

If you prefer to use a pipeline YAML file for configuration, refer to the [Setup & Stages guide](../flamingock-library-config/setup-and-stages.md) for more details.

### Step 4: Run Flamingock

At application startup, Flamingock will automatically detect the YAML file and process it as a standard change, following the same execution flow as code-based changes.

---

## Use case: SQL database migration

Let’s compare how an SQL migration is handled using a **template-based ChangeUnit** vs. a **traditional code-based ChangeUnit**.

### Approach 1: Using a Traditional Code-Based ChangeUnit

```java
import io.flamingock.api.annotations.ChangeUnit;
import io.flamingock.api.annotations.Execution;

import java.sql.Connection;
import java.sql.SQLException;
import java.sql.Statement;
import javax.sql.DataSource;

@ChangeUnit(id = "create-persons-table", order = 1, author = "developer")
public class CreatePersonsTableChangeUnit {

    private final DataSource dataSource;

    public CreatePersonsTableChangeUnit(DataSource dataSource) {
        this.dataSource = dataSource;
    }

    @Execution
    public void execute() throws SQLException {
        try (Connection connection = dataSource.getConnection();
             Statement statement = connection.createStatement()) {

            statement.executeUpdate("""
                CREATE TABLE Persons (
                    PersonID int PRIMARY KEY,
                    LastName varchar(255),
                    FirstName varchar(255),
                    Address varchar(255),
                    City varchar(255)
                )
            """);
        }
    }
}

```

### Approach 2: Using a Flamingock SQL Template

With the **SQL Template**, users define the same migration in **YAML** instead of Java:

```yaml
id: create-persons-table-from-template
order: 1
templateName: sql-template
templateConfiguration:
    executionSql: |
        CREATE TABLE Persons (
            PersonID int,
            LastName varchar(255),
            FirstName varchar(255),
            Address varchar(255),
            City varchar(255)
        )
```

### Key Benefits of Using a Template Instead of Code-Based ChangeUnits:
- **Less code maintenance**: No need to write Java classes, inject DataSource, manage connections, or handle SQL execution manually.
- **Faster onboarding**: YAML is easier for non-Java developers.
- **Standardised migrations**: Ensures best practices and avoids custom implementation errors.
- **Improved readability**: Easier to review and version control.

---

// File: templates/create-your-own-template

# Create your own Flamingock template

## Introduction

[Flamingock Templates](./templates-introduction.md) allow you to encapsulate common logic and reduce boilerplate when defining change units. This document explains how to create your own templates for reuse across projects or for contribution to the Flamingock community.

---

## Overview of the required components

To create a template, you need:

- A Java class extending `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>`
- An `@Execution` method to perform the main change
- (Optionally) A `@RollbackExecution` method for undo support
- A service loader registration file (`META-INF/services`)
- (Optional) Package and distribute your template

---

## 1. Implement the Template class

Extend `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>` with three generics:

- **SHARED_CONFIG**: Shared configuration that applies to both execution and rollback (e.g., database connection, common settings). Use `Void` if no shared config is needed.
- **EXECUTION**: The type representing the execution logic/data
- **ROLLBACK**: The type representing the rollback logic/data  

**Example:**

```java
public class MongoChangeTemplate extends AbstractChangeTemplate<Void, MongoOperation, MongoOperation> {

    public MongoChangeTemplate() {
        super(MongoOperation.class);
    }

    @Execution
    public void execute(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional changeUnit[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, execution, clientSession);
    }

    @RollbackExecution
    public void rollback(MongoDatabase db, @Nullable ClientSession clientSession) {
        if (this.isTransactional && clientSession == null) {
            throw new IllegalArgumentException(String.format("Transactional changeUnit[%s] requires transactional ecosystem with ClientSession", changeId));
        }
        executeOp(db, rollback, clientSession);
    }

    private void executeOp(MongoDatabase db, MongoOperation op, ClientSession clientSession) {
        op.getOperator(db).apply(clientSession);
    }
}
```

#### Important notes
- Access your execution and rollback data directly via `this.execution` and `this.rollback` fields.
- Access shared configuration via `this.configuration` field (if using a non-Void shared config type).
- If your template references custom types, make sure to register them for reflection—especially for **GraalVM** native builds. When extending `AbstractChangeTemplate`, you can pass your custom types to the superclass constructor to ensure proper reflection support.

:::note 
See [**2. Define Execution and Rollback methods** ](./create-your-own-template#2-define-execution-and-rollback-methods) section for how to implement the core logic inside your template class using the execution/rollback data and dependency injection
:::

---

## 2. Define Execution and Rollback methods
Each template must include an `@Execution` method, and may optionally include a `@RollbackExecution` method.
These methods define the core logic that will be executed when Flamingock runs the corresponding change.

Inside these methods, it’s expected that you use the data provided by the user in the template-based change unit through the following fields:

- `this.execution` — the execution logic/data to apply during execution
- `this.rollback` — the rollback logic/data to apply during rollback or undo  
- `this.configuration` — shared configuration data (if using a non-Void shared config type)

An example of a template for Kafka topic management:

:::info
This is an illustrative example to demonstrate the template structure. Real Kafka templates would use different parameters and configuration structures based on actual requirements.
:::

```java
public class KafkaTopicTemplate extends AbstractChangeTemplate<Void, TopicConfig, String> {

    public KafkaTopicTemplate() {
        super(TopicConfig.class);
    }

    @Execution
    public void execute(AdminClient adminClient) throws Exception {
        // Create topic using the execution configuration
        NewTopic newTopic = new NewTopic(
            this.execution.getName(),
            this.execution.getPartitions(),
            this.execution.getReplicationFactor()
        );
        newTopic.configs(this.execution.getConfigs());
        
        adminClient.createTopics(List.of(newTopic)).all().get();
    }

    @RollbackExecution
    public void rollback(AdminClient adminClient) throws Exception {
        // Delete topic using the rollback topic name
        adminClient.deleteTopics(List.of(this.rollback)).all().get();
    }
}
```

### Example with Shared Configuration

When you need to share configuration between execution and rollback (such as connection details, common settings, etc.), you can use a non-Void shared configuration type:

:::info
This is an illustrative example to demonstrate the shared configuration pattern. Real S3 templates would use different parameters and configuration structures based on actual AWS SDK requirements.
:::

```java
public class S3BucketTemplate extends AbstractChangeTemplate<S3ConnectionConfig, BucketCreationRequest, String> {

    public S3BucketTemplate() {
        super(S3ConnectionConfig.class, BucketCreationRequest.class);
    }

    @Execution
    public void execute() {
        // Access shared configuration for AWS connection
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();
        
        // Create bucket using execution configuration
        CreateBucketRequest request = new CreateBucketRequest(this.execution.getBucketName())
            .withCannedAcl(this.execution.getAcl());
        
        if (this.execution.getEncryption() != null) {
            // Apply encryption settings
            request.withObjectLockEnabledForBucket(this.execution.getEncryption().isEnabled());
        }
        
        s3Client.createBucket(request);
    }

    @RollbackExecution
    public void rollback() {
        // Use the same shared configuration for rollback
        AmazonS3 s3Client = AmazonS3ClientBuilder.standard()
            .withRegion(this.configuration.getRegion())
            .withCredentials(this.configuration.getCredentialsProvider())
            .build();
        
        // Delete bucket using rollback bucket name
        s3Client.deleteBucket(this.rollback);
    }
}
```

This pattern is useful when:
- Both execution and rollback need the same configuration data (AWS credentials, region, etc.)
- You want to avoid duplicating connection details or common settings
- The template needs different data for execution vs rollback operations

### Injecting dependencies into Template methods
Template methods (such as those annotated with `@Execution` and `@RollbackExecution`) support method-level dependency injection using the same mechanism as change units.

Template classes do not support constructor injection.
All dependencies must be injected as parameters in the `@Execution` and `@RollbackExecution` methods.

You can inject any registered dependency as a method parameter:

```java
@Execution
public void execute(MongoDatabase db, ClientService clientService) {
  clientService.doSomething();
}
```
:::info
Flamingock will apply lock-safety guards unless you annotate the parameter with `@NonLockGuarded`.
:::

### Mapping between template-base changeUnit file and template methods

For details on how Flamingock maps the `execution` and `rollback` sections in your declarative change unit to the methods in your template class, refer to the [Template mapping](template-mapping-section.md) documentation.


---

## 3. Register the Template with ServiceLoader

Templates are discovered automatically at runtime using Java’s `ServiceLoader` system.

Steps:
1. Create a file at:

```
src/main/resources/META-INF/services/io.flamingock.core.api.template.ChangeTemplate
```

2. List the fully qualified class names of all templates in the file:

```plaintext
io.flamingock.template.kafka.CreateTopicTemplate
io.flamingock.template.kafka.UpdateTopicConfigTemplate
io.flamingock.template.kafka.DeleteTopicTemplate
```

:::tip 
Group templates by domain or technology for better maintainability.
:::

---

## 4. Package and distribute the Template

Depending on your target:

### Internal Templates (Private)
- No special packaging needed.
- Keep your template class inside your application.

### Public Templates (Contributing to the Community)
- Package your template as a JAR.
- Notify the Flamingock team via [development@flamingock.io](mailto:development@flamingock.io) or GitHub.
- Submit your template for validation.

#### Validation Requirements:
- Clear and justified use case
- Name must align and not conflict with existing templates
- Technically correct and production-grade implementation
- Public classes must be Javadoc-documented
- Submit a Pull Request adding the template's documentation to [flamingock.github.io](https://github.com/flamingock/flamingock.github.io)

---

## ✅ Best Practices

- Use `AbstractChangeTemplate<SHARED_CONFIG, EXECUTION, ROLLBACK>` with the appropriate generic types for your use case.
- Always provide an `@RollbackExecution` method if rollback or undo is expected.
- Use `Void` for generics when that type is not needed (e.g., `<Void, String, String>` for simple SQL templates).
- Use shared configuration (`<ConfigType, Void, Void>`) when both execution and rollback need the same configuration data.
- Document your template's purpose and generic types clearly for users.
- Ensure all custom types are registered for reflection by passing them to the superclass constructor, especially when targeting native builds.
- Group multiple templates by domain when packaging a library.

---

---

// File: templates/template-mapping-section

### How Execution and Rollback Mapping Works

In a template-based change unit (declarative format), Flamingock uses the `execution` and `rollback` sections to determine which methods to invoke in your template class.

#### Execution

- The method annotated with `@Execution` is **mandatory** for the template developer.
- The `execution` section in the declarative change unit is **mandatory** for the user.
- If the `execution` section is missing, Flamingock throws an exception at startup.

#### Rollback

- The method annotated with `@RollbackExecution` is **mandatory** for the template developer.
- The `rollback` section in the declarative change unit is **optional** for the user.

The behavior of rollback varies depending on context:

**Rollback during execution failure**

- If the system is **transactional** (e.g., MySQL), Flamingock relies on the system’s native transaction handling. It will not call the rollback method.
- If the system is **non-transactional**, Flamingock will:
  - Attempt to call the `@RollbackExecution` method only if the user provides a `rollback` section in the declarative file.
  - If no rollback config is provided, Flamingock skips the method call and logs the change as **FAILED**.

**Rollback during Undo operations (manual reversion)**

- If a `rollback` section is present in the declarative file, Flamingock will call the `@RollbackExecution` method — even if the change was previously applied successfully.
- If no `rollback` is provided, Flamingock skips the rollback logic, but still marks the change as **ROLLED_BACK** in the audit.

:::note 
In undo operations, if rollback is not defined in the declarative file, the change is marked as reverted even though no actual rollback was executed. It’s up to the user to ensure reversibility when needed.
:::

---

// File: testing/introduction

## Introduction

This section provides guidance on how to test applications that use **Flamingock**, including strategies for validating your change logic, ensuring proper execution coordination, and maintaining audit and rollback guarantees.

Whether you are running Flamingock in a local development environment, as part of CI pipelines, or through framework integrations like Spring Boot, testing is a key part of ensuring consistency and reliability across deployments.

Flamingock is not limited to database systems — it supports a wide range of targets (e.g., message brokers, file systems, APIs). Your testing strategy should reflect the behavior of the underlying systems you integrate with.

---

## What to test

There are **three primary levels** at which Flamingock-related functionality can be tested:

### 1. Unit test: Change logic
Isolate and test the logic inside your `@Execution` and `@RollbackExecution` methods without involving Flamingock’s runtime or audit mechanism.

- Use mocks for dependencies (e.g., `MongoTemplate`, `DynamoDbClient`, `S3Client`)
- Focus on business correctness and expected side effects
- No audit logs or locking are involved

👉 See [Unit testing your change units](./unit-testing.md)

---

### 2. Integration test: Flamingock execution
Run Flamingock end-to-end in a controlled environment to verify:

- Execution of the `@Execution` method
- Audit log persistence
- Rollback behavior on failure

This usually requires a real or containerized backend system (e.g., using **Testcontainers**).

👉 See [Integration testing Flamingock](./integration-testing.md)

---

### 3. Spring Boot integration
For applications using **Spring Boot**, test how Flamingock integrates with your app lifecycle:

- Use `@SpringBootTest` to validate full configuration
- Confirm that changes run on startup
- Optionally inject mocks to verify execution paths

👉 See [Testing with Spring Boot](./springboot-integration-testing.md)

---

// File: testing/unit-testing

## Introduction

Unit tests focus on verifying the internal logic of a **single change unit**, without relying on any external system.  
They are fast, isolated, and ideal for validating:

- That the `@Execution` method performs the correct logic
- That the `@RollbackExecution` method compensates properly on failure
- That injected dependencies are used as expected (using mocks or fakes)

Unit tests are most useful when your change unit contains business logic, computation, validation, or decisions.

---

## Example: Creating an S3 bucket

Suppose you have a change unit that creates an Amazon S3 bucket:

```java
@Change(id = "create-bucket", order = "0001", author = "dev-team")
public class _0001_CreateS3BucketChange {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }
}
```

---

## Writing a unit test

To unit test this class, we use JUnit and a mocking library (e.g., Mockito).  
We'll mock the `S3Client` and verify the correct calls were made.

```java
class _0001_CreateS3BucketChangeTest {

  private final S3Client s3Client = mock(S3Client.class);
  private final CreateS3BucketChange change = new CreateS3BucketChange();

  @Test
  void shouldCallCreateBucketOnExecution() {
    S3Client s3Client = mock(S3Client.class);
    new _0001_CreateS3BucketChange().execute(s3Client);

    verify(s3Client).createBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }

  @Test
  void shouldCallDeleteBucketOnRollback() {
    S3Client s3Client = mock(S3Client.class);
    new _0001_CreateS3BucketChange().rollback(s3Client);
    
    verify(s3Client).deleteBucket(argThat(req ->
        req.bucket().equals("flamingock-test-bucket")));
  }
}
```

---

## ✅ Best practices

- Use mocks or fakes to isolate the dependencies used in your change unit
- Focus only on the logic inside the `@Execution` and `@RollbackExecution` methods
- Keep assertions specific and minimal — check that the right dependencies are called
- Avoid testing Flamingock itself (e.g., locking or audit behavior — that’s handled in integration tests)
- Use descriptive test names like `shouldCallCreateBucketOnExecution()` for readability

---

// File: testing/integration-testing

## Introduction

Integration tests ensure that Flamingock operates correctly in a real environment by executing changes against live systems — such as databases, cloud APIs, or internal services. 

These tests involve spinning up the actual backend system and running Flamingock end-to-end:

- Change unit execution
- Audit log persistence
- Distributed lock acquisition

Integration tests should be used to validate that the full pipeline behaves as expected — from execution to rollback.

---

## Example: Creating an S3 bucket

Suppose you have a change unit that creates an Amazon S3 bucket:

```java
@Change(id = "create-bucket", order = "0001", author = "dev-team")
public class _0001_CreateS3BucketChange {

  @Execution
  public void execute(S3Client s3Client) {
    s3Client.createBucket(CreateBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }

  @RollbackExecution
  public void rollback(S3Client s3Client) {
    s3Client.deleteBucket(DeleteBucketRequest.builder()
        .bucket("flamingock-test-bucket")
        .build());
  }
}
```

---

## Integration test with Testcontainers

To test this change end-to-end, we will:

1. Spin up a **MongoDB container** to be used as Flamingock’s audit backend
2. Inject a real **S3 client** (mocked, localstack, or real AWS)
3. Configure Flamingock and execute it

```java
class IntegrationTest {

    static final MongoDBContainer mongoContainer = new MongoDBContainer("mongo:6.0");

    @BeforeAll
    static void initMongo() {
        mongoContainer.start();
    }

    @AfterAll
    static void tearDown() {
        mongoContainer.stop();
    }

    @Test
    void shouldExecuteChangeAgainstS3AndAuditToMongo() {
        S3Client s3Client = S3Client.builder()
                .region(Region.EU_WEST_1)
                .build();

        MongoClient mongoClient = MongoClients.create(mongoContainer.getReplicaSetUrl());

        Runner runner = Flamingock.builder()
                .addDependency(s3Client)
                .addDependency(mongoClient)
                .setProperty("mongodb.databaseName", "test-db")
                .build();

        runner.execute();

        // ✅ Verify the S3 bucket was created
        ListBucketsResponse buckets = s3Client.listBuckets();
        boolean bucketExists = buckets.buckets().stream()
                .anyMatch(b -> b.name().equals("flamingock-test-bucket"));
        assertTrue(bucketExists, "Expected S3 bucket was not found");

        // ✅ Verify the change was audited in MongoDB
        MongoDatabase db = mongoClient.getDatabase("test-db");
        MongoCollection<Document> auditCollection = db.getCollection("flamingockAuditLogs");

        Document document = new Document("changeId", "create-bucket")
                .append("state","EXECUTED");
        Document auditEntry = auditCollection.find(document).first();
        assertNotNull(auditEntry, "Flamingock audit log entry was not found in MongoDB");
    }

}
```

---

## ✅ Best practices

- Use Testcontainers to spin up a real audit backend (e.g., MongoDB) — this avoids the need for manual test setup
- Run Flamingock fully using `.build().execute()` — don’t call internal methods manually
- Clean up the backend between tests or isolate data with unique test identifiers
- Validate changes by checking the actual target system or using custom assertions
- Use integration tests sparingly — unit tests are faster and should cover most logic

---

// File: testing/springboot-integration-testing

## Introduction

This guide explains how to write integration tests for Flamingock when using **Spring Boot** with the `@EnableFlamingock` annotation.

With this setup:

- Flamingock is auto-configured using Spring Boot properties
- Dependencies like `Kafka AdminClient` or `DynamoDbClient`  must be declared as Spring beans
- The change units are executed end-to-end using real systems (e.g., DynamoDB Local, Kafka, S3)

> This test style is ideal for verifying that Flamingock interacts correctly with both its audit backend and any external systems.

---

## Example: Modifying a Kafka topic and auditing to DynamoDB

Suppose you have a change unit that modifies a Kafka topic configuration:

```java
@Change(id = "modify-topic-config", order = "0002", author = "dev-team")
public class _0002_ModifyKafkaTopicConfig {

  @Execution
  public void execute(AdminClient adminClient) {
    Map<ConfigResource, Config> configs = Map.of(
      new ConfigResource(ConfigResource.Type.TOPIC, "orders"),
      new Config(List.of(new ConfigEntry("retention.ms", "86400000")))
    );

    adminClient.alterConfigs(configs).all().join();
  }

  @RollbackExecution
  public void rollback(AdminClient adminClient) {
    Map<ConfigResource, Config> configs = Map.of(
      new ConfigResource(ConfigResource.Type.TOPIC, "orders"),
      new Config(List.of(new ConfigEntry("retention.ms", "604800000")))
    );

    adminClient.alterConfigs(configs).all().join();
  }
}
```

---

## Writing the test

In this test, we’ll:

- Spin up **Kafka** and **DynamoDB Local** using Testcontainers
- Provide the required beans (`AdminClient`, `DynamoDbClient`) to Spring Boot
- Assert that the Flamingock change unit executed and was **audited to DynamoDB**

:::info 
Flamingock requires `DynamoDbClient` and other injected services (like `AdminClient`) to be present in the Spring ApplicationContext. Spring Boot will auto-detect them if they are declared as `@Bean`s.
:::
```java
@SpringBootTest
@Testcontainers
@EnableFlamingock(
    stages = {
        @Stage(location = "com.yourapp.changes")
    }
)
public class FlamingockSpringbootTest {

  static final KafkaContainer kafka = new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:7.2.1"));
  
  static final GenericContainer<?> dynamoDb = new GenericContainer<>("amazon/dynamodb-local")
      .withExposedPorts(8000);

  @BeforeAll
  static void startContainers() {
    kafka.start();
    dynamoDb.start();
  }

  @AfterAll
  static void stopContainers() {
    kafka.stop();
    dynamoDb.stop();
  }

  @Bean
  public DynamoDbClient dynamoDbClient() {
    return DynamoDbClient.builder()
        .region(Region.US_EAST_1)
        .endpointOverride(URI.create("http://" + dynamoDb.getHost() + ":" + dynamoDb.getFirstMappedPort()))
        .build();
  }

  @Bean
  public AdminClient kafkaAdminClient() {
    Properties config = new Properties();
    config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBootstrapServers());
    return AdminClient.create(config);
  }

  @Test
  void shouldExecuteChangeAndWriteAuditToDynamoDB() {
    DynamoDbClient client = dynamoDbClient();
    ScanResponse scan = client.scan(ScanRequest.builder()
        .tableName("flamingockAuditLogs")
        .build());

    boolean changeExecuted = scan.items().stream()
        .anyMatch(item -> "modify-topic-config".equals(item.get("changeId").s())
                       && "EXECUTED".equals(item.get("state").s()));

    assertTrue(changeExecuted, "Audit log entry for executed change not found in DynamoDB");
  }
}
```

---

## Advanced configuration

Flamingock can be configured using Spring Boot properties, either in your `application.yml` or dynamically via `@DynamicPropertySource`.

This is especially useful for setting values like:

```java
@DynamicPropertySource
static void overrideProperties(DynamicPropertyRegistry registry) {
  String endpoint = "http://" + dynamoDb.getHost() + ":" + dynamoDb.getFirstMappedPort();
  registry.add("flamingock.dynamodb.readCapacityUnits", () -> 5L);
  registry.add("flamingock.dynamodb.writeCapacityUnits", () -> 5L);
  registry.add("flamingock.dynamodb.autoCreate", () -> true);
  registry.add("flamingock.dynamodb.auditRepositoryName", () -> "flamingockAuditLogs");
  registry.add("flamingock.dynamodb.lockRepositoryName", () -> "flamingockLocks");
}
```

These properties allow Flamingock to connect to the appropriate DynamoDB instance and create its internal metadata tables automatically.

---

## Best practices

- Declare all required dependencies (like `DynamoDbClient`, `AdminClient`, etc.) as Spring beans
- Use `@DynamicPropertySource` to inject dynamic config for local/test environments
- Validate both the **external effect** (Kafka, S3, etc.) and the **audit record** in the backend
- Use `Testcontainers` for isolation and reproducibility across environments
- Keep tests focused: use Spring Boot only when testing real integration scenarios (not just logic)